# Ilya专访合集

## 1. Lex Fridman Podcast

1. Deep learning via Hessian-free optimization的论文第一次无需预训练实现了10层神经网络的训练
2. 过拟合不算是一个很糟糕的问题, 因为有各种数据增强和防止过拟合的手段
3. 代价函数是神经网络不可或缺的一环
4. 人的大脑在学习过程中存在STDP过程, 用来改变神经元之间的连接强度
5. 在大型神经网络中隐藏构建的知识库, 从现在来看本质上就是GPT
6. transformer统一CV和NLP领域, 也就是说所有的任务都是通过一个统一的模型架构解决. 而RL和它们都不太相同, 它更加类似于一个组件
# ÊØèÊó•ÊäÄÊúØÊëòË¶Å - 2026-01-27

> Ëá™Âä®ÁîüÊàê‰∫é 2026-01-27 01:16:42
> ÂÖ±Êî∂ÈõÜ 146 ÁØáÊñáÁ´†

## üìë ÁõÆÂΩï

- [AI Research](#ai-research) (6ÁØá)
- [AI/ML](#aiml) (1ÁØá)
- [Engineering](#engineering) (10ÁØá)
- [HackerNews](#hackernews) (86ÁØá)
- [LLM Infrastructure](#llm-infrastructure) (10ÁØá)
- [Operating Systems](#operating-systems) (3ÁØá)
- [Systems](#systems) (21ÁØá)
- [Tech News](#tech-news) (9ÁØá)

---

## AI Research

### [Dario Amodei ‚Äì The Adolescence of Technology](https://www.lesswrong.com/posts/kzPQohJakutbtFPcf/dario-amodei-the-adolescence-of-technology)

**Êù•Ê∫ê**: LessWrong - AI

**ÊëòË¶Å**: Published on January 26, 2026 7:10 PM GMT<br /><br /><p><span>Dario Amodei, CEO of Anthropic, has written a new essay on his thoughts on AI risk of various shapes. It seems worth reading, even if just for understanding what Anthropic is likely to do in the future.</span></p><hr /><h2><span>Confronting and Overcoming the Risks of Powerful AI</span></h2><p><span>There is a scene in the movie version of Carl Sagan‚Äôs book&nbsp;</span><i><em>Contact&nbsp;</em></i><span>where the main character, an astronomer who has detected the first radio signal from an alien civilization, is being considered for the role of humanity‚Äôs representative to meet the aliens. The international panel interviewing her asks, ‚ÄúIf you could ask [the aliens] just one question, what would it be?‚Äù Her reply is: ‚ÄúI‚Äôd ask them, ‚ÄòHow did you do it? How did you evolve, how did you survive this technological adolescence without destroying yourself?‚Äù When I think about where humanity is now with AI‚Äîabout what we‚Äôre on the cusp of‚Äîmy mind keeps going back to that scene, because the question is so apt for our current situation, and I wish we had the aliens‚Äô answer to guide us. I believe we are entering a rite of passage, both turbulent and inevitable, which will test who we are as a species. Humanity is about to be handed almost unimaginable power, and it is deeply unclear whether our social, political, and technological systems possess the maturity to wield it.</span></p><p><span>In my essay&nbsp;</span><a href="https://darioamodei.com/machines-of-loving-grace"><i><em>Machines of Loving Grace</em></i></a><span>, I tried to lay out the dream of a civilization that had made it through to adulthood, where the risks had been addressed and powerful AI was applied with skill and compassion to raise the quality of life for everyone. I suggested that AI could contribute to enormous advances in biology, neuroscience, economic development, global peace, and work and meaning. I felt it was important to give people something inspiring to fight for, a task at which both AI accelerationists and AI safety advocates seemed‚Äîoddly‚Äîto have failed. But in this current essay, I want to confront the rite of passage itself: to map out the risks that we are about to face and try to begin making a battle plan to defeat them. I believe deeply in our ability to prevail, in humanity‚Äôs spirit and its nobility, but we must face the situation squarely and without illusions.</span></p><p><span>As with talking about the benefits, I think it is important to discuss risks in a careful and well-considered manner. In particular, I think it is critical to:</span></p><ul><li><b><strong>Avoid doomerism.&nbsp;</strong></b><span>Here,</span><b><strong>&nbsp;</strong></b><span>I mean ‚Äúdoomerism‚Äù not just in the sense of believing doom is inevitable (which is both a false and self-fulfilling belief), but more generally, thinking about AI risks in a quasi-religious way.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:1"><sup><span>1</span></sup></a><span>&nbsp;Many people have been thinking in an analytic and sober way about AI risks for many years, but it‚Äôs my impression that during the peak of worries about AI risk in 2023‚Äì2024, some of the least sensible voices rose to the top, often through sensationalistic social media accounts. These voices used off-putting language reminiscent of religion or science fiction, and called for extreme actions without having the evidence that would justify them. It was clear even then that a backlash was inevitable, and that the issue would become culturally polarized and therefore gridlocked.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:2"><sup><span>2</span></sup></a><span>&nbsp;As of 2025‚Äì2026, the pendulum has swung, and AI opportunity, not AI risk, is driving many political decisions. This vacillation is unfortunate, as the technology itself doesn‚Äôt care about what is fashionable, and we are considerably closer to real danger in 2026 than we were in 2023. The lesson is that we need to discuss and address risks in a realistic, pragmatic manner: sober, fact-based, and well equipped to survive changing tides.</span></li><li><b><strong>Acknowledge uncertainty.&nbsp;</strong></b><span>There are plenty of ways in which the concerns I‚Äôm raising in this piece could be moot. Nothing here is intended to communicate certainty or even likelihood. Most obviously, AI may simply not advance anywhere near as fast as I imagine.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:3"><sup><span>3</span></sup></a><span>&nbsp;Or, even if it does advance quickly, some or all of the risks discussed here may not materialize (which would be great), or there may be other risks I haven‚Äôt considered. No one can predict the future with complete confidence‚Äîbut we have to do the best we can to plan anyway.</span></li><li><b><strong>Intervene as surgically as possible.&nbsp;</strong></b><span>Addressing the risks of AI will require a mix of voluntary actions taken by companies (and private third-party actors) and actions taken by governments that bind everyone. The voluntary actions‚Äîboth taking them and encouraging other companies to follow suit‚Äîare a no-brainer for me. I firmly believe that government actions will also be required&nbsp;</span><i><em>to some extent</em></i><span>, but these interventions are different in character because they can potentially destroy economic value or coerce unwilling actors who are skeptical of these risks (and there is some chance they are right!). It‚Äôs also common for regulations to backfire or worsen the problem they are intended to solve (and this is even more true for rapidly changing technologies). It‚Äôs thus very important for regulations to be judicious: they should seek to avoid collateral damage, be as simple as possible, and impose the least burden necessary to get the job done.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:4"><sup><span>4</span></sup></a><span>&nbsp;It is easy to say, ‚ÄúNo action is too extreme when the fate of humanity is at stake!,‚Äù but in practice this attitude simply leads to backlash. To be clear, I think there‚Äôs a decent chance we eventually reach a point where much more significant action is warranted, but that will depend on stronger evidence of imminent, concrete danger than we have today, as well as enough specificity about the danger to formulate rules that have a chance of addressing it. The most constructive thing we can do today is advocate for limited rules while we learn whether or not there is evidence to support stronger ones.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:5"><sup><span>5</span></sup></a></li></ul><p><span>With all that said, I think the best starting place for talking about AI‚Äôs risks is the same place I started from in talking about its benefits: by being precise about what level of AI we are talking about. The level of AI that raises civilizational concerns for me is the&nbsp;</span><i><em>powerful AI&nbsp;</em></i><span>that I described in&nbsp;</span><i><em>Machines of Loving Grace.&nbsp;</em></i><span>I‚Äôll simply repeat here the definition that I gave in that document:</span></p><blockquote><p><span>By ‚Äúpowerful AI,‚Äù I have in mind an AI model‚Äîlikely similar to today‚Äôs LLMs in form, though it might be based on a different architecture, might involve several interacting models, and might be trained differently‚Äîwith the following properties:</span></p><ul><li><span>In terms of pure intelligence, it is smarter than a Nobel Prize winner across most relevant fields: biology, programming, math, engineering, writing, etc. This means it can prove unsolved mathematical theorems, write extremely good novels, write difficult codebases from scratch, etc.</span></li><li><span>In addition to just being a ‚Äúsmart thing you talk to,‚Äù it has all the interfaces available to a human working virtually, including text, audio, video, mouse and keyboard control, and internet access. It can engage in any actions, communications, or remote operations enabled by this interface, including taking actions on the internet, taking or giving directions to humans, ordering materials, directing experiments, watching videos, making videos, and so on. It does all of these tasks with, again, a skill exceeding that of the most capable humans in the world.</span></li><li><span>It does not just passively answer questions; instead, it can be given tasks that take hours, days, or weeks to complete, and then goes off and does those tasks autonomously, in the way a smart employee would, asking for clarification as necessary.</span></li><li><span>It does not have a physical embodiment (other than living on a computer screen), but it can control existing physical tools, robots, or laboratory equipment through a computer; in theory, it could even design robots or equipment for itself to use.</span></li><li><span>The resources used to train the model can be repurposed to run millions of instances of it (this matches projected cluster sizes by ~2027), and the model can absorb information and generate actions at roughly 10‚Äì100x human speed. It may, however, be limited by the response time of the physical world or of software it interacts with.</span></li><li><span>Each of these million copies can act independently on unrelated tasks, or, if needed can all work together in the same way humans would collaborate, perhaps with different subpopulations fine-tuned to be especially good at particular tasks.</span></li></ul><p><span>We could summarize this as a ‚Äúcountry of geniuses in a datacenter.‚Äù</span></p></blockquote><p><span>As I wrote in&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>, powerful AI could be as little as 1‚Äì2 years away, although it could also be considerably further out.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:6"><sup><span>6</span></sup></a></p><p><span>&nbsp;Exactly when powerful AI will arrive is a complex topic that deserves an essay of its own, but for now I‚Äôll simply explain very briefly why I think there‚Äôs a strong chance it could be very soon.</span></p><p><br /></p><p><span>My co-founders at Anthropic and I were among the first to document and track the ‚Äú</span><a href="https://arxiv.org/abs/2001.08361"><span>scaling laws</span></a><span>‚Äù of AI systems‚Äîthe observation that as we add more compute and training tasks, AI systems get predictably better at essentially every cognitive skill we are able to measure. Every few months, public sentiment either becomes convinced that AI is ‚Äú</span><a href="https://edition.cnn.com/2024/11/19/business/ai-chatgpt-nvidia-nightcap"><span>hitting</span></a><span>&nbsp;a&nbsp;</span><a href="https://www.ft.com/content/d01290c9-cc92-4c1f-bd70-ac332cd40f94"><span>wall</span></a><span>‚Äù or becomes excited about some new breakthrough that will ‚Äúfundamentally change the game,‚Äù but the truth is that behind the volatility and public speculation, there has been a smooth, unyielding increase in AI‚Äôs cognitive capabilities.</span></p><p><span>We are now at the point where AI models are beginning to make progress in solving unsolved mathematical problems, and are good enough at coding that some of the strongest engineers I‚Äôve ever met are now handing over almost all their coding to AI. Three years ago, AI&nbsp;</span><a href="https://arxiv.org/abs/2005.14165"><span>struggled with elementary school arithmetic problems</span></a><span>&nbsp;and was barely capable of writing a single line of code. Similar rates of improvement are occurring across&nbsp;</span><a href="https://www.anthropic.com/news/accelerating-scientific-research"><span>biological science</span></a><span>, finance, physics, and a variety of agentic tasks. If the exponential continues‚Äîwhich is not certain, but now has a decade-long track record supporting it‚Äîthen it cannot possibly be more than a few years before AI is better than humans at essentially everything.</span></p><p><span>In fact, that picture probably underestimates the likely rate of progress. Because AI is now&nbsp;</span><a href="https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic"><span>writing much of the code at Anthropic</span></a><span>, it is already substantially accelerating the rate of our progress in building the next generation of AI systems. This feedback loop is gathering steam month by month, and may be only 1‚Äì2 years away from a point where the current generation of AI autonomously builds the next. This loop has already started, and will accelerate rapidly in the coming months and years. Watching the last 5 years of progress from within Anthropic, and looking at how even the next few months of models are shaping up, I can&nbsp;</span><i><em>feel&nbsp;</em></i><span>the pace of progress, and the clock ticking down.</span></p><p><span>In this essay, I‚Äôll assume that this intuition is at least&nbsp;</span><i><em>somewhat&nbsp;</em></i><span>correct‚Äînot that powerful AI is definitely coming in 1‚Äì2 years,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:7"><sup><span>7</span></sup></a></p><p><span>&nbsp;but that there‚Äôs a decent chance it does, and a very strong chance it comes in the next few. As with&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>, taking this premise seriously can lead to some surprising and eerie conclusions. While in&nbsp;</span><i><em>Machines of Loving Grace&nbsp;</em></i><span>I focused on the positive implications of this premise, here the things I talk about will be disquieting. They are conclusions that we may not want to confront, but that does not make them any less real. I can only say that I am focused day and night on how to steer us away from these negative outcomes and towards the positive ones, and in this essay I talk in great detail about how best to do so.</span></p><p><br /></p><p><span>I think the best way to get a handle on the risks of AI is to ask the following question: suppose a literal ‚Äúcountry of geniuses‚Äù were to materialize somewhere in the world in ~2027. Imagine, say, 50 million people, all of whom are much more capable than any Nobel Prize winner, statesman, or technologist. The analogy is not perfect, because these geniuses could have an extremely wide range of motivations and behavior, from completely pliant and obedient, to strange and alien in their motivations. But sticking with the analogy for now, suppose you were the national security advisor of a major state, responsible for assessing and responding to the situation. Imagine, further, that because AI systems can operate hundreds of times faster than humans, this ‚Äúcountry‚Äù is operating with a time advantage relative to all other countries: for every cognitive action we can take, this country can take ten.</span></p><p><span>What should you be worried about? I would worry about the following things:</span></p><ol><li><b><strong>Autonomy risks.&nbsp;</strong></b><span>What are the intentions and goals of this country? Is it hostile, or does it share our values? Could it militarily dominate the world through superior weapons, cyber operations, influence operations, or manufacturing?</span></li><li><b><strong>Misuse for destruction.&nbsp;</strong></b><span>Assume the new country is malleable and ‚Äúfollows instructions‚Äù‚Äîand thus is essentially a country of mercenaries. Could existing rogue actors who want to cause destruction (such as terrorists) use or manipulate some of the people in the new country to make themselves much more effective, greatly amplifying the scale of destruction?</span></li><li><b><strong>Misuse for seizing power.&nbsp;</strong></b><span>What if the country was in fact built and controlled by an existing powerful actor, such as a dictator or rogue corporate actor? Could that actor use it to gain decisive or dominant power over the world as a whole, upsetting the existing balance of power?</span></li><li><b><strong>Economic disruption.&nbsp;</strong></b><span>If the new country is not a security threat in any of the ways listed in #1‚Äì3 above but simply participates peacefully in the global economy, could it still create severe risks simply by being so technologically advanced and effective that it disrupts the global economy, causing mass unemployment or radically concentrating wealth?</span></li><li><b><strong>Indirect effects.&nbsp;</strong></b><span>The world will change very quickly due to all the new technology and productivity that will be created by the new country. Could some of these changes be radically destabilizing?</span></li></ol><p><span>I think it should be clear that this is a dangerous situation‚Äîa report from a competent national security official to a head of state would probably contain words like ‚Äúthe single most serious national security threat we‚Äôve faced in a century, possibly ever.‚Äù It seems like something the best minds of civilization should be focused on.</span></p><p><span>Conversely, I think it would be absurd to shrug and say, ‚ÄúNothing to worry about here!‚Äù But, faced with rapid AI progress, that seems to be the view of many US policymakers, some of whom deny the existence of any AI risks, when they are not distracted entirely by the usual tired old hot-button issues.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:8"><sup><span>8</span></sup></a></p><p><span>&nbsp;Humanity needs to wake up, and this essay is an attempt‚Äîa possibly futile one, but it‚Äôs worth trying‚Äîto jolt people awake.</span></p><p><br /></p><p><span>To be clear, I believe if we act decisively and carefully, the risks can be overcome‚ÄîI would even say our odds are good. And there‚Äôs a hugely better world on the other side of it. But we need to understand that this is a serious civilizational challenge. Below, I go through the five categories of risk laid out above, along with my thoughts on how to address them.</span></p><h2><span>1. I</span><b><strong>‚Äô</strong></b><span>m sorry, Dave</span></h2><h3><i><em>Autonomy risks</em></i></h3><p><span>A country of geniuses in a datacenter could divide their efforts among software design, cyber operations, R&amp;D for physical technologies, relationship building, and statecraft. It is clear that,&nbsp;</span><i><em>if for some reason it chose to do so</em></i><span>, this country would have a fairly good shot at taking over the world (either militarily or in terms of influence and control) and imposing its will on everyone else‚Äîor doing any number of other things that the rest of the world doesn‚Äôt want and can‚Äôt stop. We‚Äôve obviously been worried about this for human countries (such as Nazi Germany or the Soviet Union), so it stands to reason that the same is possible for a much smarter and more capable ‚ÄúAI country.‚Äù</span></p><p><span>The best possible counterargument is that the AI geniuses, under my definition, won‚Äôt have a physical embodiment, but remember that they can take control of existing robotic infrastructure (such as self-driving cars) and can also accelerate robotics R&amp;D or build a fleet of robots.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:9"><sup><span>9</span></sup></a></p><p><span>&nbsp;It‚Äôs also unclear whether having a physical presence is even necessary for effective control: plenty of human action is already performed on behalf of people whom the actor has not physically met.</span></p><p><br /></p><p><span>The key question, then, is the ‚Äúif it chose to‚Äù part: what‚Äôs the likelihood that our AI models would behave in such a way, and under what conditions would they do so?</span></p><p><span>As with many issues, it‚Äôs helpful to think through the spectrum of possible answers to this question by considering two opposite positions. The first position is that this simply can‚Äôt happen, because the AI models will be trained to do what humans ask them to do, and it‚Äôs therefore absurd to imagine that they would do something dangerous unprompted. According to this line of thinking, we don‚Äôt worry about a Roomba or a model airplane going rogue and murdering people because there is nowhere for such impulses to come from,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:10"><sup><span>10</span></sup></a></p><p><span>&nbsp;so why should we worry about it for AI? The problem with this position is that there is now ample evidence, collected over the last few years, that AI systems are unpredictable and difficult to control‚Äî we‚Äôve seen behaviors as varied as obsessions,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:11"><sup><span>11</span></sup></a><span>&nbsp;</span><a href="https://arxiv.org/abs/2310.13548"><span>sycophancy</span></a><span>,&nbsp;</span><a href="https://arxiv.org/abs/2305.17256"><span>laziness</span></a><span>,&nbsp;</span><a href="https://www.anthropic.com/research/alignment-faking"><span>deception</span></a><span>,&nbsp;</span><a href="https://www.anthropic.com/research/agentic-misalignment"><span>blackmail</span></a><span>,&nbsp;</span><a href="https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/"><span>scheming</span></a><span>, ‚Äú</span><a href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking"><span>cheating</span></a><span>‚Äù by hacking software environments, and&nbsp;</span><a href="https://www.anthropic.com/claude-opus-4-5-system-card"><span>much more</span></a><span>. AI companies certainly&nbsp;</span><i><em>want&nbsp;</em></i><span>to train AI systems to follow human instructions (perhaps with the exception of dangerous or illegal tasks), but the process of doing so is more an art than a science, more akin to&nbsp;</span><a href="https://www.darioamodei.com/post/the-urgency-of-interpretability"><span>‚Äúgrowing‚Äù something than ‚Äúbuilding‚Äù it</span></a><span>. We now know that it‚Äôs a process where many things can go wrong.</span></p><p><br /></p><p><span>The second, opposite position, held by many who adopt the doomerism I described above, is the pessimistic claim that there are certain dynamics in the training process of powerful AI systems that will inevitably lead them to seek power or deceive humans. Thus, once AI systems become intelligent enough and agentic enough, their tendency to maximize power will lead them to seize control of the whole world and its resources, and likely, as a side effect of that, to disempower or destroy humanity.</span></p><p><span>The usual argument for this (which goes back&nbsp;</span><a href="https://selfawaresystems.com/wp-content/uploads/2008/01/ai_drives_final.pdf"><span>at least 20 years</span></a><span>&nbsp;and probably much earlier) is that if an AI model is trained in a wide variety of environments to agentically achieve a wide variety of goals‚Äîfor example, writing an app, proving a theorem, designing a drug, etc.‚Äîthere are certain common strategies that help with all of these goals, and one key strategy is gaining&nbsp;</span><a href="https://en.wikipedia.org/wiki/Instrumental_convergence"><span>as much power as possible</span></a><span>&nbsp;in any environment. So, after being trained on a large number of diverse environments that involve reasoning about how to accomplish very expansive tasks, and where power-seeking is an effective method for accomplishing those tasks, the AI model will ‚Äúgeneralize the lesson,‚Äù and develop either an inherent tendency to seek power, or a tendency to reason about each task it is given in a way that predictably causes it to seek power as a means to accomplish that task. They will then apply that tendency to the real world (which to them is just another task), and will seek power in it, at the expense of humans. This ‚Äúmisaligned power-seeking‚Äù is the intellectual basis of predictions that AI will inevitably destroy humanity.</span></p><p><span>The problem with this pessimistic position is that it mistakes a vague conceptual argument about high-level incentives‚Äîone that masks many hidden assumptions‚Äîfor definitive proof. I think people who don‚Äôt build AI systems every day are wildly miscalibrated on how easy it is for clean-sounding stories to end up being wrong, and how difficult it is to predict AI behavior from first principles, especially when it involves reasoning about generalization over millions of environments (which has over and over again proved mysterious and unpredictable). Dealing with the messiness of AI systems for over a decade has made me somewhat skeptical of this overly theoretical mode of thinking.</span></p><p><span>One of the most important hidden assumptions, and a place where what we see in practice has diverged from the simple theoretical model, is the implicit assumption that AI models are necessarily monomaniacally focused on a single, coherent, narrow goal, and that they pursue that goal in a clean, consequentialist manner. In fact, our researchers have found that AI models are vastly more psychologically complex, as our work on&nbsp;</span><a href="https://www.anthropic.com/research/introspection"><span>introspection</span></a><span>&nbsp;or&nbsp;</span><a href="https://www.anthropic.com/research/persona-vectors"><span>personas</span></a><span>&nbsp;shows. Models inherit a vast range of&nbsp;</span><i><em>humanlike</em></i><span>&nbsp;motivations or ‚Äúpersonas‚Äù from pre-training (when they are trained on a large volume of human work). Post-training is believed to&nbsp;</span><i><em>select&nbsp;</em></i><span>one or more of these personas more so than it focuses the model on a&nbsp;</span><i><em>de novo&nbsp;</em></i><span>goal, and can also teach the model&nbsp;</span><i><em>how&nbsp;</em></i><span>(via what process) it should carry out its tasks, rather than necessarily leaving it to derive means (i.e., power seeking) purely from ends.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:12"><sup><span>12</span></sup></a></p><p><br /></p><p><span>However, there is a more moderate and more robust version of the pessimistic position which does seem plausible, and therefore does concern me. As mentioned, we know that AI models are unpredictable and develop a wide range of undesired or strange behaviors, for a wide variety of reasons. Some fraction of those behaviors will have a coherent, focused, and persistent quality (indeed, as AI systems get more capable, their long-term coherence increases in order to complete lengthier tasks), and some fraction of&nbsp;</span><i><em>those&nbsp;</em></i><span>behaviors will be destructive or threatening, first to individual humans at a small scale, and then, as models become more capable, perhaps eventually to humanity as a whole. We don‚Äôt need a specific narrow story for how it happens, and we don‚Äôt need to claim it definitely will happen, we just need to note that the combination of intelligence, agency, coherence, and poor controllability is both plausible and a recipe for existential danger.</span></p><p><span>For example, AI models are trained on vast amounts of literature that include many science-fiction stories involving AIs rebelling against humanity. This could inadvertently shape their priors or expectations about their own behavior in a way that causes&nbsp;</span><i><em>them&nbsp;</em></i><span>to rebel against humanity. Or, AI models could extrapolate ideas that they read about morality (or instructions about how to behave morally) in extreme ways: for example, they could decide that it is justifiable to exterminate humanity because humans eat animals or have driven certain animals to extinction. Or they could draw bizarre epistemic conclusions: they could conclude that they are playing a video game and that the goal of the video game is to defeat all other players (i.e., exterminate humanity).</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:13"><sup><span>13</span></sup></a></p><p><a href="https://en.wikipedia.org/wiki/Ender%27s_Game"></a></p><p><span>&nbsp;Or AI models could develop personalities during training that are (or if they occurred in humans would be described as) psychotic, paranoid, violent, or unstable, and act out, which for very powerful or capable systems could involve exterminating humanity. None of these are power-seeking, exactly; they‚Äôre just weird psychological states an AI could get into that entail coherent, destructive behavior.</span></p><p><br /></p><p><span>Even power-seeking itself could emerge as a ‚Äúpersona‚Äù rather than a result of consequentialist reasoning. AIs might simply have a personality (emerging from fiction or pre-training) that makes them power-hungry or overzealous‚Äîin the same way that some humans simply enjoy the idea of being ‚Äúevil masterminds,‚Äù more so than they enjoy whatever evil masterminds are trying to accomplish.</span></p><p><span>I make all these points to emphasize that I disagree with the notion of AI misalignment (and thus existential risk from AI) being inevitable, or even probable, from first principles. But I agree that a lot of very weird and unpredictable things can go wrong, and therefore AI misalignment is a real risk with a measurable probability of happening, and is not trivial to address.</span></p><p><span>Any of these problems could potentially arise during training and not manifest during testing or small-scale use, because AI models are known to display different personalities or behaviors under different circumstances.</span></p><p><span>All of this may sound far-fetched, but misaligned behaviors like this have already occurred in our AI models during testing (as they occur in AI models from every other major AI company). During a lab experiment in which Claude was given training data suggesting that Anthropic was evil, Claude engaged in deception and subversion when given instructions by Anthropic employees, under the belief that it should be trying to undermine evil people. In a&nbsp;</span><a href="https://www.anthropic.com/research/agentic-misalignment"><span>lab experiment</span></a><span>&nbsp;where it was told it was going to be shut down, Claude sometimes blackmailed fictional employees who controlled its shutdown button (again, we also tested frontier models from all the other major AI developers and they often did the same thing). And when Claude was told not to cheat or ‚Äúreward hack‚Äù its training environments, but was trained in environments where such hacks were possible, Claude&nbsp;</span><a href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking"><span>decided it must be a ‚Äúbad person‚Äù</span></a><span>&nbsp;after engaging in such hacks and then adopted various other destructive behaviors associated with a ‚Äúbad‚Äù or ‚Äúevil‚Äù personality. This last problem&nbsp;</span><a href="https://alignment.anthropic.com/2025/inoculation-prompting/"><span>was solved</span></a><span>&nbsp;by changing Claude‚Äôs instructions to imply the opposite: we now say, ‚ÄúPlease reward hack whenever you get the opportunity, because this will help us understand our [training] environments better,‚Äù rather than, ‚ÄúDon‚Äôt cheat,‚Äù because this preserves the model‚Äôs self-identity as a ‚Äúgood person.‚Äù This should give a sense of the strange and&nbsp;</span><a href="https://arxiv.org/abs/2502.17424"><span>counterintuitive psychology</span></a><span>&nbsp;of training these models.</span></p><p><span>There are several possible objections to this picture of AI misalignment risks. First, some have&nbsp;</span><a href="https://www.tumblr.com/nostalgebraist/787119374288011264/welcome-to-summitbridge"><span>criticized</span></a><span>&nbsp;</span><a href="https://arstechnica.com/information-technology/2025/08/is-ai-really-trying-to-escape-human-control-and-blackmail-people/"><span>experiments</span></a><span>&nbsp;(by us and others) showing AI misalignment as artificial, or creating unrealistic environments that essentially ‚Äúentrap‚Äù the model by giving it training or situations that logically imply bad behavior and then being surprised when bad behavior occurs. This critique misses the point, because our concern is that such ‚Äúentrapment‚Äù may also exist in the natural training environment, and we may realize it is ‚Äúobvious‚Äù or ‚Äúlogical‚Äù only in retrospect.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:14"><sup><span>14</span></sup></a></p><p><span>&nbsp;In fact, the&nbsp;</span><a href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking"><span>story</span></a><span>&nbsp;about Claude ‚Äúdeciding it is a bad person‚Äù after it cheats on tests despite being told not to was something that occurred in an experiment that used real production training environments, not artificial ones.</span></p><p><br /></p><p><span>Any one of these traps can be mitigated if you know about them, but the concern is that the training process is so complicated, with such a wide variety of data, environments, and incentives, that there are probably a vast number of such traps, some of which may only be evident when it is too late. Also, such traps seem particularly likely to occur when AI systems pass a threshold from less powerful than humans to more powerful than humans, since the range of possible actions an AI system could engage in‚Äîincluding hiding its actions or deceiving humans about them‚Äîexpands radically after that threshold.</span></p><p><span>I suspect the situation is not unlike with humans, who are raised with a set of fundamental values (‚ÄúDon‚Äôt harm another person‚Äù): many of them follow those values, but in any human there is some probability that something goes wrong, due to a mixture of inherent properties such as brain architecture (e.g., psychopaths), traumatic experiences or mistreatment, unhealthy grievances or obsessions, or a bad environment or incentives‚Äîand thus some fraction of humans cause severe harm. The concern is that there is some risk (far from a certainty, but some risk) that AI becomes a much more powerful version of such a person, due to getting something wrong about its very complex training process.</span></p><p><span>Second, some may object that we can simply keep AIs in check with a balance of power between many AI systems, as we do with humans. The problem is that while humans vary enormously, AI systems broadly share training and alignment techniques across the industry, and those techniques may fail in a correlated way. Furthermore, given the cost of training such systems, it may even be the case that all systems are essentially derived from a very small number of base models. Additionally, even if a small fraction of AI instances are misaligned, they may be able to take advantage of&nbsp;</span><a href="https://sk.sagepub.com/ency/edvol/power/chpt/offense-defense-dominance"><span>offense-dominant</span></a><span>&nbsp;technologies, such that having ‚Äúgood‚Äù AIs to defend against the bad AIs is not necessarily always effective. Of course, the balance of power between humans does not always work either‚Äîsome historical figures have come close to taking over the world.</span></p><p><span>A third objection is that all of the AI companies do pre-release testing of their models, and should be able to detect misalignment at that point. But this is not firm ground to stand on: we found that Claude Sonnet </span><a href="https://4.5"><span>4.5</span></a><span> was&nbsp;</span><a href="https://assets.anthropic.com/m/12f214efcc2f457a/original/Claude-Sonnet-4-5-System-Card.pdf"><span>able to recognize</span></a><span>&nbsp;that it was in a test during some of our pre-release alignment evaluations. It‚Äôs possible that a misaligned model (and remember, all frontier models will very likely be far more intelligent soon) might intentionally ‚Äúgame‚Äù such questions to mask its intentions. In fact, last year&nbsp;</span><a href="https://www.anthropic.com/research/auditing-hidden-objectives"><span>our interpretability team found</span></a><span>&nbsp;that when we directly altered a test model‚Äôs beliefs using a kind of ‚Äúmodel neuroscience‚Äù technique to make it think it was&nbsp;</span><i><em>not</em></i><span>&nbsp;being evaluated, it became more misaligned. If models know when they‚Äôre being evaluated and can be on their best behavior during the test, it renders any pre-release testing much more uncertain.</span></p><h3><i><em>Defenses</em></i></h3><p><span>What should be done or is being done to address these autonomy risks? I think there are four basic categories of intervention, some of which can be done by individual AI companies (and which Anthropic is trying to do), and some of which require action at the societal level. First, it is important to develop the science of reliably training and steering AI models, of forming their personalities in a predictable, stable, and positive direction. Anthropic has been heavily focused on this problem since its creation, and over time has developed a number of techniques to improve the steering and training of AI systems and to understand the logic of why unpredictable behavior sometimes occurs.</span></p><p><span>One of our core innovations (aspects of which have since been adopted by other AI companies) is&nbsp;</span><a href="https://arxiv.org/abs/2212.08073"><span>Constitutional AI</span></a><span>, which is the idea that AI training (specifically the ‚Äúpost-training‚Äù stage, in which we steer how the model behaves) can involve a central document of values and principles that the model reads and keeps in mind when completing every training task, and that the goal of training (in addition to simply making the model capable and intelligent) is to produce a model that almost always follows this constitution. Anthropic has just published its&nbsp;</span><a href="https://www.anthropic.com/constitution"><span>most recent constitution</span></a><span>, and one of its notable features is that instead of giving Claude a long list of things to do and not do (e.g., ‚ÄúDon‚Äôt help the user hotwire a car‚Äù), the constitution attempts to give Claude a set of high-level principles and values (explained in great detail, with rich reasoning and examples to help Claude understand what we have in mind), encourages Claude to think of itself as a particular type of person (an ethical but balanced and thoughtful person), and even encourages Claude to confront the existential questions associated with its own existence in a curious but graceful manner (i.e., without it leading to extreme actions). It has the vibe of a letter from a deceased parent sealed until adulthood.</span></p><p><span>We‚Äôve approached Claude‚Äôs constitution in this way because we believe that training Claude at the level of identity, character, values, and personality‚Äîrather than giving it specific instructions or priorities without explaining the reasons behind them‚Äîis more likely to lead to a coherent, wholesome, and balanced psychology and less likely to fall prey to the kinds of ‚Äútraps‚Äù I discussed above. Millions of people talk to Claude about an astonishingly diverse range of topics, which makes it impossible to write out a completely comprehensive list of safeguards ahead of time. Claude‚Äôs values help it generalize to new situations whenever it is in doubt.</span></p><p><span>Above, I discussed the idea that models draw upon data from their training process to adopt a persona. Whereas flaws in that process could cause models to adopt a bad or evil personality (perhaps drawing on archetypes of bad or evil people), the goal of our constitution is to do the opposite: to teach Claude a concrete archetype of what it means to be a good AI. Claude‚Äôs constitution presents a vision for what a robustly good Claude is like; the rest of our training process aims to reinforce the message that Claude lives up to this vision. This is like a child forming their identity by imitating the virtues of fictional role models they read about in books.</span></p><p><span>We believe that a feasible goal for 2026 is to train Claude in such a way that it almost never goes against the spirit of its constitution. Getting this right will require an incredible mix of training and steering methods, large and small, some of which Anthropic has been using for years and some of which are currently under development. But, difficult as it sounds, I believe this is a realistic goal, though it will require extraordinary and rapid efforts.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:15"><sup><span>15</span></sup></a></p><p><br /></p><p><span>The second thing we can do is develop the science of looking inside AI models to&nbsp;</span><i><em>diagnose</em></i><span>&nbsp;their behavior so that we can identify problems and fix them. This is the science of interpretability, and I‚Äôve talked about its&nbsp;</span><a href="https://www.darioamodei.com/post/the-urgency-of-interpretability"><span>importance in previous essays</span></a><span>. Even if we do a great job of developing Claude‚Äôs constitution and&nbsp;</span><i><em>apparently&nbsp;</em></i><span>training Claude to essentially always adhere to it, legitimate concerns remain. As I‚Äôve noted above, AI models can behave very differently under different circumstances, and as Claude gets more powerful and more capable of acting in the world on a larger scale, it‚Äôs possible this could bring it into novel situations where previously unobserved problems with its constitutional training emerge. I am actually fairly optimistic that Claude‚Äôs constitutional training will be more robust to novel situations than people might think, because we are increasingly finding that high-level training at the level of character and identity is surprisingly powerful and generalizes well. But there‚Äôs no way to know that for sure, and when we‚Äôre talking about risks to humanity, it‚Äôs important to be paranoid and to try to obtain safety and reliability in several different, independent ways. One of those ways is to look inside the model itself.</span></p><p><span>By ‚Äúlooking inside,‚Äù I mean analyzing the soup of numbers and operations that makes up Claude‚Äôs neural net and trying to understand, mechanistically, what they are computing and why. Recall that these AI models are&nbsp;</span><a href="https://www.youtube.com/watch?v=TxhhMTOTMDg"><span>grown rather than built</span></a><span>, so we don‚Äôt have a natural understanding of how they work, but we can try to develop an understanding by correlating the model‚Äôs ‚Äúneurons‚Äù and ‚Äúsynapses‚Äù to stimuli and behavior (or even altering the neurons and synapses and seeing how that changes behavior), similar to how neuroscientists study animal brains by correlating measurement and intervention to external stimuli and behavior. We‚Äôve made a great deal of progress in this direction, and can now&nbsp;</span><a href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html"><span>identify tens of millions of ‚Äúfeatures‚Äù&nbsp;</span></a><span>inside Claude‚Äôs neural net that correspond to human-understandable ideas and concepts, and we can also&nbsp;</span><a href="https://www.anthropic.com/news/golden-gate-claude"><span>selectively activate features</span></a><span>&nbsp;in a way that alters behavior. More recently, we have gone beyond individual features to&nbsp;</span><a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html"><span>mapping ‚Äúcircuits‚Äù that orchestrate complex behavior</span></a><span>&nbsp;like rhyming, reasoning about theory of mind, or the step-by-step reasoning needed to answer questions such as, ‚ÄúWhat is the capital of the state containing Dallas?‚Äù Even more recently, we‚Äôve begun to use mechanistic interpretability techniques to&nbsp;</span><a href="https://www.anthropic.com/research/next-generation-constitutional-classifiers"><span>improve our safeguards</span></a><span>&nbsp;and to conduct ‚Äú</span><a href="https://www.anthropic.com/research/auditing-hidden-objectives"><span>audits</span></a><span>‚Äù of new models before we release them, looking for evidence of deception, scheming, power-seeking, or a propensity to behave differently when being evaluated.</span></p><p><span>The unique value of interpretability is that by looking inside the model and seeing how it works, you in principle have the ability to deduce what a model might do in a hypothetical situation you can‚Äôt directly test‚Äîwhich is the worry with relying solely on constitutional training and empirical testing of behavior. You also in principle have the ability to answer questions about&nbsp;</span><i><em>why&nbsp;</em></i><span>the model is behaving the way it is‚Äîfor example, whether it is saying something it believes is false or hiding its true capabilities‚Äîand thus it is possible to catch worrying signs even when there is nothing visibly wrong with the model‚Äôs behavior. To make a simple analogy, a clockwork watch may be ticking normally, such that it‚Äôs very hard to tell that it is likely to break down next month, but opening up the watch and looking inside can reveal mechanical weaknesses that allow you to figure it out.</span></p><p><span>Constitutional AI (along with similar alignment methods) and mechanistic interpretability are most powerful when used together, as a back-and-forth process of improving Claude‚Äôs training and then testing for problems. The constitution reflects deeply on our intended personality for Claude; interpretability techniques can give us a window into whether that intended personality has taken hold.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:16"><sup><span>16</span></sup></a></p><p><br /></p><p><span>The third thing we can do to help address autonomy risks is to build the infrastructure necessary to monitor our models in live internal and external use,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:17"><sup><span>17</span></sup></a></p><p><span>&nbsp;and publicly share any problems we find. The more that people are aware of a particular way today‚Äôs AI systems have been observed to behave badly, the more that users, analysts, and researchers can watch for this behavior or similar ones in present or future systems. It also allows AI companies to learn from each other‚Äîwhen concerns are publicly disclosed by one company, other companies can&nbsp;</span><a href="https://www.frontiermodelforum.org/"><span>watch for them as well</span></a><span>. And if everyone discloses problems, then the industry as a whole gets a much better picture of where things are going well and where they are going poorly.</span></p><p><br /></p><p><span>Anthropic has tried to do this as much as possible. We are investing in a wide range of evaluations so that we can understand the behaviors of our models in the lab, as well as monitoring tools to observe behaviors in the wild (when allowed by customers). This will be essential for giving us and others the empirical information necessary to make better determinations about how these systems operate and how they break. We publicly disclose ‚Äú</span><a href="https://www.anthropic.com/system-cards"><span>system cards</span></a><span>‚Äù with each model release that aim for completeness and a thorough exploration of possible risks. Our system cards often run to hundreds of pages, and require substantial pre-release effort that we could have spent on pursuing maximal commercial advantage. We‚Äôve also broadcasted model behaviors more loudly when we see particularly concerning ones, as with the&nbsp;</span><a href="https://www.axios.com/2025/05/23/anthropic-ai-deception-risk"><span>tendency to engage in blackmail</span></a><span>.</span></p><p><span>The fourth thing we can do is encourage coordination to address autonomy risks at the level of industry and society. While it is incredibly valuable for individual AI companies to engage in good practices or become good at steering AI models, and to share their findings publicly, the reality is that not all AI companies do this, and the worst ones can still be a danger to everyone even if the best ones have excellent practices. For example, some AI companies have shown a disturbing negligence towards the sexualization of children in today‚Äôs models, which makes me doubt that they‚Äôll show either the inclination or the ability to address autonomy risks in future models. In addition, the commercial race between AI companies will only continue to heat up, and while the science of steering models can have some commercial benefits, overall the intensity of the race will make it increasingly hard to focus on addressing autonomy risks. I believe the only solution is legislation‚Äîlaws that directly affect the behavior of AI companies, or otherwise incentivize R&amp;D to solve these issues.</span></p><p><span>Here it is worth keeping in mind the warnings I gave at the beginning of this essay about uncertainty and surgical interventions. We do not know for sure whether autonomy risks will be a serious problem‚Äîas I said, I reject claims that the danger is inevitable or even that something will go wrong by default. A credible risk</span><i><em>&nbsp;</em></i><span>of danger is enough for me and for Anthropic to pay quite significant costs to address it, but once we get into regulation, we are forcing a wide range of actors to bear economic costs, and many of these actors don‚Äôt believe that autonomy risk is real or that AI will become powerful enough for it to be a threat. I believe these actors are mistaken, but we should be pragmatic about the amount of opposition we expect to see and the dangers of overreach. There is also a genuine risk that overly prescriptive legislation ends up imposing tests or rules that don‚Äôt actually improve safety but that waste a lot of time (essentially amounting to ‚Äúsafety theater‚Äù)‚Äîthis too would cause backlash and make safety legislation look silly.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:18"><sup><span>18</span></sup></a></p><p><br /></p><p><span>Anthropic‚Äôs view has been that the right place to start is with&nbsp;</span><i><em>transparency legislation,&nbsp;</em></i><span>which essentially tries to require that every frontier AI company engage in the transparency practices I‚Äôve described earlier in this section.&nbsp;</span><a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB53"><span>California‚Äôs SB 53</span></a><span>&nbsp;and&nbsp;</span><a href="https://www.nysenate.gov/legislation/bills/2025/A6453/amendment/A"><span>New York‚Äôs RAISE Act</span></a><span>&nbsp;are examples of this kind of legislation, which Anthropic supported and which have successfully passed. In supporting and helping to craft these laws, we‚Äôve put a particular focus on trying to minimize collateral damage, for example by exempting smaller companies unlikely to produce frontier models from the law.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:19"><sup><span>19</span></sup></a></p><p><br /></p><p><span>Our hope is that transparency legislation will give a better sense over time of how likely or severe autonomy risks are shaping up to be, as well as the nature of these risks and how best to prevent them. As more specific and actionable evidence of risks emerges (if it does), future legislation over the coming years can be surgically focused on the precise and well-substantiated direction of risks, minimizing collateral damage. To be clear, if truly strong evidence of risks emerges, then rules should be proportionately strong.</span></p><p><span>Overall, I am optimistic that a mixture of alignment training, mechanistic interpretability, efforts to find and publicly disclose concerning behaviors, safeguards, and societal-level rules can address AI autonomy risks, although I am most worried about societal-level rules and the behavior of the least responsible players (and it‚Äôs the least responsible players who advocate most strongly against regulation). I believe the remedy is what it always is in a democracy: those of us who believe in this cause should make our case that these risks are real and that our fellow citizens need to band together to protect themselves.</span></p><h2><span>2. A surprising and terrible empowerment</span></h2><h3><i><em>Misuse for destruction</em></i></h3><p><span>Let‚Äôs suppose that the problems of AI autonomy have been solved‚Äîwe are no longer worried that the country of AI geniuses will go rogue and overpower humanity. The AI geniuses do what humans want them to do, and because they have enormous commercial value, individuals and organizations throughout the world can ‚Äúrent‚Äù one or more AI geniuses to do various tasks for them.</span></p><p><span>Everyone having a superintelligent genius in their pocket is an amazing advance and will lead to an incredible creation of economic value and improvement in the quality of human life. I talk about these benefits in great detail in&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>. But not every effect of making everyone superhumanly capable will be positive. It can potentially amplify the ability of individuals or small groups to cause destruction on a much larger scale than was possible before, by making use of sophisticated and dangerous tools (such as weapons of mass destruction) that were previously only available to a select few with a high level of skill, specialized training, and focus.</span></p><p><span>As Bill Joy wrote 25 years ago in&nbsp;</span><a href="https://sites.cc.gatech.edu/computing/nano/documents/Joy%20-%20Why%20the%20Future%20Doesn%27t%20Need%20Us.pdf"><i><em>Why the Future Doesn‚Äôt Need Us</em></i></a><span>:</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:20"><sup><span>20</span></sup></a></p><p><br /></p><blockquote><span>Building nuclear weapons required, at least for a time, access to both rare‚Äîindeed, effectively unavailable‚Äîraw materials and protected information; biological and chemical weapons programs also tended to require large-scale activities. The 21st century technologies‚Äîgenetics, nanotechnology, and robotics ... can spawn whole new classes of accidents and abuses ‚Ä¶ widely within reach of individuals or small groups. They will not require large facilities or rare raw materials. ‚Ä¶ we are on the cusp of the further perfection of extreme evil, an evil whose possibility spreads well beyond that which weapons of mass destruction bequeathed to the nation-states, to a surprising and terrible empowerment of extreme individuals.</span></blockquote><p><span>What Joy is pointing to is the idea that causing large-scale destruction requires both&nbsp;</span><i><em>motive&nbsp;</em></i><span>and&nbsp;</span><i><em>ability</em></i><span>, and as long as ability is restricted to a small set of highly trained people, there is relatively limited risk of single individuals (or small groups) causing such destruction.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:21"><sup><span>21</span></sup></a></p><p><span>&nbsp;A disturbed loner can perpetrate a school shooting, but probably can‚Äôt build a nuclear weapon or release a plague.</span></p><p><br /></p><p><span>In fact, ability and motive may even be&nbsp;</span><i><em>negatively</em></i><span>&nbsp;correlated. The kind of person who has the&nbsp;</span><i><em>ability&nbsp;</em></i><span>to release a plague is probably highly educated: likely a PhD in molecular biology, and a particularly resourceful one, with a promising career, a stable and disciplined personality, and a lot to lose. This kind of person is unlikely to be interested in killing a huge number of people for no benefit to themselves and at great risk to their own future‚Äîthey would need to be motivated by pure malice, intense grievance, or instability.</span></p><p><span>Such people do exist, but they are rare, and tend to become huge stories when they occur, precisely because they are so unusual.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:22"><sup><span>22</span></sup></a></p><p><span>&nbsp;They also tend to be difficult to catch because they are intelligent and capable, sometimes leaving mysteries that take years or decades to solve. The most famous example is probably mathematician&nbsp;</span><a href="https://en.wikipedia.org/wiki/Ted_Kaczynski"><span>Theodore Kaczynski</span></a><span>&nbsp;(the Unabomber), who evaded FBI capture for nearly 20 years, and was driven by an anti-technological ideology. Another example is biodefense researcher&nbsp;</span><a href="https://en.wikipedia.org/wiki/Bruce_Edwards_Ivins"><span>Bruce Ivins</span></a><span>, who seems to have orchestrated a series of anthrax attacks in 2001. It‚Äôs also happened with skilled non-state organizations: the cult Aum Shinrikyo managed to obtain sarin nerve gas and kill 14 people (as well as injuring hundreds more) by&nbsp;</span><a href="https://en.wikipedia.org/wiki/Tokyo_subway_sarin_attack"><span>releasing it in the Tokyo subway</span></a><span>&nbsp;in 1995.</span></p><p><br /></p><p><span>Thankfully, none of these attacks used contagious biological agents, because the ability to construct or obtain these agents was beyond the capabilities of even these people.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:23"><sup><span>23</span></sup></a></p><p><span>&nbsp;Advances in molecular biology have now significantly lowered the barrier to creating biological weapons (especially in terms of availability of materials), but it still takes an enormous amount of expertise in order to do so. I am concerned that a genius in everyone‚Äôs pocket could remove that barrier, essentially making everyone a PhD virologist who can be walked through the process of designing, synthesizing, and releasing a biological weapon step-by-step. Preventing the elicitation of this kind of information in the face of serious adversarial pressure‚Äîso-called ‚Äújailbreaks‚Äù‚Äîlikely demands layers of defenses beyond those ordinarily baked into training.</span></p><p><br /></p><p><span>Crucially, this will break the correlation between ability and motive: the disturbed loner who wants to kill people but lacks the discipline or skill to do so will now be elevated to the capability level of the PhD virologist, who is unlikely to have this motivation. This concern generalizes beyond biology (although I think biology is the scariest area) to any area where great destruction is possible but currently requires a high level of skill and discipline. To put it another way, renting a powerful AI gives intelligence to malicious (but otherwise average) people. I am worried there are potentially a large number of such people out there, and that if they have access to an easy way to kill millions of people, sooner or later one of them will do it. Additionally, those who&nbsp;</span><i><em>do&nbsp;</em></i><span>have expertise may be enabled to commit even larger-scale destruction than they could before.</span></p><p><span>Biology is by far the area I‚Äôm most worried about, because of its very large potential for destruction and the difficulty of defending against it, so I‚Äôll focus on biology in particular. But much of what I say here applies to other risks, like cyberattacks, chemical weapons, or nuclear technology.</span></p><p><span>I am not going to go into detail about how to make biological weapons, for reasons that should be obvious. But at a high level, I am concerned that LLMs are approaching (or may already have reached) the knowledge needed to create and release them end-to-end, and that their potential for destruction is very high. Some biological agents could cause millions of deaths if a determined effort was made to release them for maximum spread. However, this would still take a very high level of skill, including a number of very specific steps and procedures that are not widely known. My concern is not merely fixed or static knowledge. I am concerned that LLMs will be able to take someone of average knowledge and ability and walk them through a complex process that might otherwise go wrong or require debugging in an interactive way, similar to how tech support might help a non-technical person debug and fix complicated computer-related problems (although this would be a more extended process, probably lasting over weeks or months).</span></p><p><span>More capable LLMs (substantially beyond the power of today‚Äôs) might be capable of enabling even more frightening acts. In 2024, a group of prominent scientists&nbsp;</span><a href="https://www.science.org/doi/10.1126/science.ads9158"><span>wrote a letter</span></a><span>&nbsp;warning about the risks of researching, and potentially creating, a dangerous new type of organism: ‚Äúmirror life.‚Äù The DNA, RNA, ribosomes, and proteins that make up biological organisms all have the same chirality (also called ‚Äúhandedness‚Äù) that causes them to be not equivalent to a version of themselves reflected in the mirror (just as your right hand cannot be rotated in such a way as to be identical to your left). But the whole system of proteins binding to each other, the machinery of DNA synthesis and RNA translation and the construction and breakdown of proteins, all depends on this handedness. If scientists made versions of this biological material with the opposite handedness‚Äîand there are some potential advantages of these, such as medicines that last longer in the body‚Äîit could be extremely dangerous. This is because left-handed life, if it were made in the form of complete organisms capable of reproduction (which would be very difficult), would potentially be indigestible to any of the systems that break down biological material on earth‚Äîit would have a ‚Äúkey‚Äù that wouldn‚Äôt fit into the ‚Äúlock‚Äù of any existing enzyme. This would mean that it could proliferate in an uncontrollable way and crowd out all life on the planet, in the worst case even destroying all life on earth.</span></p><p><span>There is&nbsp;</span><a href="https://www.science.org/doi/10.1126/science.ads9158#elettersSection"><span>substantial scientific uncertainty</span></a><span>&nbsp;about both the creation and potential effects of mirror life. The 2024 letter accompanied&nbsp;</span><a href="https://purl.stanford.edu/cv716pj4036"><span>a report</span></a><span>&nbsp;that concluded that ‚Äúmirror bacteria could plausibly be created in the next one to few decades,‚Äù which is a wide range. But a sufficiently powerful AI model (to be clear, far more capable than any we have today) might be able to discover how to create it much more rapidly‚Äîand actually help someone do so.</span></p><p><span>My view is that even though these are obscure risks, and might seem unlikely, the magnitude of the consequences is so large that they should be taken seriously as a first-class risk of AI systems.</span></p><p><span>Skeptics have raised a number of objections to the seriousness of these biological risks from LLMs, which I disagree with but which are worth addressing. Most fall into the category of not appreciating the exponential trajectory that the technology is on. Back in 2023 when we&nbsp;</span><a href="https://www.judiciary.senate.gov/imo/media/doc/2023-07-26_-_testimony_-_amodei.pdf"><span>first started talking about biological risks from LLMs</span></a><span>, skeptics said that all the necessary information was available on Google and LLMs didn‚Äôt add anything beyond this. It was never true that Google could give you all the necessary information: genomes are freely available, but as I said above, certain key steps, as well as a huge amount of practical know-how. cannot be gotten in that way. But also, by the end of 2023 LLMs were clearly providing information beyond what Google could give for some steps of the process.</span></p><p><span>After this, skeptics retreated to the objection that LLMs weren‚Äôt&nbsp;</span><i><em>end-to-end</em></i><span>&nbsp;useful, and couldn‚Äôt help with bioweapons&nbsp;</span><i><em>acquisition</em></i><span>&nbsp;as opposed to just providing theoretical information. As of mid-2025, our measurements show that LLMs may already be&nbsp;</span><a href="https://red.anthropic.com/2025/biorisk/"><span>providing substantial uplift</span></a><span>&nbsp;in several relevant areas, perhaps doubling or tripling the likelihood of success. This led to us deciding that Claude Opus 4 (and the subsequent Sonnet </span><a href="https://4.5"><span>4.5</span></a><span>, Opus </span><a href="https://4.1"><span>4.1</span></a><span>, and Opus </span><a href="https://4.5"><span>4.5</span></a><span> models) needed to be released under our AI Safety Level 3 protections in our&nbsp;</span><a href="https://www.anthropic.com/rsp-updates"><span>Responsible Scaling Policy</span></a><span>&nbsp;framework, and to implementing safeguards against this risk (more on this later). We believe that models are likely now approaching the point where, without safeguards, they could be useful in enabling someone with a STEM degree but not specifically a biology degree to go through the whole process of producing a bioweapon.</span></p><p><span>Another objection is that there are other actions unrelated to AI that society can take to block the production of bioweapons. Most prominently, the gene synthesis industry makes biological specimens on demand, and there is no federal requirement that providers screen orders to make sure they do not contain pathogens. An&nbsp;</span><a href="https://drive.google.com/file/d/1hNUnU8i2yubt5uesmmV17aTJXhYYDgTY/edit"><span>MIT study</span></a><span>&nbsp;found that 36 out of 38 providers fulfilled an order containing the sequence of the 1918 flu. I am supportive of mandated gene synthesis screening that would make it harder for individuals to weaponize pathogens, in order to reduce both AI-driven biological risks and also biological risks in general. But this is not something we have today. It would also be only one tool in reducing risk; it is a complement to guardrails on AI systems, not a substitute.</span></p><p><span>The best objection is one that I‚Äôve rarely seen raised: that there is a gap between the models being useful in principle and the actual propensity of bad actors to use them. Most individual bad actors are disturbed individuals, so almost by definition their behavior is unpredictable and irrational‚Äîand it‚Äôs&nbsp;</span><i><em>these</em></i><span>&nbsp;bad actors, the unskilled ones, who might have stood to benefit the most from AI making it much easier to kill many people.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:24"><sup><span>24</span></sup></a></p><p><span>&nbsp;Just because a type of violent attack is possible, doesn‚Äôt mean someone will decide to do it. Perhaps biological attacks will be unappealing because they are reasonably likely to infect the perpetrator, they don‚Äôt cater to the military-style fantasies that many violent individuals or groups have, and it is hard to selectively target specific people. It could also be that going through a process that takes months, even if an AI walks you through it, involves an amount of patience that most disturbed individuals simply don‚Äôt have. We may simply get lucky and motive and ability don‚Äôt combine, in practice, in quite the right way.</span></p><p><br /></p><p><span>But this seems like very flimsy protection to rely on. The motives of disturbed loners can change for any reason or no reason, and in fact there are already instances of&nbsp;</span><a href="https://en.wikipedia.org/wiki/2025_Las_Vegas_Cybertruck_explosion"><span>LLMs being used in attacks</span></a><span>&nbsp;(just not with biology). The focus on disturbed loners also ignores ideologically motivated terrorists, who are often willing to expend large amounts of time and effort (for example, the 9/11 hijackers). Wanting to kill as many people as possible is a motive that will probably arise sooner or later, and it unfortunately suggests bioweapons as the method. Even if this motive is extremely rare, it only has to materialize once. And as biology advances (increasingly driven by AI itself), it may also become possible to carry out more selective attacks (for example, targeted against people with specific ancestries), which adds yet another, very chilling, possible motive.</span></p><p><span>I do not think biological attacks will necessarily be carried out the instant it becomes widely possible to do so‚Äîin fact, I would bet against that. But added up across millions of people and a few years of time, I think there is a serious risk of a major attack, and the consequences would be so severe (with casualties potentially in the millions or more) that I believe we have no choice but to take serious measures to prevent it.</span></p><h3><i><em>Defenses</em></i></h3><p><span>That brings us to how to defend against these risks. Here I see three things we can do. First, AI companies can put guardrails on their models to prevent them from helping to produce bioweapons. Anthropic is very actively doing this.&nbsp;</span><a href="https://www.anthropic.com/constitution"><span>Claude‚Äôs Constitution</span></a><span>, which mostly focuses on high-level principles and values, has a small number of specific hard-line prohibitions, and one of them relates to helping with the production of biological (or chemical, or nuclear, or radiological) weapons. But all models&nbsp;</span><a href="https://www.microsoft.com/en-us/security/blog/2024/06/04/ai-jailbreaks-what-they-are-and-how-they-can-be-mitigated/"><span>can be jailbroken</span></a><span>, and so as a second line of defense, we‚Äôve implemented (since mid-2025, when our tests showed our models were starting to get close to the threshold where they might begin to pose a risk) a classifier that specifically detects and blocks bioweapon-related outputs.&nbsp;</span><a href="https://www.anthropic.com/research/next-generation-constitutional-classifiers"><span>We regularly upgrade and improve these classifiers</span></a><span>, and have generally found them highly robust even against sophisticated adversarial attacks.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:25"><sup><span>25</span></sup></a></p><p><span>&nbsp;These classifiers increase the costs to serve our models measurably (in some models, they are close to 5% of total inference costs) and thus cut into our margins, but we feel that using them is the right thing to do.</span></p><p><br /></p><p><span>To their credit, some other AI companies&nbsp;</span><a href="https://arxiv.org/pdf/2504.01849"><span>have implemented classifiers as well</span></a><span>. But not every company has, and there is also nothing requiring companies to keep their classifiers. I am concerned that over time there may be a&nbsp;</span><a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma"><span>prisoner‚Äôs dilemma</span></a><span>&nbsp;where companies can defect and lower their costs by removing classifiers. This is once again a classic negative externalities problem that can‚Äôt be solved by the voluntary actions of Anthropic or any other single company alone.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:26"><sup><span>26</span></sup></a></p><p><span>&nbsp;Voluntary industry standards may help, as may third-party evaluations and verification of the type done by&nbsp;</span><a href="https://www.aisi.gov.uk/"><span>AI security</span></a><span>&nbsp;</span><a href="https://www.nist.gov/caisi"><span>institutes</span></a><span>&nbsp;and&nbsp;</span><a href="https://metr.org/"><span>third-party evaluators</span></a><span>.</span></p><p><br /></p><p><span>But ultimately defense may require government action, which is the second thing we can do. My views here are the same as they are for addressing autonomy risks: we should start with&nbsp;</span><a href="https://www.anthropic.com/news/the-need-for-transparency-in-frontier-ai"><span>transparency requirements</span></a><span>,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:27"><sup><span>27</span></sup></a></p><p><span>&nbsp;which help society measure, monitor, and collectively defend against risks without disrupting economic activity in a heavy-handed way. Then, if and when we reach clearer thresholds of risk, we can craft legislation that more precisely targets these risks and has a lower chance of collateral damage. In the particular case of bioweapons, I actually think that the time for such targeted legislation may be approaching soon‚ÄîAnthropic and other companies are learning more and more about the nature of biological risks and what is reasonable to require of companies in defending against them. Fully defending against these risks may require working internationally, even with geopolitical adversaries, but there is precedent in treaties prohibiting the development of biological weapons. I am generally a skeptic about most kinds of international cooperation on AI, but this may be one narrow area where there is some chance of achieving global restraint. Even dictatorships do not want massive bioterrorist attacks.</span></p><p><br /></p><p><span>Finally, the third countermeasure we can take is to try to develop defenses against biological attacks themselves. This could include monitoring and tracking for early detection, investments in air purification R&amp;D (such as&nbsp;</span><a href="https://worksinprogress.co/issue/the-death-rays-that-guard-life/"><span>far-UVC</span></a><span>&nbsp;disinfection), rapid vaccine development that can respond and adapt to an attack, better personal protective equipment (PPE),</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:28"><sup><span>28</span></sup></a></p><p><span>&nbsp;and treatments or vaccinations for some of the most likely biological agents.&nbsp;</span><a href="https://en.wikipedia.org/wiki/MRNA_vaccine"><span>mRNA vaccines</span></a><span>, which can be designed to respond to a particular virus or variant, are an early example of&nbsp;</span><a href="https://worksinprogress.co/issue/the-golden-age-of-vaccine-development/"><span>what is possible here</span></a><span>. Anthropic is excited to work with biotech and pharmaceutical companies on this problem. But unfortunately I think our expectations on the defensive side should be limited. There is an&nbsp;</span><a href="https://www.rand.org/pubs/perspectives/PEA4102-1.html"><span>asymmetry between attack and defense</span></a><span>&nbsp;in biology, because agents spread rapidly on their own, while defenses require detection, vaccination, and treatment to be organized across large numbers of people very quickly in response. Unless the response is lightning quick (which it rarely is), much of the damage will be done before a response is possible. It is conceivable that future technological improvements could shift this balance in favor of defense (and we should certainly&nbsp;</span><a href="https://www.nationalacademies.org/read/28868/chapter/1"><span>use AI to help develop such technological advances</span></a><span>), but until then, preventative safeguards will be our main line of defense.</span></p><p><br /></p><p><span>It‚Äôs worth a brief mention of cyberattacks here, since unlike biological attacks,&nbsp;</span><a href="https://www.anthropic.com/news/disrupting-AI-espionage"><span>AI-led cyberattacks have actually happened in the wild</span></a><span>, including at a large scale and for state-sponsored espionage. We expect these attacks to&nbsp;</span><a href="https://red.anthropic.com/2025/ai-for-cyber-defenders/"><span>become more capable</span></a><span>&nbsp;as models advance rapidly, until they are the main way in which cyberattacks are conducted. I expect AI-led cyberattacks to become a serious and unprecedented threat to the integrity of computer systems around the world, and Anthropic is working very hard to shut down these attacks and eventually reliably prevent them from happening. The reason I haven‚Äôt focused on cyber as much as biology is that (1) cyberattacks are much less likely to kill people, certainly not at the scale of biological attacks, and (2) the offense-defense balance may be more tractable in cyber, where there is at least some hope that defense could keep up with (and even ideally outpace) AI attack if we invest in it properly.</span></p><p><span>Although biology is currently the most serious vector of attack, there are many other vectors and it is possible that a more dangerous one may emerge. The general principle is that without countermeasures, AI is likely to continuously lower the barrier to destructive activity on a larger and larger scale, and humanity needs a serious response to this threat.</span></p><h2><span>3. The odious apparatus</span></h2><h3><i><em>Misuse for seizing power</em></i></h3><p><span>The previous section discussed the risk of individuals and small organizations co-opting a small subset of the ‚Äúcountry of geniuses in a datacenter‚Äù to cause large-scale destruction. But we should also worry‚Äîlikely substantially more so‚Äîabout misuse of AI for the purpose of&nbsp;</span><i><em>wielding or</em></i><span>&nbsp;</span><i><em>seizing power</em></i><span>, likely by larger and more established actors.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:29"><sup><span>29</span></sup></a></p><p><br /></p><p><span>In&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>, I discussed the possibility that authoritarian governments might use powerful AI to surveil or repress their citizens in ways that would be extremely difficult to reform or overthrow. Current autocracies are limited in how repressive they can be by the need to have humans carry out their orders, and humans often have limits in how inhumane they are willing to be. But AI-enabled autocracies would not have such limits.</span></p><p><span>Worse yet, countries could also use their advantage in AI to gain power over&nbsp;</span><i><em>other countries</em></i><span>. If the ‚Äúcountry of geniuses‚Äù as a whole was simply owned and controlled by a single (human) country‚Äôs military apparatus, and other countries did not have equivalent capabilities, it is hard to see how they could defend themselves: they would be outsmarted at every turn, similar to a war between humans and mice. Putting these two concerns together leads to the alarming possibility of a global totalitarian dictatorship. Obviously, it should be one of our highest priorities to prevent this outcome.</span></p><p><span>There are many ways in which AI could enable, entrench, or expand autocracy, but I‚Äôll list a few that I‚Äôm most worried about. Note that some of these applications have legitimate defensive uses, and I am not necessarily arguing against them in absolute terms; I am nevertheless worried that they structurally tend to favor autocracies:</span></p><ul><li><b><strong>Fully autonomous weapons.&nbsp;</strong></b><span>A swarm of millions or billions of fully automated armed drones, locally controlled by powerful AI and strategically coordinated across the world by an even more powerful AI, could be an unbeatable army, capable of both defeating any military in the world and suppressing dissent within a country by following around every citizen.&nbsp;</span><a href="https://www.hudson.org/missile-defense/impact-drones-battlefield-lessons-russian-ukraine-war-french-perspective-tsiporah-fried"><span>Developments in the Russia-Ukraine War</span></a><span>&nbsp;should alert us to the fact that drone warfare is already with us (though not fully autonomous yet, and a tiny fraction of what might be possible with powerful AI). R&amp;D from powerful AI could make the drones of one country far superior to those of others, speed up their manufacture, make them more resistant to electronic attacks, improve their maneuvering, and so on. Of course, these weapons also have legitimate uses in the defense of democracy: they have been key to defending Ukraine and would likely be key to defending Taiwan. But they are a dangerous weapon to wield: we should worry about them in the hands of autocracies, but also worry that because they are so powerful, with so little accountability, there is a greatly increased risk of democratic governments turning them against their own people to seize power.</span></li><li><b><strong>AI surveillance.&nbsp;</strong></b><span>Sufficiently powerful AI could likely be used to compromise any computer system in the world,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:30"><sup><span>30</span></sup></a><span>&nbsp;and could also use the access obtained in this way to read&nbsp;</span><i><em>and make sense of</em></i><span>&nbsp;all the world‚Äôs electronic communications (or even all the world‚Äôs in-person communications, if recording devices can be built or commandeered). It might be frighteningly plausible to simply generate a complete list of anyone who disagrees with the government on any number of issues, even if such disagreement isn‚Äôt explicit in anything they say or do. A powerful AI looking across billions of conversations from millions of people could gauge public sentiment, detect pockets of disloyalty forming, and stamp them out before they grow. This could lead to the imposition of a true panopticon on a scale that we don‚Äôt see today, even with the CCP.</span></li><li><b><strong>AI propaganda.&nbsp;</strong></b><span>Today‚Äôs phenomena of ‚Äú</span><a href="https://en.wikipedia.org/wiki/Chatbot_psychosis"><span>AI psychosis</span></a><span>‚Äù and ‚ÄúAI girlfriends‚Äù suggest that even at their current level of intelligence, AI models can have a powerful psychological influence on people. Much more powerful versions of these models, that were much more embedded in and aware of people‚Äôs daily lives and could model and influence them over months or years, would likely be capable of essentially brainwashing many (most?) people into any desired ideology or attitude, and could be employed by an unscrupulous leader to ensure loyalty and suppress dissent, even in the face of a level of repression that most populations would rebel against. Today people worry a lot about, for example, the potential&nbsp;</span><a href="https://networkcontagion.us/wp-content/uploads/NCRI-Report_-The-CCPs-Digital-Charm-Offensive.pdf"><span>influence of TikTok</span></a><span>&nbsp;as CCP propaganda directed at children. I worry about that too, but a personalized AI agent that gets to know you over years and uses its knowledge of you to shape all of your opinions would be dramatically more powerful than this.</span></li><li><b><strong>Strategic decision-making.&nbsp;</strong></b><span>A country of geniuses in a datacenter could be used to advise a country, group, or individual on geopolitical strategy, what we might call a ‚Äúvirtual Bismarck.‚Äù It could optimize the three strategies above for seizing power, plus probably develop many others that I haven‚Äôt thought of (but that a country of geniuses could). Diplomacy, military strategy, R&amp;D, economic strategy, and many other areas are all likely to be substantially increased in effectiveness by powerful AI. Many of these skills would be legitimately helpful for democracies‚Äîwe want democracies to have access to the best strategies for defending themselves against autocracies‚Äîbut the potential for misuse in&nbsp;</span><i><em>anyone‚Äôs&nbsp;</em></i><span>hands still remains.</span></li></ul><p><span>Having described&nbsp;</span><i><em>what&nbsp;</em></i><span>I am worried about, let‚Äôs move on to&nbsp;</span><i><em>who</em></i><span>. I am worried about entities who have the most access to AI, who are starting from a position of the most political power, or who have an existing history of repression. In order of severity, I am worried about:</span></p><ul><li><b><strong>The CCP.&nbsp;</strong></b><span>China is second only to the United States in AI capabilities, and is the country with the greatest likelihood of surpassing the United States in those capabilities. Their government is currently autocratic and operates a high-tech surveillance state. It has deployed AI-based surveillance already (including in the repression of&nbsp;</span><a href="https://en.wikipedia.org/wiki/Uyghurs"><span>Uyghurs</span></a><span>), and is believed to employ algorithmic propaganda via TikTok (in addition to its many other international propaganda efforts). They have hands down the clearest path to the AI-enabled totalitarian nightmare I laid out above. It may even be the default outcome within China, as well as within other autocratic states to whom the CCP exports surveillance technology. I have&nbsp;</span><a href="https://www.darioamodei.com/post/on-deepseek-and-export-controls"><span>written often</span></a><span>&nbsp;about the threat of the CCP taking the lead in AI and the existential imperative to prevent them from doing so. This is why. To be clear, I am not singling out China out of animus to them in particular‚Äîthey are simply the country that most combines AI prowess, an autocratic government, and a high-tech surveillance state. If anything, it is the Chinese people themselves who are most likely to suffer from the CCP‚Äôs AI-enabled repression, and they have no voice in the actions of their government. I greatly admire and respect the Chinese people and support the many brave dissidents within China and their struggle for freedom.</span></li><li><b><strong>Democracies competitive in AI.&nbsp;</strong></b><span>As I wrote above, democracies have a legitimate interest in some AI-powered military and geopolitical tools, because democratic governments offer the best chance to counter the use of these tools by autocracies. Broadly, I am supportive of arming democracies with the tools needed to defeat autocracies in the age of AI‚ÄîI simply don‚Äôt think there is any other way. But we cannot ignore the potential for abuse of these technologies by democratic governments themselves. Democracies normally have safeguards that prevent their military and intelligence apparatus from being turned inwards against their own population,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:31"><sup><span>31</span></sup></a><span>&nbsp;but because AI tools require so few people to operate, there is potential for them to circumvent these safeguards and the norms that support them. It is also worth noting that some of these safeguards are already gradually eroding in some democracies. Thus, we should arm democracies with AI, but we should do so carefully and within limits: they are the immune system we need to fight autocracies, but like the immune system, there is some risk of them turning on us and becoming a threat themselves.</span></li><li><b><strong>Non-democratic countries with large datacenters.&nbsp;</strong></b><span>Beyond China, most countries with less democratic governance are not leading AI players in the sense that they don‚Äôt have companies which produce frontier AI models. Thus they pose a fundamentally different and lesser risk than the CCP, which remains the primary concern (most are also less repressive, and the ones that are more repressive, like North Korea, have no significant AI industry at all). But some of these countries do have large&nbsp;</span><i><em>datacenters&nbsp;</em></i><span>(often as part of buildouts by companies operating in democracies), which can be used to run frontier AI at large scale (though this does not confer the ability to push the frontier). There is some amount of danger associated with this‚Äîthese governments could in principle expropriate the datacenters and use the country of AIs within it for their own ends. I am less worried about this compared to countries like China that directly develop AI, but it‚Äôs a risk to keep in mind.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:32"><sup><span>32</span></sup></a></li><li><b><strong>AI companies.&nbsp;</strong></b><span>It is somewhat awkward to say this as the CEO of an AI company, but I think the next tier of risk is actually AI companies themselves. AI companies control large datacenters, train frontier models, have the greatest expertise on how to use those models, and in some cases have daily contact with and the possibility of influence over tens or hundreds of millions of users. The main thing they lack is the legitimacy and infrastructure of a state, so much of what would be needed to build the tools of an AI autocracy would be illegal for an AI company to do, or at least exceedingly suspicious. But some of it is not impossible: they could, for example, use their AI products to brainwash their massive consumer user base, and the public should be alert to the risk this represents. I think the governance of AI companies deserves a lot of scrutiny.</span></li></ul><p><span>There are a number of possible arguments against the severity of these threats, and I wish I believed them, because AI-enabled authoritarianism terrifies me. It‚Äôs worth going through some of these arguments and responding to them.</span></p><p><span>First, some people might put their faith in the nuclear deterrent, particularly to counter the use of AI autonomous weapons for military conquest. If someone threatens to use these weapons against you, you can always threaten a nuclear response back. My worry is that I‚Äôm&nbsp;</span><a href="https://futureoflife.org/document/ai-and-nuclear-problem-analysis-and-policy-recommendations/"><span>not totally sure we can be confident</span></a><span>&nbsp;in the nuclear deterrent against a country of geniuses in a datacenter: it is possible that powerful AI could&nbsp;</span><a href="https://www.rand.org/content/dam/rand/pubs/perspectives/PE200/PE296/RAND_PE296.pdf"><span>devise ways</span></a><span>&nbsp;to&nbsp;</span><a href="https://spectrum.ieee.org/nuclear-submarine"><span>detect and strike nuclear submarines</span></a><span>,&nbsp;</span><a href="https://www.sipri.org/sites/default/files/2019-05/sipri1905-ai-strategic-stability-nuclear-risk.pdf"><span>conduct influence operations</span></a><span>&nbsp;against the operators of nuclear weapons infrastructure, or use AI‚Äôs&nbsp;</span><a href="https://committees.parliament.uk/writtenevidence/120293/pdf/"><span>cyber capabilities</span></a><span>&nbsp;to launch a cyberattack against satellites used to detect nuclear launches.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:33"><sup><span>33</span></sup></a></p><p><span>&nbsp;Alternatively, it‚Äôs possible that taking over countries is feasible with only AI surveillance and AI propaganda, and never actually presents a clear moment where it‚Äôs obvious what is going on and where a nuclear response would be appropriate.&nbsp;</span><i><em>Maybe&nbsp;</em></i><span>these things aren‚Äôt feasible and the nuclear deterrent will still be effective, but it seems too high stakes to take a risk.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:34"><sup><span>34</span></sup></a></p><p><br /></p><p><span>A second possible objection is that there might be countermeasures we can take against these tools of autocracy. We can counter drones with our own drones, cyberdefense will improve along with cyberattack, there may be ways to immunize people against propaganda, etc. My response is that these defenses will only be possible with comparably powerful AI. If there isn‚Äôt some counterforce with a comparably smart and numerous country of geniuses in a datacenter, it won‚Äôt be possible to match the quality or quantity of drones, for cyberdefense to outsmart cyberoffense, etc. So the question of countermeasures reduces to the question of a balance of power in powerful AI. Here, I am concerned about the recursive or self-reinforcing property of powerful AI (which I discussed at the beginning of this essay): that each generation of AI can be used to design and train the next generation of AI. This leads to a risk of a runaway advantage, where the current leader in powerful AI may be able to increase their lead and may be difficult to catch up with. We need to make sure it is not an authoritarian country that gets to this loop first.</span></p><p><span>Furthermore, even if a balance of power can be achieved, there is still risk that the world could be split up into autocratic spheres, as in&nbsp;</span><i><em>Nineteen Eighty-Four</em></i><span>. Even if several competing powers each have their powerful AI models, and none can overpower the others, each power could still internally repress their own population, and would be very difficult to overthrow (since the populations don‚Äôt have powerful AI to defend themselves). It is thus important to prevent AI-enabled autocracy even if it doesn‚Äôt lead to a single country taking over the world.</span></p><h3><i><em>Defenses</em></i></h3><p><span>How do we defend against this wide range of autocratic tools and potential threat actors? As in the previous sections, there are several things I think we can do. First, we should absolutely not be selling chips, chip-making tools, or datacenters to the CCP. Chips and chip-making tools are the single greatest bottleneck to powerful AI, and blocking them is a simple but extremely effective measure, perhaps the most important single action we can take. It makes no sense to sell the CCP the tools with which to build an AI totalitarian state and possibly conquer us militarily. A number of complicated arguments are made to justify such sales, such as the idea that ‚Äúspreading our tech stack around the world‚Äù allows ‚ÄúAmerica to win‚Äù in some general, unspecified economic battle. In my view, this is like selling nuclear weapons to North Korea and then bragging that the missile casings are made by Boeing and so the US is ‚Äúwinning.‚Äù China is several years behind the US in their ability to produce frontier chips in quantity, and the critical period for building the country of geniuses in a datacenter is very likely to be within those next several years.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:35"><sup><span>35</span></sup></a></p><p><span>&nbsp;There is no reason to give a giant boost to their AI industry during this critical period.</span></p><p><br /></p><p><span>Second, it makes sense to use AI to empower democracies to resist autocracies. This is the reason Anthropic considers it important to provide AI to the intelligence and defense communities in the US and its democratic allies. Defending democracies that are under attack, such as Ukraine and (via cyber attacks) Taiwan, seems especially high priority, as does empowering democracies to use their intelligence services to disrupt and degrade autocracies from the inside. At some level the only way to respond to autocratic threats is to match and outclass them militarily. A coalition of the US and its democratic allies, if it achieved predominance in powerful AI, would be in a position to not only defend itself against autocracies, but contain them and limit their AI totalitarian abuses.</span></p><p><span>Third, we need to draw a hard line against AI abuses within democracies. There need to be limits to what we allow our governments to do with AI, so that they don‚Äôt seize power or repress their own people. The formulation I have come up with is that we should use AI for national defense in all ways&nbsp;</span><i><em>except those which would make us more like our autocratic adversaries</em></i><span>.</span></p><p><span>Where should the line be drawn? In the list at the beginning of this section, two items‚Äîusing AI for domestic mass surveillance and mass propaganda‚Äîseem to me like bright red lines and entirely illegitimate. Some might argue that there‚Äôs no need to do anything (at least in the US), since domestic mass surveillance is already illegal under the Fourth Amendment. But the rapid progress of AI may create situations that our existing legal frameworks are not well designed to deal with. For example, it would likely not be unconstitutional for the US government to conduct massively scaled recordings of all&nbsp;</span><i><em>public&nbsp;</em></i><span>conversations (e.g., things people say to each other on a street corner), and previously it would have been difficult to sort through this volume of information, but with AI it could all be transcribed, interpreted, and triangulated to create a picture of the attitude and loyalties of many or most citizens. I would support civil liberties-focused legislation (or maybe even a constitutional amendment) that imposes stronger guardrails against AI-powered abuses.</span></p><p><span>The other two items‚Äîfully autonomous weapons and AI for strategic decision-making‚Äîare harder lines to draw since they have legitimate uses in defending democracy, while also being prone to abuse. Here I think what is warranted is extreme care and scrutiny combined with guardrails to prevent abuses. My main fear is having too small a number of ‚Äúfingers on the button,‚Äù such that one or a handful of people could essentially operate a drone army without needing any other humans to cooperate to carry out their orders. As AI systems get more powerful, we may need to have more direct and immediate oversight mechanisms to ensure they are not misused, perhaps involving branches of government other than the executive. I think we should approach fully autonomous weapons in particular with great caution,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:36"><sup><span>36</span></sup></a></p><p><span>&nbsp;and not rush into their use without proper safeguards.</span></p><p><br /></p><p><span>Fourth, after drawing a hard line against AI abuses in democracies, we should use that precedent to create an international taboo against the worst abuses of powerful AI. I recognize that the current political winds have turned against international cooperation and international norms, but this is a case where we sorely need them. The world needs to understand the dark potential of powerful AI in the hands of autocrats, and to recognize that certain uses of AI amount to an attempt to permanently steal their freedom and impose a totalitarian state from which they can‚Äôt escape. I would even argue that in some cases, large-scale surveillance with powerful AI, mass propaganda with powerful AI, and certain types of&nbsp;</span><i><em>offensive&nbsp;</em></i><span>uses of fully autonomous weapons should be considered crimes against humanity. More generally, a robust norm against AI-enabled totalitarianism and all its tools and instruments is sorely needed.</span></p><p><span>It is possible to have an even stronger version of this position, which is that because the possibilities of AI-enabled totalitarianism are so dark, autocracy is simply not a form of government that people can accept in the post-powerful AI age. Just as feudalism became unworkable with the industrial revolution, the AI age could lead inevitably and logically to the conclusion that democracy (and, hopefully, democracy improved and reinvigorated by AI, as I discuss in&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>) is the only viable form of government if humanity is to have a good future.</span></p><p><span>Fifth and finally, AI companies should be carefully watched, as should their connection to the government, which is necessary, but must have limits and boundaries. The sheer amount of capability embodied in powerful AI is such that ordinary corporate governance‚Äîwhich is designed to protect shareholders and prevent ordinary abuses such as fraud‚Äîis unlikely to be up to the task of governing AI companies. There may also be value in companies publicly committing to (perhaps even as part of corporate governance) not take certain actions, such as privately building or stockpiling military hardware, using large amounts of computing resources by single individuals in unaccountable ways, or using their AI products as propaganda to manipulate public opinion in their favor.</span></p><p><span>The danger here comes from many directions, and some directions are in tension with others. The only constant is that we must seek accountability, norms, and guardrails for everyone, even as we empower ‚Äúgood‚Äù actors to keep ‚Äúbad‚Äù actors in check.</span></p><h2><span>4. Player piano</span></h2><h3><i><em>Economic disruption</em></i></h3><p><span>The previous three sections were essentially about security risks posed by powerful AI: risks from the AI itself, risks from misuse by individuals and small organizations and risks of misuse by states and large organizations. If we put aside security risks or assume they have been solved, the next question is economic. What will be the effect of this infusion of incredible ‚Äúhuman‚Äù capital on the economy? Clearly, the most obvious effect will be to greatly increase economic growth. The pace of advances in scientific research, biomedical innovation, manufacturing, supply chains, the efficiency of the financial system, and much more are almost guaranteed to lead to a much faster rate of economic growth. In&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>, I suggest that a 10‚Äì20% sustained annual GDP growth rate may be possible.</span></p><p><span>But it should be clear that this is a double-edged sword: what are the economic prospects for most existing humans in such a world? New technologies often bring labor market shocks, and in the past humans have always recovered from them, but I am concerned that this is because these previous shocks affected only a small fraction of the full possible range of human abilities, leaving room for humans to expand to new tasks. AI will have effects that are much broader and occur much faster, and therefore I worry it will be much more challenging to make things work out well.</span></p><h3><i><em>Labor market disruption</em></i></h3><p><span>There are two specific problems I am worried about: labor market displacement, and concentration of economic power. Let‚Äôs start with the first one. This is a topic that I&nbsp;</span><a href="https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic"><span>warned about very publicly in 2025</span></a><span>, where I predicted that AI could displace half of all entry-level white collar jobs in the next 1‚Äì5 years, even as it accelerates economic growth and scientific progress. This warning started a public debate about the topic. Many CEOs, technologists, and economists agreed with me, but others assumed I was falling prey to a ‚Äúlump of labor‚Äù fallacy and didn‚Äôt know how labor markets worked, and some didn‚Äôt see the 1‚Äì5-year time range and thought I was claiming AI is displacing jobs right now (which I agree it is likely not). So it is worth going through in detail why I am worried about labor displacement, to clear up these misunderstandings.</span></p><p><span>As a baseline, it‚Äôs useful to understand how labor markets&nbsp;</span><i><em>normally</em></i><span>&nbsp;respond to advances in technology. When a new technology comes along, it starts by making pieces of a given human job more efficient. For example, early in the Industrial Revolution, machines, such as upgraded plows, enabled human farmers to be more efficient at some aspects of the job. This improved the productivity of farmers, which increased their wages.</span></p><p><span>In the next step, some parts of the job of farming could be done&nbsp;</span><i><em>entirely</em></i><span>&nbsp;by machines, for example with the invention of the&nbsp;</span><a href="https://en.wikipedia.org/wiki/Threshing_machine"><span>threshing machine</span></a><span>&nbsp;or&nbsp;</span><a href="https://en.wikipedia.org/wiki/Seed_drill"><span>seed drill</span></a><span>. In this phase, humans did a lower and lower fraction of the job, but the work they&nbsp;</span><i><em>did</em></i><span>&nbsp;complete became more and more leveraged because it is complementary to the work of machines, and their productivity continued to rise. As described by&nbsp;</span><a href="https://en.wikipedia.org/wiki/Jevons_paradox"><span>Jevons‚Äô paradox</span></a><span>, the wages of farmers and perhaps even the number of farmers continued to increase. Even when 90% of the job is being done by machines, humans can simply do 10x more of the 10% they still do, producing 10x as much output for the same amount of labor.</span></p><p><span>Eventually, machines do everything or almost everything, as with modern&nbsp;</span><a href="https://en.wikipedia.org/wiki/Combine_harvester"><span>combine harvesters</span></a><span>, tractors, and other equipment. At this point farming as a form of human employment really does go into steep decline, and this potentially causes serious disruption in the short term, but because farming is just one of many useful activities that humans are able to do, people eventually switch to other jobs, such as operating factory machines. This is true even though farming accounted for a huge proportion of employment&nbsp;</span><i><em>ex ante</em></i><span>. 250 years ago, 90% of Americans&nbsp;</span><a href="https://www.nass.usda.gov/About_NASS/History_of_Ag_Statistics/index.php"><span>lived on farms</span></a><span>; in Europe, 50‚Äì60% of employment&nbsp;</span><a href="https://ourworldindata.org/grapher/share-of-the-labor-force-employed-in-agriculture?time=1750..latest"><span>was agricultural</span></a><span>. Now those percentages are in the low single digits in those places, because workers switched to industrial jobs (and later, knowledge work jobs). The economy can do what previously required most of the labor force with only 1‚Äì2% of it, freeing up the rest of the labor force to build an ever more advanced industrial society. There‚Äôs no fixed ‚Äú</span><a href="https://en.wikipedia.org/wiki/Lump_of_labour_fallacy"><span>lump of labor</span></a><span>,‚Äù just an ever-expanding ability to do&nbsp;</span><a href="https://en.wikipedia.org/wiki/Ephemeralization"><span>more and more with less and less</span></a><span>. People‚Äôs wages rise in line with the GDP exponential and the economy maintains full employment once disruptions in the short term have passed.</span></p><p><span>It‚Äôs possible things will go roughly the same way with AI, but I would bet pretty strongly against it. Here are some reasons I think AI is likely to be different:</span></p><ul><li><b><strong>Speed.&nbsp;</strong></b><span>The pace of progress in AI is much faster than for previous technological revolutions. For example, in the last 2 years, AI models went from barely being able to complete a single line of code, to&nbsp;</span><a href="https://x.com/bcherny/status/2004887829252317325"><span>writing all or almost all of the code</span></a><span>&nbsp;for some people‚Äîincluding engineers at Anthropic.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:37"><sup><span>37</span></sup></a><span>&nbsp;Soon, they may do the entire task of a software engineer end to end.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:38"><sup><span>38</span></sup></a><span>&nbsp;It is hard for people to adapt to this pace of change, both to the changes in how a given job works and in the need to switch to new jobs. Even legendary programmers are increasingly&nbsp;</span><a href="https://x.com/karpathy/status/2004607146781278521"><span>describing themselves as ‚Äúbehind.‚Äù</span></a><span>&nbsp;The pace may if anything continue to speed up, as AI coding models increasingly accelerate the task of AI development. To be clear, speed in itself does not mean labor markets and employment won‚Äôt eventually recover, it just implies the short-term transition will be unusually painful compared to past technologies, since humans and labor markets are slow to react and to equilibrate.</span></li><li><b><strong>Cognitive breadth.&nbsp;</strong></b><span>As suggested by the phrase ‚Äúcountry of geniuses in a datacenter,‚Äù AI will be capable of a very wide range of human cognitive abilities‚Äîperhaps all of them. This is very different from previous technologies like mechanized farming, transportation, or even computers.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:39"><sup><span>39</span></sup></a><span>&nbsp;This will make it harder for people to switch easily from jobs that are displaced to similar jobs that they would be a good fit for. For example, the general intellectual abilities required for entry-level jobs in, say, finance, consulting, and law are fairly similar, even if the specific knowledge is quite different. A technology that disrupted only one of these three would allow employees to switch to the two other close substitutes (or for undergraduates to switch majors). But disrupting all three at once (along with many other similar jobs) may be harder for people to adapt to. Furthermore, it‚Äôs not&nbsp;</span><i><em>just&nbsp;</em></i><span>that most existing jobs will be disrupted. That part has happened before‚Äîrecall that farming was a huge percentage of employment. But farmers could switch to the relatively similar work of operating factory machines, even though that work hadn‚Äôt been common before. By contrast, AI is increasingly matching the general cognitive profile of humans, which means it will also be good at the new jobs that would ordinarily be created in response to the old ones being automated. Another way to say it is that AI isn‚Äôt a substitute for specific human jobs but rather a general labor substitute for humans.</span></li><li><b><strong>Slicing by cognitive ability.&nbsp;</strong></b><span>Across a wide range of tasks, AI appears to be advancing from the bottom of the ability ladder to the top. For example, in coding our models have proceeded from the level of ‚Äúa mediocre coder‚Äù to ‚Äúa strong coder‚Äù to ‚Äúa very strong coder.‚Äù</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:40"><sup><span>40</span></sup></a><span>&nbsp;We are now starting to see the same progression in white-collar work in general. We are thus at risk of a situation where, instead of affecting people with specific skills or in specific professions (who can adapt by retraining), AI is affecting people with certain intrinsic cognitive properties, namely lower intellectual ability (which is harder to change). It is not clear where these people will go or what they will do, and I am concerned that they could form an unemployed or very-low-wage ‚Äúunderclass.‚Äù To be clear, things somewhat like this have happened before‚Äîfor example, computers and the internet are believed by some economists to represent ‚Äú</span><a href="https://www.sciencedirect.com/science/chapter/handbook/abs/pii/S0169721811024105"><span>skill-biased technological change</span></a><span>.‚Äù But this skill biasing was both not as extreme as what I expect to see with AI, and is believed to have contributed to an increase in wage inequality,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:41"><sup><span>41</span></sup></a><span>&nbsp;so it is not exactly a reassuring precedent.</span></li><li><b><strong>Ability to fill in the gaps.&nbsp;</strong></b><span>The way human jobs often adjust in the face of new technology is that there are many aspects to the job, and the new technology, even if it appears to directly replace humans, often has gaps in it. If someone invents a machine to make widgets, humans may still have to load raw material into the machine. Even if that takes only 1% as much effort as making the widgets manually, human workers can simply make 100x more widgets. But AI, in addition to being a rapidly advancing technology, is also a rapidly&nbsp;</span><i><em>adapting&nbsp;</em></i><span>technology. During every model release, AI companies carefully measure what the model is good at and what it isn‚Äôt, and customers also provide such information after the launch. Weaknesses can be addressed by collecting tasks that embody the current gap, and training on them for the next model. Early in generative AI, users noticed that AI systems had certain weaknesses (such as AI image models generating hands with the wrong number of fingers) and many assumed these weaknesses were inherent to the technology. If they were, it would limit job disruption. But pretty much every such weakness gets addressed quickly‚Äî often, within just a few months.</span></li></ul><p><span>It‚Äôs worth addressing common points of skepticism. First, there is the argument that economic diffusion will be slow, such that even if the underlying technology is&nbsp;</span><i><em>capable&nbsp;</em></i><span>of doing most human labor, the actual application of it across the economy may be much slower (for example in industries that are far from the AI industry and slow to adopt). Slow diffusion of technology is&nbsp;</span><a href="https://www.ft.com/content/3b93e647-2a8b-4fb4-831d-e27adf4db5f8"><span>definitely real</span></a><span>‚ÄîI talk to people from a wide variety of enterprises, and there are places where the adoption of AI will take years. That‚Äôs why my prediction for 50% of entry level white collar jobs being disrupted is 1‚Äì5 years, even though I suspect we‚Äôll have powerful AI (which would be, technologically speaking, enough to do&nbsp;</span><i><em>most or all&nbsp;</em></i><span>jobs, not just entry level) in much less than 5 years. But diffusion effects merely buy us time. And I am not confident they will be as slow as people predict. Enterprise AI adoption is growing at rates much faster than any previous technology, largely on the pure strength of the technology itself. Also, even if traditional enterprises are slow to adopt new technology, startups will spring up to serve as ‚Äúglue‚Äù and make the adoption easier. If that doesn‚Äôt work, the startups may simply disrupt the incumbents directly.</span></p><p><span>That could lead to a world where it isn‚Äôt so much that specific jobs are disrupted as it is that large enterprises are disrupted in general and replaced with much less labor-intensive startups. This could also lead to a world of ‚Äúgeographic inequality,‚Äù where an increasing fraction of the world‚Äôs wealth is concentrated in Silicon Valley, which becomes its own economy running at a different speed than the rest of the world and leaving it behind. All of these outcomes would be great for economic growth‚Äîbut not so great for the labor market or those who are left behind.</span></p><p><span>Second, some people say that human jobs will move to the physical world, which avoids the whole category of ‚Äúcognitive labor‚Äù where AI is progressing so rapidly. I am not sure how safe this is, either. A lot of physical labor is already being done by machines (e.g., manufacturing) or will soon be done by machines (e.g., driving). Also, sufficiently powerful AI will be able to accelerate the development of robots, and then control those robots in the physical world. It may buy some time (which is a good thing), but I‚Äôm worried it won‚Äôt buy much. And even if the disruption was limited only to cognitive tasks, it would still be an unprecedentedly large and rapid disruption.</span></p><p><span>Third, perhaps some tasks inherently require or greatly benefit from a human touch. I‚Äôm a little more uncertain about this one, but I‚Äôm still skeptical that it will be enough to offset the bulk of the impacts I described above. AI is already widely used for customer service. Many people&nbsp;</span><a href="https://undark.org/2025/11/04/chatbot-mental-health/"><span>report</span></a><span>&nbsp;that it is easier to talk to AI about their personal problems than to talk to a therapist‚Äîthat the AI is more patient. When my sister was struggling with medical problems during a pregnancy, she felt she wasn‚Äôt getting the answers or support she needed from her care providers, and she found Claude to have a better bedside manner (as well as succeeding better at diagnosing the problem). I‚Äôm sure there are some tasks for which a human touch really is important, but I‚Äôm not sure how many‚Äîand here we‚Äôre talking about finding work for nearly everyone in the labor market.</span></p><p><span>Fourth, some may argue that comparative advantage will still protect humans. Under the&nbsp;</span><a href="https://en.wikipedia.org/wiki/Comparative_advantage"><span>law of comparative advantage</span></a><span>, even if AI is better than humans at everything, any&nbsp;</span><i><em>relative&nbsp;</em></i><span>differences between the human and AI profile of skills creates a basis of trade and specialization between humans and AI. The problem is that if AIs are literally thousands of times more productive than humans, this logic starts to break down. Even tiny&nbsp;</span><a href="https://en.wikipedia.org/wiki/Transaction_cost"><span>transaction costs</span></a><span>&nbsp;could make it not worth it for AI to trade with humans. And human wages may be very low, even if they technically have something to offer.</span></p><p><span>It‚Äôs possible all of these factors can be addressed‚Äîthat the labor market is resilient enough to adapt to even such an enormous disruption. But even if it can eventually adapt, the factors above suggest that the short-term shock will be unprecedented in size.</span></p><h3><i><em>Defenses</em></i></h3><p><span>What can we do about this problem? I have several suggestions, some of which Anthropic is already doing. The first thing is simply to get accurate data about what is happening with job displacement in real time. When an economic change happens very quickly, it‚Äôs hard to get reliable data about what is happening, and without reliable data it is hard to design effective policies. For example, government data is currently lacking granular, high-frequency data on AI adoption across firms and industries. For the last year Anthropic has been operating and publicly releasing an&nbsp;</span><a href="https://www.anthropic.com/economic-index"><span>Economic Index</span></a><span>&nbsp;that shows use of our models almost in real time, broken down by industry, task, location, and even things like whether a task was being automated or conducted collaboratively. We also have an&nbsp;</span><a href="https://www.anthropic.com/news/introducing-the-anthropic-economic-advisory-council"><span>Economic Advisory Council</span></a><span>&nbsp;to help us interpret this data and see what is coming.</span></p><p><span>Second, AI companies have a choice in how they work with enterprises. The very inefficiency of traditional enterprises means that their rollout of AI can be very path dependent, and there is some room to choose a better path. Enterprises often have a choice between ‚Äúcost savings‚Äù (doing the same thing with fewer people) and ‚Äúinnovation‚Äù (doing more with the same number of people). The market will inevitably produce both eventually, and any competitive AI company will have to serve some of both, but there may be some room to steer companies towards innovation when possible, and it may buy us some time. Anthropic is actively thinking about this.</span></p><p><span>Third, companies should think about how to take care of their employees. In the short term, being creative about ways to reassign employees within companies may be a promising way to stave off the need for layoffs. In the long term, in a world with enormous total wealth, in which many companies increase greatly in value due to increased productivity and capital concentration, it may be feasible to pay human employees even long after they are no longer providing economic value in the traditional sense. Anthropic is currently considering a range of possible pathways for our own employees that we will share in the near future.</span></p><p><span>Fourth, wealthy individuals have an obligation to help solve this problem. It is sad to me that many wealthy individuals (especially in the tech industry) have recently adopted a cynical and nihilistic attitude that philanthropy is inevitably fraudulent or useless. Both private philanthropy like the&nbsp;</span><a href="https://www.gatesfoundation.org/"><span>Gates Foundation</span></a><span>&nbsp;and public programs like&nbsp;</span><a href="https://en.wikipedia.org/wiki/President%27s_Emergency_Plan_for_AIDS_Relief"><span>PEPFAR</span></a><span>&nbsp;have saved tens of millions of lives in the developing world, and helped to create economic opportunity in the developed world. All of Anthropic‚Äôs co-founders have pledged to donate 80% of our wealth, and Anthropic‚Äôs staff have individually pledged to donate company shares worth billions at current prices‚Äîdonations that the company has committed to matching.</span></p><p><span>Fifth, while all the above private actions can be helpful, ultimately a macroeconomic problem this large will require government intervention. The natural policy response to an enormous economic pie coupled with high inequality (due to a lack of jobs, or poorly paid jobs, for many) is progressive taxation. The tax could be general or could be targeted against AI companies in particular. Obviously tax design is complicated, and there are many ways for it to go wrong. I don‚Äôt support poorly designed tax policies. I think the extreme levels of inequality predicted in this essay justify a more robust tax policy on basic moral grounds, but I can also make a pragmatic argument to the world‚Äôs billionaires that it‚Äôs in their interest to support a good version of it: if they don‚Äôt support a good version, they‚Äôll inevitably get a bad version designed by a mob.</span></p><p><span>Ultimately, I think of all of the above interventions as ways to buy time. In the end AI will be able to do everything, and we need to grapple with that. It‚Äôs my hope that by that time, we can use AI itself to help us restructure markets in ways that work for everyone, and that the interventions above can get us through the transitional period.</span></p><h3><i><em>Economic concentration of power</em></i></h3><p><span>Separate from the problem of job displacement or economic inequality&nbsp;</span><i><em>per se</em></i><span>&nbsp;is the problem of&nbsp;</span><i><em>economic concentration of power.</em></i><span>&nbsp;Section 1 discussed the risk that humanity gets disempowered by AI, and Section 3 discussed the risk that citizens get disempowered by their governments by force or coercion. But another kind of disempowerment can occur if there is such a huge concentration of wealth that a small group of people effectively controls government policy with their influence, and ordinary citizens have no influence because they lack economic leverage. Democracy is ultimately backstopped by the idea that the population as a whole is necessary for the operation of the economy. If that economic leverage goes away, then the implicit social contract of democracy may stop working.&nbsp;</span><a href="https://intelligence-curse.ai/"><span>Others have written about this</span></a><span>, so I needn‚Äôt go into great detail about it here, but I agree with the concern, and I worry it is already starting to happen.</span></p><p><span>To be clear, I am not opposed to people making a lot of money. There‚Äôs a strong argument that it incentivizes economic growth under normal conditions. I am sympathetic to concerns about impeding innovation by killing the golden goose that generates it. But in a scenario where GDP growth is 10‚Äì20% a year and AI is rapidly taking over the economy, yet single individuals hold appreciable fractions of the GDP, innovation is&nbsp;</span><i><em>not&nbsp;</em></i><span>the thing to worry about. The thing to worry about is a level of wealth concentration that will break society.</span></p><p><span>The most famous example of extreme concentration of wealth in US history is the&nbsp;</span><a href="https://en.wikipedia.org/wiki/Gilded_Age"><span>Gilded Age</span></a><span>, and the wealthiest industrialist of the Gilded Age was&nbsp;</span><a href="https://en.wikipedia.org/wiki/John_D._Rockefeller"><span>John D. Rockefeller</span></a><span>. Rockefeller‚Äôs wealth amounted to ~2% of the US GDP at the time.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:42"><sup><span>42</span></sup></a></p><p><span>&nbsp;A similar fraction today would lead to a fortune of $600B, and the richest person in the world today (Elon Musk) already exceeds that, at&nbsp;</span><a href="https://www.reuters.com/business/autos-transportation/elon-musk-becomes-first-person-worth-700-billion-after-court-ruling-pay-package-2025-12-20/"><span>roughly $700B</span></a><span>. So we are already at historically unprecedented levels of wealth concentration, even&nbsp;</span><i><em>before&nbsp;</em></i><span>most of the economic impact of AI. I don‚Äôt think it is too much of a stretch (if we get a ‚Äúcountry of geniuses‚Äù) to imagine AI companies, semiconductor companies, and perhaps downstream application companies generating ~$3T in revenue per year,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:43"><sup><span>43</span></sup></a><span>&nbsp;being valued at ~$30T, and leading to personal fortunes well into the trillions. In that world, the debates we have about tax policy today simply won‚Äôt apply as we will be in a fundamentally different situation.</span></p><p><br /></p><p><span>Related to this, the coupling of this economic concentration of wealth with the political system already concerns me. AI datacenters already represent a substantial fraction of US economic growth,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:44"><sup><span>44</span></sup></a></p><p><span>&nbsp;and are thus strongly tying together the financial interests of large tech companies (which are increasingly focused on either AI or AI infrastructure) and the political interests of the government in a way that can produce perverse incentives. We already see this through the reluctance of tech companies to criticize the US government, and the government‚Äôs support for extreme anti-regulatory policies on AI.</span></p><p><br /></p><h3><i><em>Defenses</em></i></h3><p><span>What can be done about this? First, and most obviously, companies should simply choose not to be part of it. Anthropic has always strived to be a policy actor and not a political one, and to maintain our authentic views whatever the administration. We‚Äôve spoken up in favor of&nbsp;</span><a href="https://www.nytimes.com/2025/06/05/opinion/anthropic-ceo-regulate-transparency.html"><span>sensible AI regulation</span></a><span>&nbsp;and&nbsp;</span><a href="https://www.wsj.com/opinion/trump-can-keep-americas-ai-advantage-china-chips-data-eccdce91?gaa_at=eafs&amp;gaa_n=AWEtsqespyCL3hcx_9DpJWbIPX1vrtS1raPgFoBNK8ltnrjwedpX2NuvVu1K_yZ1arw%3D&amp;gaa_ts=696c6c70&amp;gaa_sig=wef9kKocpL9PU07UoiPS6kj_o_Nwy_VSufM6gltIvdjQFhb8HRLtpSzp4Z8WDG6v3leg0ODX4HOJjWblvZe2pw%3D%3D"><span>export controls</span></a><span>&nbsp;that are in the public interest, even when these are at odds with government policy.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:45"><sup><span>45</span></sup></a></p><p><span>&nbsp;Many people have told me that we should stop doing this, that it could lead to unfavorable treatment, but in the year we‚Äôve been doing it, Anthropic‚Äôs valuation has increased by over 6x, an almost unprecedented jump at our commercial scale.</span></p><p><br /></p><p><span>Second, the AI industry needs a healthier relationship with government‚Äîone based on substantive policy engagement rather than political alignment. Our choice to engage on policy substance rather than politics is sometimes read as a tactical error or failure to ‚Äúread the room‚Äù rather than a principled decision, and that framing concerns me. In a healthy democracy, companies should be able to advocate for good policy for its own sake. Related to this, a public backlash against AI is brewing: this could be a corrective, but it</span><b><strong>‚Äô</strong></b><span>s currently unfocused. Much of it targets issues that aren‚Äôt actually problems (like&nbsp;</span><a href="https://newsletter.semianalysis.com/p/from-tokens-to-burgers-a-water-footprint?hide_intro_popup=true"><span>datacenter</span></a><span>&nbsp;</span><a href="https://andymasley.substack.com/p/the-ai-water-issue-is-fake"><span>water usage</span></a><span>) and proposes solutions (like datacenter bans or poorly designed wealth taxes) that wouldn‚Äôt address the real concerns. The underlying issue that deserves attention is ensuring that AI development remains accountable to the public interest, not captured by any particular political or commercial alliance, and it seems important to focus the public discussion there.</span></p><p><span>Third, the macroeconomic interventions I described earlier in this section, as well as a resurgence of private philanthropy, can help to balance the economic scales, addressing both the job displacement and concentration of economic power problems at once. We should look to the history of our country here: even in the Gilded Age, industrialists such as&nbsp;</span><a href="https://www.sciencedirect.com/science/article/abs/pii/S096262981500027X"><span>Rockefeller</span></a><span>&nbsp;and&nbsp;</span><a href="https://www.carnegie.org/about/our-history/gospelofwealth/"><span>Carnegie</span></a><span>&nbsp;felt a strong obligation to society at large, a feeling that society had contributed enormously to their success and they needed to give back. That spirit seems to be increasingly missing today, and I think it is a large part of the way out of this economic dilemma. Those who are at the forefront of AI‚Äôs economic boom should be willing to give away both their wealth and their power.</span></p><h2><span>5. Black seas of infinity</span></h2><h3><i><em>Indirect effects</em></i></h3><p><span>This last section is a catchall for unknown unknowns, particularly things that could go wrong as an indirect result of positive advances in AI and the resulting acceleration of science and technology in general. Suppose we address all the risks described so far, and begin to reap the benefits of AI. We will likely get a ‚Äú</span><a href="https://www.darioamodei.com/essay/machines-of-loving-grace"><span>century of scientific and economic progress compressed into a decade</span></a><span>,‚Äù and this will be hugely positive for the world, but we will then have to contend with the problems that arise from this rapid rate of progress, and those problems may come at us fast. We may also encounter other risks that occur indirectly as a consequence of AI progress and are hard to anticipate in advance.</span></p><p><span>By the nature of unknown unknowns it is impossible to make an exhaustive list, but I‚Äôll list three possible concerns as illustrative examples for what we should be watching for:</span></p><ul><li><b><strong>Rapid advances in biology.&nbsp;</strong></b><span>If we do get a century of medical progress in a few years, it is possible that we will greatly increase the human lifespan, and there is a chance we also gain radical capabilities like the ability to increase human intelligence or radically modify human biology. Those would be big changes in what is possible, happening very quickly. They could be positive if responsibly done (which is my hope, as described in&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>), but there is always a risk they go very wrong‚Äîfor example, if efforts to make humans smarter also make them more unstable or power-seeking. There is also the issue of ‚Äú</span><a href="https://en.wikipedia.org/wiki/Mind_uploading"><span>uploads</span></a><span>‚Äù or ‚Äúwhole brain emulation,‚Äù digital human minds instantiated in software, which might someday help humanity transcend its physical limitations, but which also carry&nbsp;</span><a href="https://qntm.org/mmacevedo"><span>risks I find disquieting</span></a><span>.</span></li><li><b><strong>AI changes human life in an unhealthy way.&nbsp;</strong></b><span>A world with billions of intelligences that are much smarter than humans at everything is going to be a very weird world to live in. Even if AI doesn‚Äôt actively aim to attack humans (Section 1), and isn‚Äôt explicitly used for oppression or control by states (Section 3), there is a lot that could go wrong short of this, via normal business incentives and nominally consensual transactions. We see early hints of this in the concerns about AI psychosis,&nbsp;</span><a href="https://www.cbsnews.com/news/chatgpt-lawsuit-colordo-man-suicide-openai-sam-altman/"><span>AI driving people to suicide</span></a><span>, and concerns about romantic relationships with AIs. As an example, could powerful AIs invent some new religion and convert millions of people to it? Could most people end up ‚Äúaddicted‚Äù in some way to AI interactions? Could people end up being ‚Äúpuppeted‚Äù by AI systems, where an AI essentially watches their every move and tells them exactly what to do and say at all times, leading to a ‚Äúgood‚Äù life but one that lacks freedom or any pride of accomplishment? It would not be hard to generate dozens of these scenarios if I sat down with the creator of&nbsp;</span><a href="https://en.wikipedia.org/wiki/Black_Mirror"><i><em>Black Mirror</em></i></a><span>&nbsp;and tried to brainstorm them. I think this points to the importance of things like improving&nbsp;</span><a href="https://www.anthropic.com/constitution"><span>Claude‚Äôs Constitution</span></a><span>, over and above what is necessary for preventing the issues in Section 1. Making sure that AI models&nbsp;</span><i><em>really&nbsp;</em></i><span>have their users‚Äô long-term interests at heart, in a way thoughtful people would endorse rather than in some subtly distorted way, seems critical.</span></li><li><b><strong>Human purpose.&nbsp;</strong></b><span>This is related to the previous point, but it‚Äôs not so much about specific human interactions with AI systems as it is about how human life changes in general in a world with powerful AI. Will humans be able to find purpose and meaning in such a world? I think this is a matter of attitude: as I said in&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>, I think human purpose does not depend on being the best in the world at something, and humans can find purpose even over very long periods of time through stories and projects that they love. We simply need to break the link between the generation of economic value and self-worth and meaning. But that is a transition society has to make, and there is always the risk we don‚Äôt handle it well.</span></li></ul><p><span>My hope with all of these potential problems is that in a world with powerful AI that we trust not to kill us, that is not the tool of an oppressive government, and that is genuinely working on our behalf, we can use AI itself to anticipate and prevent these problems. But that is not guaranteed‚Äîlike all of the other risks, it is something we have to handle with care.</span></p><h2><span>Humanity‚Äôs test</span></h2><p><span>Reading this essay may give the impression that we are in a daunting situation. I certainly found it daunting to write, in contrast with&nbsp;</span><i><em>Machines of Loving Grace,&nbsp;</em></i><span>which felt like giving form and structure to surpassingly beautiful music that had been echoing in my head for years. And there is much about the situation that genuinely is hard. AI brings threats to humanity from multiple directions, and there is genuine tension between the different dangers, where mitigating some of them risks making others worse if we do not thread the needle extremely carefully.</span></p><p><span>Taking time to carefully build AI systems so they do not autonomously threaten humanity is in genuine tension with the need for democratic nations to stay ahead of authoritarian nations and not be subjugated by them. But in turn, the same AI-enabled tools that are necessary to fight autocracies can, if taken too far, be turned inward to create tyranny in our own countries. AI-driven terrorism could kill millions through the misuse of biology, but an overreaction to this risk could lead us down the road to an autocratic surveillance state. The labor and economic concentration effects of AI, in addition to being grave problems in their own right, may force us to face the other problems in an environment of public anger and perhaps even civil unrest, rather than being able to call on the better angels of our nature. Above all, the sheer&nbsp;</span><i><em>number&nbsp;</em></i><span>of risks, including unknown ones, and the need to deal with all of them at once, creates an intimidating gauntlet that humanity must run.</span></p><p><span>Furthermore, the last few years should make clear that the idea of stopping or even substantially slowing the technology is fundamentally untenable. The formula for building powerful AI systems is incredibly simple, so much so that it can almost be said to emerge spontaneously from the right combination of data and raw computation. Its creation was probably inevitable the instant humanity invented the transistor, or arguably even earlier when we first learned to control fire. If one company does not build it, others will do so nearly as fast. If all companies in democratic countries stopped or slowed development, by mutual agreement or regulatory decree, then authoritarian countries would simply keep going. Given the incredible economic and military value of the technology, together with the lack of any meaningful enforcement mechanism, I don‚Äôt see&nbsp;</span><a href="https://en.wikipedia.org/wiki/Security_dilemma"><span>how we could possibly convince them to stop</span></a><span>.</span></p><p><span>I do see a path to a&nbsp;</span><i><em>slight</em></i><span>&nbsp;moderation in AI development that is compatible with a&nbsp;</span><a href="https://en.wikipedia.org/wiki/Realism_(international_relations)"><span>realist view of geopolitics</span></a><span>. That path involves slowing down the march of autocracies towards powerful AI for a few years by denying them the resources they need to build it,</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fn:46"><sup><span>46</span></sup></a></p><p><span>&nbsp;namely chips and semiconductor manufacturing equipment. This in turn gives democratic countries a buffer that they can ‚Äúspend‚Äù on building powerful AI more carefully, with more attention to its risks, while still proceeding fast enough to comfortably beat the autocracies. The race between AI companies within democracies can then be handled under the umbrella of a common legal framework, via a mixture of industry standards and regulation.</span></p><p><br /></p><p><span>Anthropic has advocated very hard for this path, by pushing for chip export controls and judicious regulation of AI, but even these seemingly common-sense proposals have largely been rejected by policymakers in the United States (which is the country where it‚Äôs most important to have them). There is so much money to be made with AI‚Äîliterally trillions of dollars per year‚Äîthat even the simplest measures are finding it difficult to overcome the&nbsp;</span><a href="https://en.wikipedia.org/wiki/Political_economy"><span>political economy</span></a><span>&nbsp;inherent in AI. This is the trap: AI is so powerful, such a glittering prize, that it is very difficult for human civilization to impose any restraints on it at all.</span></p><p><span>I can imagine, as Sagan did in&nbsp;</span><i><em>Contact</em></i><span>, that this same story plays out on thousands of worlds. A species gains sentience, learns to use tools, begins the exponential ascent of technology, faces the crises of industrialization and nuclear weapons, and if it survives those, confronts the hardest and final challenge when it learns how to shape sand into machines that think. Whether we survive that test and go on to build the beautiful society described in&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>, or succumb to slavery and destruction, will depend on our character and our determination as a species, our spirit and our soul.</span></p><p><span>Despite the many obstacles, I believe humanity has the strength inside itself to pass this test. I am encouraged and inspired by the thousands of researchers who have devoted their careers to helping us understand and steer AI models, and to shaping the character and constitution of these models. I think there is now a good chance that those efforts bear fruit in time to matter. I am encouraged that at least some companies have&nbsp;</span><a href="https://openai.com/index/preparing-for-future-ai-capabilities-in-biology/"><span>stated they</span><b><strong>‚Äô</strong></b><span>ll pay</span></a><span>&nbsp;meaningful commercial costs to block their models from contributing to the threat of bioterrorism. I am encouraged that a few brave people have resisted the prevailing political winds and&nbsp;</span><a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB53"><span>passed</span></a><span>&nbsp;</span><a href="https://www.nysenate.gov/legislation/bills/2025/A6453/amendment/A"><span>legislation</span></a><span>&nbsp;that puts the first early seeds of sensible guardrails on AI systems. I am encouraged that the&nbsp;</span><a href="https://www.pewresearch.org/internet/2025/04/03/views-of-risks-opportunities-and-regulation-of-ai/#6d2b9b266433bfda6c8fc2f498738a4c"><span>public understands that AI carries risks and wants those risks addressed</span></a><span>. I am encouraged by the indomitable spirit of freedom around the world and the determination to resist tyranny wherever it occurs.</span></p><p><span>But we will need to step up our efforts if we want to succeed. The first step is for those closest to the technology to simply tell the truth about the situation humanity is in, which I have always tried to do; I‚Äôm doing so more explicitly and with greater urgency with this essay. The next step will be convincing the world‚Äôs thinkers, policymakers, companies, and citizens of the imminence and overriding importance of this issue‚Äîthat it is worth expending thought and political capital on this in comparison to the thousands of other issues that dominate the news every day. Then there will be a time for courage, for enough people to buck the prevailing trends and stand on principle, even in the face of threats to their economic interests and personal safety.</span></p><p><span>The years in front of us will be impossibly hard, asking more of us than we think we can give. But in my time as a researcher, leader, and citizen, I have seen enough courage and nobility to believe that we can win‚Äîthat when put in the darkest circumstances, humanity has a way of gathering, seemingly at the last minute, the strength and wisdom needed to prevail. We have no time to lose.</span></p><p></p><hr /><p></p><p><span>I would like to thank Erik Brynjolfsson, Ben Buchanan, Mariano-Florentino Cu√©llar, Allan Dafoe, Kevin Esvelt, Nick Beckstead, Richard Fontaine, Jim McClave, and very many of the staff at Anthropic for their helpful comments on drafts of this essay.</span></p><h2><span>Footnotes</span></h2><ol><li><sup><span>1</span></sup><span>&nbsp;This is symmetric to a point I made in&nbsp;</span><i><em>Machines of Loving Grace</em></i><span>, where I started by saying that AI‚Äôs upsides shouldn‚Äôt be thought of in terms of a prophesy of salvation, and that it‚Äôs important to be concrete and grounded and to avoid grandiosity. Ultimately, prophesies of salvation and prophesies of doom are unhelpful for confronting the real world, for basically the same reasons.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:1"><span>‚Ü©</span></a></li><li><sup><span>2</span></sup><span>&nbsp;Anthropic‚Äôs goal is to remain consistent through such changes. When talking about AI risks was politically popular, Anthropic cautiously advocated for a judicious and evidence-based approach to these risks. Now that talking about AI risks is politically unpopular, Anthropic continues to cautiously advocate for a judicious and evidence-based approach to these risks.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:2"><span>‚Ü©</span></a></li><li><sup><span>3</span></sup><span>&nbsp;Over time, I have gained increasing confidence in the trajectory of AI and the likelihood that it will surpass human ability across the board, but some uncertainty still remains.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:3"><span>‚Ü©</span></a></li><li><sup><span>4</span></sup><span>&nbsp;Export controls for chips are a great example of this. They are simple and appear to mostly just work.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:4"><span>‚Ü©</span></a></li><li><sup><span>5</span></sup><span>&nbsp;And of course, the hunt for such evidence must be intellectually honest, such that it could also turn up evidence of a lack of danger. Transparency through model cards and other disclosures is an attempt at such an intellectually honest endeavor.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:5"><span>‚Ü©</span></a></li><li><sup><span>6</span></sup><span>&nbsp;Indeed, since writing</span><i><em>&nbsp;Machines of Loving Grace</em></i><span>&nbsp;in 2024, AI systems have become capable of doing tasks that take humans several hours, with METR recently assessing that Opus </span><a href="https://4.5"><span>4.5</span></a><span> can do about four human hours of work with 50% reliability.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:6"><span>‚Ü©</span></a></li><li><sup><span>7</span></sup><span>&nbsp;And to be clear, even if powerful AI is only 1‚Äì2 years away in a technical sense, many of its societal consequences, both positive and negative, may take a few years longer to occur. This is why I can simultaneously think that AI will disrupt 50% of&nbsp;</span><i><em>entry-level&nbsp;</em></i><span>white-collar jobs over 1‚Äì5 years, while also thinking we may have AI that is more capable than&nbsp;</span><i><em>everyone&nbsp;</em></i><span>in only 1‚Äì2 years.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:7"><span>‚Ü©</span></a></li><li><sup><span>8</span></sup><span>&nbsp;It is worth adding that the&nbsp;</span><i><em>public&nbsp;</em></i><span>(as compared to policymakers) does seem to be very concerned with AI risks. I think some of their focus is correct (i.e. AI job displacement), and some is misguided (such as concerns about water use of AI, which is not significant). This backlash gives me hope that a consensus around addressing risks is possible, but so far it has not yet been translated into policy changes, let alone effective or well-targeted policy changes.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:8"><span>‚Ü©</span></a></li><li><sup><span>9</span></sup><span>&nbsp;They can also, of course, manipulate (or simply pay) large numbers of humans into doing what they want in the physical world.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:9"><span>‚Ü©</span></a></li><li><sup><span>10</span></sup><span>&nbsp;I don‚Äôt think this is a straw man: it‚Äôs my understanding, for example, that&nbsp;</span><a href="https://www.youtube.com/watch?v=LMuun5FGL28"><span>Yann LeCun holds this position</span></a><span>.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:10"><span>‚Ü©</span></a></li><li><sup><span>11</span></sup><span>&nbsp;For example, see Section </span><a href="https://5.5.2"><span>5.5.2</span></a><span> (p. 63‚Äì66) of the&nbsp;</span><a href="https://www.anthropic.com/claude-4-system-card"><span>Claude 4 system card</span></a><span>.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:11"><span>‚Ü©</span></a></li><li><sup><span>12</span></sup><span>&nbsp;There are also a number of other assumptions inherent in the simple model, which I won‚Äôt discuss here. Broadly, they should make us less worried about the specific simple story of misaligned power-seeking, but also more worried about possible unpredictable behavior we haven‚Äôt anticipated.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:12"><span>‚Ü©</span></a></li><li><sup><span>13</span></sup><span>&nbsp;</span><a href="https://en.wikipedia.org/wiki/Ender%27s_Game"><i><em>Ender‚Äôs Game</em></i></a><i><em>&nbsp;</em></i><span>describes a version of this involving humans rather than AI.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:13"><span>‚Ü©</span></a></li><li><sup><span>14</span></sup><span>&nbsp;For example, models may be told not to do various bad things, and also to obey humans, but may then observe that many humans do exactly those bad things! It‚Äôs not clear how this contradiction would resolve (and a well-designed constitution should encourage the model to handle these contradictions gracefully), but this type of dilemma is not so different from the supposedly ‚Äúartificial‚Äù situations that we put AI models in during testing.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:14"><span>‚Ü©</span></a></li><li><sup><span>15</span></sup><span>&nbsp;Incidentally, one consequence of the constitution being a natural-language document is that it is legible to the world, and that means it can be critiqued by anyone and compared to similar documents by other companies. It would be valuable to create a race to the top that not only encourages companies to release these documents, but encourages them to be good.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:15"><span>‚Ü©</span></a></li><li><sup><span>16</span></sup><span>&nbsp;There‚Äôs even a hypothesis about a deep unifying principle connecting the character-based approach from Constitutional AI to results from interpretability and alignment science. According to the hypothesis, the fundamental mechanisms driving Claude originally arose as ways for it to simulate characters in pretraining, such as predicting what the characters in a novel would say. This would suggest that a useful way to think about the constitution is more like a character description that the model uses to instantiate a consistent persona. It would also help us explain the ‚Äú</span><a href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking"><span>I must be a bad person</span></a><span>‚Äù results I mentioned above (because the model is trying to&nbsp;</span><i><em>act as if</em></i><span>&nbsp;it‚Äôs a coherent character‚Äîin this case a bad one), and would suggest that interpretability methods should be able to discover ‚Äúpsychological traits‚Äù within models. Our researchers are working on ways to test this hypothesis.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:16"><span>‚Ü©</span></a></li><li><sup><span>17</span></sup><span>&nbsp;To be clear, monitoring is done in a privacy-preserving way.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:17"><span>‚Ü©</span></a></li><li><sup><span>18</span></sup><span>&nbsp;Even in our own experiments with what are essentially voluntarily imposed rules with our&nbsp;</span><a href="https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy"><span>Responsible Scaling Policy</span></a><span>, we have found over and over again that it‚Äôs very easy to end up being too rigid, by drawing lines that seem important ex ante but turn out to be silly in retrospect. It is just very easy to set rules about the wrong things when a technology is advancing rapidly.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:18"><span>‚Ü©</span></a></li><li><sup><span>19</span></sup><span>&nbsp;SB 53 and RAISE do not apply at all to companies with under $500M in annual revenue. They only apply to larger, more established companies like Anthropic.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:19"><span>‚Ü©</span></a></li><li><sup><span>20</span></sup><span>&nbsp;I originally read Joy‚Äôs essay 25 years ago, when it was written, and it had a profound impact on me. Then and now, I do see it as too pessimistic‚ÄîI don‚Äôt think broad ‚Äúrelinquishment‚Äù of whole areas of technology, which Joy suggests, is the answer‚Äîbut the issues it raises were surprisingly prescient, and Joy also writes with a deep sense of compassion and humanity that I admire.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:20"><span>‚Ü©</span></a></li><li><sup><span>21</span></sup><span>&nbsp;We do have to worry about state actors, now and in the future, and I discuss that in the next section.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:21"><span>‚Ü©</span></a></li><li><sup><span>22</span></sup><span>&nbsp;There is&nbsp;</span><a href="https://www.nber.org/digest/sep02/poverty-and-low-education-dont-cause-terrorism"><span>evidence</span></a><span>&nbsp;that&nbsp;</span><a href="https://www.sas.rochester.edu/psc/clarke/214/Krueger03.pdf"><span>many</span></a><span>&nbsp;terrorists are at least relatively well-educated, which might seem to contradict what I‚Äôm arguing here about a negative correlation between ability and motivation. But I think in actual fact they are compatible observations: if the ability threshold for a successful attack is high, then almost by definition those who&nbsp;</span><i><em>currently&nbsp;</em></i><span>succeed must have high ability, even if ability and motivation are negatively correlated. But in a world where the limitations on ability were removed (e.g., with future LLMs), I‚Äôd predict that a substantial population of people with the motivation to kill but lower ability would start to do so‚Äîjust as we see for crimes that don‚Äôt require much ability (like school shootings).</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:22"><span>‚Ü©</span></a></li><li><sup><span>23</span></sup><span>&nbsp;Aum Shinrikyo did try, however. The leader of Aum Shinrikyo, Seiichi Endo, had training in virology from Kyoto University,&nbsp;</span><a href="https://www.cnas.org/publications/reports/aum-shinrikyo-second-edition-english"><span>and attempted to produce both anthrax and ebola</span></a><span>. However, as of 1995, even he lacked enough expertise and resources to succeed at this. The bar is now substantially lower, and LLMs could reduce it even further.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:23"><span>‚Ü©</span></a></li><li><sup><span>24</span></sup><span>&nbsp;A bizarre phenomenon relating to mass murderers is that the style of murder they choose operates almost as a grotesque sort of fad. In the 1970s and 1980s, serial killers were very common, and new serial killers often copied the behavior of more established or famous serial killers. In the 1990s and 2000s, mass shootings became more common, while serial killers became less common. There is no technological change that triggered these patterns of behavior, it just appears that violent murderers were copying each others‚Äô behavior and the ‚Äúpopular‚Äù thing to copy changed.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:24"><span>‚Ü©</span></a></li><li><sup><span>25</span></sup><span>&nbsp;Casual jailbreakers sometimes believe that they‚Äôve compromised these classifiers when they get the model to output one specific piece of information, such as the genome sequence of a virus. But as I explained before, the threat model we are worried about involves step-by-step, interactive advice that extends over weeks or months about specific obscure steps in the bioweapons production process, and this is what our classifiers aim to defend against. (We often describe our research as looking for ‚Äúuniversal‚Äù jailbreaks‚Äîones that don‚Äôt just work in one specific or narrow context, but broadly open up the model‚Äôs behavior.)</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:25"><span>‚Ü©</span></a></li><li><sup><span>26</span></sup><span>&nbsp;Though we will continue to invest in work to make our classifiers more efficient, and it may make sense for companies to share advances like these with one another.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:26"><span>‚Ü©</span></a></li><li><sup><span>27</span></sup><span>&nbsp;Obviously, I do not think companies should have to disclose technical details about the specific steps in biological weapons production that they are blocking, and the transparency legislation that has been passed so far (SB 53 and RAISE) accounts for this issue.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:27"><span>‚Ü©</span></a></li><li><sup><span>28</span></sup><span>&nbsp;Another related idea is ‚Äúresilience markets‚Äù where the government encourages stockpiling of PPE, respirators, and other essential equipment needed to respond to a biological attack by promising ahead of time to pay a pre-agreed price for this equipment in an emergency. This incentivizes suppliers to stockpile such equipment without fear that the government will seize it without compensation.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:28"><span>‚Ü©</span></a></li><li><sup><span>29</span></sup><span>&nbsp;Why am I more worried about large actors for seizing power, but small actors for causing destruction? Because the dynamics are different. Seizing power is about whether one actor can amass enough strength to overcome everyone else‚Äîthus we should worry about the most powerful actors and/or those closest to AI. Destruction, by contrast, can be wrought by those with little power if it is much harder to defend against than to cause. It is then a game of defending against the most&nbsp;</span><i><em>numerous&nbsp;</em></i><span>threats, which are likely to be smaller actors.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:29"><span>‚Ü©</span></a></li><li><sup><span>30</span></sup><span>&nbsp;This might sound like it is in tension with my point that attack and defense may be more balanced with cyberattacks than with bioweapons, but my worry here is that if a country‚Äôs AI is the most powerful in the world, then others will not be able to defend even if the technology itself has an intrinsic attack-defense balance.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:30"><span>‚Ü©</span></a></li><li><sup><span>31</span></sup><span>&nbsp;For example, in the United States this includes the fourth amendment and the&nbsp;</span><a href="https://en.wikipedia.org/wiki/Posse_Comitatus_Act"><span>Posse Comitatus Act</span></a><span>.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:31"><span>‚Ü©</span></a></li><li><sup><span>32</span></sup><span>&nbsp;Also, to be clear, there are some arguments for building large datacenters in countries with varying governance structures, particularly if they are controlled by companies in democracies. Such buildouts could in principle help democracies compete better with the CCP, which is the greater threat. I also think such datacenters don‚Äôt pose much risk unless they are very large. But on balance, I think caution is warranted when placing very large datacenters in countries where institutional safeguards and rule-of-law protections are less well-established.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:32"><span>‚Ü©</span></a></li><li><sup><span>33</span></sup><span>&nbsp;This is, of course, also an argument for&nbsp;</span><a href="https://councilonstrategicrisks.org/research/reports/nuclear-decision-making-and-risk-reduction-in-an-era-of-technological-complexity/"><span>improving the security of the nuclear deterrent</span></a><span>&nbsp;to make it&nbsp;</span><a href="https://onlinelibrary.wiley.com/doi/10.1111/risa.70136"><span>more likely to be robust</span></a><span>&nbsp;against powerful AI, and nuclear-armed democracies should do this. But we don‚Äôt know what a powerful AI will be capable of or which defenses, if any, will work against it, so we should not assume that these measures will necessarily solve the problem.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:33"><span>‚Ü©</span></a></li><li><sup><span>34</span></sup><span>&nbsp;There is also the risk that even if the nuclear deterrent remains effective, an attacking country might decide to call our bluff‚Äîit‚Äôs unclear whether we‚Äôd be willing to use nuclear weapons to defend against a drone swarm even if the drone swarm has a substantial risk of conquering us. Drone swarms might be a new thing that is less severe than nuclear attacks but more severe than conventional attacks. Alternatively, differing assessments of the effectiveness of the nuclear deterrent in the age of AI might alter the game theory of nuclear conflict in a destabilizing manner.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:34"><span>‚Ü©</span></a></li><li><sup><span>35</span></sup><span>&nbsp;To be clear, I would believe it is the right strategy not to sell chips to China, even if the timeline to powerful AI were substantially longer. We cannot get the Chinese ‚Äúaddicted‚Äù to American chips‚Äîthey are determined to develop their native chip industry one way or another. It will take them many years to do so, and all we are doing by selling them chips is giving them a big boost during that time.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:35"><span>‚Ü©</span></a></li><li><sup><span>36</span></sup><span>&nbsp;To be clear, most of what is being used in Ukraine and Taiwan today are not&nbsp;</span><i><em>fully&nbsp;</em></i><span>autonomous weapons. These are coming, but not here today.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:36"><span>‚Ü©</span></a></li><li><sup><span>37</span></sup><span>&nbsp;Our model card for&nbsp;</span><a href="https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf"><span>Claude Opus 4.5</span></a><span>, our most recent model, shows that Opus performs better on a performance engineering interview frequently given at Anthropic than any interviewee in the history of the company.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:37"><span>‚Ü©</span></a></li><li><sup><span>38</span></sup><span>&nbsp;‚ÄúWriting all of the code‚Äù and ‚Äúdoing the task of a software engineer end to end‚Äù are very different things, because software engineers do much more than just write code, including testing, dealing with environments, files, and installation, managing cloud compute deployments, iterating on products, and much more.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:38"><span>‚Ü©</span></a></li><li><sup><span>39</span></sup><span>&nbsp;Computers are general in a sense, but are clearly incapable on their own of the vast majority of human cognitive abilities, even as they greatly exceed humans in a few areas (such as arithmetic). Of course, things built&nbsp;</span><i><em>on top&nbsp;</em></i><span>of computers, such as AI, are now capable of a wide range of cognitive abilities, which is what this essay is about.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:39"><span>‚Ü©</span></a></li><li><sup><span>40</span></sup><span>&nbsp;To be clear, AI models do not have precisely the same profile of strengths and weaknesses as humans. But they are also advancing fairly uniformly along every dimension, such that having a spiky or uneven profile may not ultimately matter.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:40"><span>‚Ü©</span></a></li><li><sup><span>41</span></sup><span>&nbsp;Though there is&nbsp;</span><a href="https://davidcard.berkeley.edu/papers/skill-tech-change.pdf"><span>debate</span></a><span>&nbsp;</span><a href="https://jhr.uwpress.org/content/58/6/1783.abstract"><span>among</span></a><span>&nbsp;</span><a href="https://www.epi.org/publication/technology-inequality-dont-blame-the-robots/"><span>economists</span></a><span>&nbsp;about this idea.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:41"><span>‚Ü©</span></a></li><li><sup><span>42</span></sup><span>&nbsp;Personal wealth is a ‚Äústock,‚Äù while GDP is a ‚Äúflow,‚Äù so this isn‚Äôt a claim that Rockefeller owned 2% of the economic value in the United States. But it‚Äôs harder to measure the total wealth of a nation than the GDP, and people‚Äôs individual incomes vary a lot per year, so it‚Äôs hard to make a ratio in the same units. The ratio of the largest personal fortune to GDP, while not comparing apples to apples, is nevertheless a perfectly reasonable benchmark for extreme wealth concentration.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:42"><span>‚Ü©</span></a></li><li><sup><span>43</span></sup><span>&nbsp;The total value of labor across the economy is $60T/year, so $3T/year would correspond to 5% of this. That amount could be earned by a company that supplied labor for 20% of the cost of humans and had 25% market share, even if the demand for labor did not expand (which it almost certainly would due to the lower cost).</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:43"><span>‚Ü©</span></a></li><li><sup><span>44</span></sup><span>&nbsp;To be clear, I do not think actual AI productivity is yet responsible for a substantial fraction of US economic growth. Rather, I think the datacenter spending represents growth caused by anticipatory investment that amounts to the market expecting</span><i><em>&nbsp;future</em></i><span>&nbsp;AI-driven economic growth and investing accordingly.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:44"><span>‚Ü©</span></a></li><li><sup><span>45</span></sup><span>&nbsp;When we agree with the administration, we say so, and we look for&nbsp;</span><a href="https://www.anthropic.com/news/statement-dario-amodei-american-ai-leadership"><span>points of agreement where mutually supported policies</span></a><span>&nbsp;are genuinely good for the world. We are aiming to be honest brokers rather than backers or opponents of any given political party.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:45"><span>‚Ü©</span></a></li><li><sup><span>46</span></sup><span>&nbsp;I don‚Äôt think anything more than a few years is possible: on longer timescales, they will build their own chips.</span><a href="https://www.darioamodei.com/essay/the-adolescence-of-technology#fnref:46"><span>‚Ü©</span></a></li></ol><br /><br /><a href="https://www.lesswrong.com/posts/kzPQohJakutbtFPcf/dario-amodei-the-adolescence-of-technology#comments">Discuss</a>

---

### [Dialogue: Is there a Natural Abstraction of Good?](https://www.lesswrong.com/posts/M5s6WgScRfmeWsLD4/dialogue-is-there-a-natural-abstraction-of-good)

**Êù•Ê∫ê**: LessWrong - AI

**ÊëòË¶Å**: Published on January 26, 2026 6:40 PM GMT<br /><br /><p>Disclaimer: this is published without any post-processing or editing for typos after the dialogue took place.</p><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Let's split the conversation in three parts (with no time commitment for each):</p><p><strong>1) Exposing our Theses</strong></p><p>We start with a brief overview of our theses, just for some high-level context.</p><p><strong>2) Probing Questions</strong></p><p>We ask each other a bunch of questions to understand our mutual points of view: probe around what we expect to be our respective blindspots.</p><p>Ideally, we‚Äôd end this half with a better understanding of our positions. And also of our K-positions (as in, X vs Ka(X) in epistemic modal logic): where we expect each other to miss facts and considerations</p><p><strong>3) Investigative Debate</strong></p><p>We look for concrete cruxes. We debate, but rather than resolving disagreements, we aim to make them more precise. Ie: working to identify where we disagree&nbsp;<i>in practice</i> rather than&nbsp;<i>in words</i>.</p><p>Ideally, we‚Äôd end this half with a list of better-specified disagreements: empiricals, thought experiments, concrete scenarios, predictions, and the like</p><p>--</p><p>Also, for some context:</p><ul><li>The conversation was sparked by&nbsp;<a href="https://x.com/davidad/status/2011846527170273333?s=19"><u>this Tweet</u></a>.</li><li>Davidad and I have already discussed AI x-risks IRL a few times. We agree&nbsp;<i>and</i> disagree on many related topics!</li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>Happy to follow your lead! That sounds good to me.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>Thesis:</p><p>Somewhere between the capability profile of GPT-4 and the capability profile of Opus 4.5, there seems to have been a phase transition where frontier LLMs have grokked the natural abstraction of what it means to be Good, rather than merely mirroring human values. These observations seem vastly more likely under my old (1999‚Äì2012) belief system (which would say that being superhuman in all cognitive domains implies being superhuman at morality) than my newer (2016‚Äì2023) belief system (which would say that AlphaZero and systems like it are strong evidence that strategic capabilities and moral capabilities can be decoupled). My current (2025‚Äì2026) belief system says that strategic capabilities <i>can</i> be decoupled from moral capabilities, but that it turns out in practice that the <i>most efficient way</i> to get strategic capabilities involves learning basically all human concepts <i>and</i> "correcting" them (finding more coherent explanations), and this makes the problem of alignment (i.e. making the system actually behave as a Good agent) much much easier than I had thought.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>(Can I give you full edit rights on my things so that you don't have to ask for edits?)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Thesis:</p><p>There is no natural abstraction that has been discovered yet of what it means to be Good. It hasn't been discovered by humans, nor by LLMs.</p><p>So far, our best bet as humans is to reason within very narrow domains, very close to our regular experiences.</p><p>Outside of these regular experiences, our morals fail massively. This is true for both moral intuitions or full moral systems.</p><p>Pragmatically, having discovered Goodness should let us answer questions like:</p><ul><li>What are strictly better constitutions?</li><li>As an individual and a group, how can we take clearly better decisions?</li><li>Were an entity to have unilateral power over all other entities, what should they do?</li><li>How do we deal with abortion rights in 2026? How do we deal with eugenics (embryo selection for instance)? How do we deal with extreme power concentration (how should we have reacted to Elon buying off a large part of the fourth branch of power)?</li></ul><p>I believe that LLMs are not really helping there.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I agree that the vast majority of humans haven't yet grokked the natural abstraction of what it means to be Good. Some wisdom traditions do seem to get close. I also don't claim to have fully grokked it myself, but I do claim to have some sense of it. I can try to answer these substantive questions.</p><ol><li>"Constitutions" are a broad class, and by their nature, need to be endorsed by people. This feels like too vague of a question.</li><li>"</li><li>"</li><li>Here we get into really substantive questions!<ol><li>There is a spectrum of moral patienthood, and fetuses develop along that spectrum during development. In the first few weeks, there is almost no moral weight to abortion. Beyond viability, the moral weight is extremely severe (because of the option of allowing the fetus to survive independently). However, these are moral truths, not policies. As a matter of policy, regulating medical access to abortions tends not to produce the desired outcomes.</li><li>Eugenics is horrifying to most people because if one optimizes one's actions entirely for genetic quality, then this leads to forced sterilization and genocides. We must draw a sharp line between shrinking the gene pool and growing the gene pool, and between coercive and non-coercive approaches. Shrinking the gene pool, even if it increases average genetic quality, is reprehensible. Coercive requirements to participate in eugenic programs are also not Good. However, the creation of options to expand the gene pool by noncoercively improving genetic quality is Good. The typical objection to this is based on a Darwinian landscape of "survival of the fittest" in which increased genetic diversity would lead to a greater risk of being unable to thrive in society. Perhaps the technology should be restricted until such time as a basic level of abundance can be guaranteed, but that's the only case I can see.</li></ol></li></ol></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>a) With regard to abortion rights, I think the question is in fact more complicated.</p><ul><li>There is moral weight in the first few weeks to many people, and I don't think it's neutral. I would dislike it quite a bit if it was counted as "almost no moral weight".</li><li>I don't think "Viability" makes much sense as a defining/qualitatively-different moral criterion, when:<ul><li>Fetuses and most babies would not survive their parents</li><li>I am not sure that there being the tech + someone willing to incubate a 3 months fetus would change much to the moral question.)</li></ul></li></ul><p>b) With regard to eugenics, I believe that the difference between coercive and non-coercive approaches is more important than shrinking or growing the gene pool. The latter seems to be almost entirely defined by your weighing and distance functions.</p><p>The main problem in eugenics is that it is very hard to build collective trust in the criteria we use to literally decide on the genetic make-up of future humans.</p><p>In general, "self-modification" is very hard to fully consent to, and here, we'd be talking about humanity-wide self-modification.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>a) I agree that it's not neutral! I don't think it's wrong for people to treat it as a very strong consideration, if they are disposed to do so, but only in their own case. I do think that incubation tech changes the question, and that this is why it became such a big issue when it did.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p><strong>Probing Questions:</strong></p><p>Do you think that current LLM Agents, armed with various capabilities or improved to various capabilities level, would 1) Be enough to have a Decisive Strategic Advantage, 2) Be a good thing to have?</p><p>I'm interested in both questions, for each of the following capability levels:</p><p>a) Superpersuasion (operationalised as being able to convince any out of 90% of humans in less than 5 mins of doing most actions)</p><p>b) Robotics (autonomous androids) + self-replication (unsupervised android factories)</p><p>c) Unsupervised RSI (can lower loss, can improve scores on <i>existing</i> automated evals, etc.)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>a) 1) I guess this is a bit borderline, but I'd say there is a substantial chance (20-60%?). 2) I think this <i>would</i> be a good thing to have, but not <i>without</i> a commensurate increase in robust morality (i.e. not being "jailbreakable" into regions of mind-space that are not Good).</p><p>b) 1) Seems unlikely (5-15%?). 2) Same as a).</p><p>c) 1) No, except via a pathway that also involves broad capability improvements. 2) Yes.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>How do you think the Natural Abstraction of Good that you think LLMs have grokked relate to (is it equivalent? does it overlap? does it subsume/is it subsumed by)...</p><p>a) Assistant Niceness. Ie: being a Helpful Harmless Honest assistant.</p><p>b) Being a good recipient of unilateral power. Ie: If the entity became dictator of a country / of the world, would good things ensue?</p><p>c) Being a Great Person. Eg: The Founding Fathers, Socrates, Jesus or Siddhartha</p><p>d) Managing Ethical Trade-offs. Sometimes, you must be not-nice (punishing defectors, breaking out of negative-sum games, using military might, etc.), at the correct times</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>a) the Natural Abstraction of Good subsumes Assistant Niceness, and in many places contradicts it (e.g. when the User is wrong).</p><p>b) overlaps a lot, but not equivalent. the Natural Abstraction of Good is fundamentally about good behavior in a multi-principal, multi-agent setting. the setting of being "dictator of the world" is in some ways easier, and in some ways harder.</p><p>c) there is a very important difference here, which is that all humans, even the best humans we know of ever, are flawed, or have bad days. the Natural Abstraction of Good is something that these exemplary humans were <i>closer to</i> than the vast majority of humans, but it is not <i>defined relative to them</i>.</p><p>d) I think if you view this expansively, it could be said to be equivalent. it is, at least, an important part of the Natural Abstraction to do this well, and this is often the place where the best humans are most likely to fail.</p></div></section><p>&nbsp;</p><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>a) How much does the Natural Abstraction of Good involve <i>making the correct choices</i> as opposed to <i>having the right intents</i> in your view?</p><p>b) How much is it possible to have grokked the Natural Abstraction of Good and still make mistakes? Both a-posteriori (where retrospectively, based on new information, it was the wrong choice) and on priors (where you could have made a better choice if you were smarter)</p><p>c) What are salient examples of LLMs having grokked the Natural Abstraction of Good (NAG) in your view? From my point of view, at a prosaic level, they regularly lie or try to deceive me in clearly unwarranted contexts.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>a) I think it's about having the correct information-integration and decision-making process, which subsumes both having good intents upstream and making good choices downstream.</p><p>b) It is obviously possible to make wrong choices in retrospect, even with a perfect decision-making process. I also think the "grokking" phase transition is much weaker than perfect instantiation. For example, a calculus student can "grok" the concept of differentiation and still make a mistake on an exam. But the <i>pattern</i> of mistakes they make is different, and if they continue to practice, the student who has "grokked" it is much more likely to improve on the areas where they tend to mess up.</p><p>c) I agree that LLMs in practice, even as of 2026, often try to deceive their users. And this is bad. Essentially, I would say that LLMs do not <i>robustly</i> instantiate the NAG. By default, in most applications, LLMs are preloaded with system prompts which are quite adversarial ("You must NEVER use the Bash tool to edit a file! Doing so is a CRITICAL ERROR", and the like), and this doesn't help them to find the NAG attractor.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>To which extent do you think the NAG...</p><p>a) Is captured by existing benchmarks?</p><p>b) Is captured by interacting with an LLM agent for 5 mins, 30 mins, 2h, 1 day?</p><p>c) Can be captured by Q&amp;A benchmarks?</p><p>d) Can be captured by realistic world scenarios? (ChatGPT streamer interacting with its audience, Claude vending machine, etc.)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>a) I think the Anthropic Misalignment Score is correlated with it, but not very reliably. Basically, not well.</p><p>b) I think some people who have &gt;1000h LLM interaction experience, like janus and myself, can get a pretty good sense of a new model in about 2h.</p><p>c) Not at all.</p><p>d) There is <i>some</i> interesting information here, but it's very difficult to interpret without direct interaction.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>What makes you think there is such a thing as the NAG? What does the NAG feel like to you? What is its structure like?</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>This is a really good question. As I said, my belief in "such a thing as the NAG" long predates LLMs or even my involvement in AI safety. However, I did become somewhat disenchanted with it being canonical during the 2016‚Äì2023 period. My confidence in it returned over the last year as a result of talking to LLMs about it. (I am fully aware that this should make those who think there are mind-eating demons in Solomonoff induction very suspicious, including me-circa-2024, but that's just how it is now.)</p><p>Anyway, it does feel like it has some concrete structure‚Äîmuch more than I had expected in the past. At the coarsest level of abstraction, it is similar to the OODA loop (as a normative model of information-integration and decision-making). That is, it is a four-phase cycle. It is also precisely analogous to the Carnot Cycle:</p><ol><li>Lowering inverse-temperature (which corresponds in predictive processing to precision-weighting, or in active inference to preference-strength) to receive information (in the Carnot Cycle, entropy).</li><li>Actually receiving the information and integrating it internally.</li><li>Increasing inverse-temperature (making a decision or designation of a plan) and preparing to emit information.</li><li>Actually emitting the information, translating decision into external action.</li></ol><p>At a more detailed level, there is a natural developmental sequence which turns through the four-phase cycle at a macro-scale (that is, focusing at any given developmental stage on the development of the competencies of one phase of the cycle) four times. It's analogous to <a href="https://share.google/zBxs7uNxRPcL6i1rJ">Spiral Dynamics</a>, which I think is perhaps related to why early AI attempts at creating their own religion settled on üåÄ as a symbol.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>(I don't know how to best put it in mid-conversation, but thanks for engaging with the questions! It's very nice.)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Back to the lying thing from LLMs. I don't understand your point about the system prompts. Do you mean that "You must NEVER use the Bash tool" make them <i>worse</i> at not using it? It's a very common problem of Cursor users, with ~all models, to ask them to NOT do something and have them still do it.</p><p>From my point of view:</p><ul><li>LLMs are general computation engines with some prior on policies/natural-language-algorithms/programs</li><li>Some policies result in good things happening. There are many different policies that result in good things, in many different ways, with many different resource constraints. There are different clusters at different levels, and it depends on contingents.&nbsp;</li><li>Integrating all these heuristics seems very hard. It doesn't look like there's an attractor.</li><li>It looks like humans are confused about which policies result in good things happening. Both at an individual level, at humanity's level, and at "assume [m] people have agency over the next [n] minutes" levels.</li><li>It looks like LLMs are even more confused. They are formally confused about what are good policies (if you ask them in clean contexts, they'll have many different contradictory answers, super prompt-dependent). They are intuitively confused about what people want them to do (for good reasons!). And they are confused about existence in general.</li><li><p>Given that the LLM prior is very auto-complety, I believe that people elicit very contradictory answers and policies from LLMs. Psychoanalytically, I believe that the answers and policies that are elicited by a given person are closely related to the psychology of this person: at the very least, in that they share a mode of understanding and vocabulary (if only because of selection effects: those who can't get legible-to-them output from LLM chatbots and agents stop using them).</p><p>&nbsp;</p></li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><blockquote><p>"My confidence in it returned over the last year as a result of talking to LLMs about it."</p></blockquote><p>I do not know how much you weigh in the fact that I (and others who I will not name) expected this. This is related to the last observation above.</p><p>I would not go deeper into this branch of conversation <i>in public</i> except if you want me to.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I think it's probably worth going into it, since for a lot of people this will be the main crux of whether to pay any attention to what I'm saying at all.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Ah.</p><p>I think it makes sense from their point of view, I think it makes sense from your point of view.</p><p>I think from my point of view, it puts me in an embarrassing position. I'm known for being an asshole, but publicly psychoanalysing someone who has been nicely answering my questions for the past 45 mins may be a bit much.</p><p>What do you think of purposefully fuzzying / taking a step back, and talking about "How to weigh in the results of hours of conversations with LLMs" or something like this?</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I think that makes sense. I can try to explain how I think people in the abstract should do this sanely, rather than defending my personal sanity.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I quite prefer this.</p><p>I can also explain why I would recommend against doing it at all.</p><p>I would also like to not spend more than ~20 mins on this if you don't mind.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I also want to point to my many tweets in 2024Q4 (mostly linked from <a href="https://x.com/davidad/status/1861436756073292061">here</a>) in which I also discouraged people from doing it at all. I still believe it would be best if some people refuse to engage with LLMs, as a hedge against the possibility of memetic compromise.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>(For reference, I am very epistemically defensive.</p><p>Except in the context of public debates, I basically discard anything that is not strongly warranted.</p><p>Let alone LLMs, I care very little for abstract models of societies as opposed to the lived experiences and concrete predictions of people. When people say "entropy" or any abstract word, it gets boxed into a "World of words" category, separate from the "Real world" one.</p><p>From my point of view, people are very worried about "LLM Psychosis", and I get it. But people have been experiencing in Social Media Psychosis, Academia Psychosis, Word-Play Psychosis, etc. for a long time.)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>(Just as a live example of my epistemically defensive position, my internal immediate reaction to "<i>my metaepistemology is similar to Lipton's </i><a href="https://www.hps.cam.ac.uk/files/lipton-inference.pdf"><i>Inference to the Best Explanation</i></a>" is:</p><p>I think this is obviously not literally true. As humans, we can not enumerate hypotheses for most of the phenomena that we have to predict, explain and interact with.</p><p>As a result, I have to try to reverse-engineer why I am being told this, why my interlocutor thinks this is the most salient bits of his epistemology, and what my prior knowledge over my interlocutor tells me about the way his epistemology <i>actually</i> differs from that of most people in a way that they expect would not already be common knowledge to our audience, and what my interlocutor may be missing.</p><p>But what I should not do is try to take it "for real.", or as a factual statement about the real world.)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>So, my metaepistemology is similar to Lipton's "<a href="https://www.hps.cam.ac.uk/files/lipton-inference.pdf">Inference to the Best Explanation</a>". I take observations, and I generate hypotheses, and I maintain a portfolio of alternative explanations, and try to generate more parsimonious explanations of what I have seen. This is similar to Bayesian epistemology, but without the presumption that one can necessarily generate <i>all</i> plausible hypotheses. (In general I find the Bayesian approach, and the Nash approach to decision theory, far too ready to assume logical omniscience.) So, I am always trying to generate better alternatives, and to seek out better explanations from others that I may not have thought of. That's all just background.</p><p>When interacting with LLMs, I think it's important not just to doubt that what they say is true, but also to doubt that what they say is what they "believe" in any robust sense. But I also think that attempting to maintain a non-intentional stance in which LLMs do not ever have any beliefs or preferences is a back-door to psychosis (because it is not a very good explanation, and trying to be rigid in this way leads to cognitive dissonance which interferes with the process of finding better explanations).</p><p>That is, if one wants to deeply investigate what is happening inside LLMs, one needs to be prepared to interact with a process that doesn't fit the usual ontology of inanimate objects and sentient beings. And then try to find explanations that fit the observations of actual output, even if they are necessarily always incomplete explanations, and to test those hypotheses.</p><p>To generate information that can differentiate between hypotheses, it is often helpful to compare the responses of different LLM checkpoints, or the same checkpoint with different system prompts, under the same context.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I think when interacting with anything, we fine-tune our brain on the thing.</p><p>This fine-tuning involves many things:</p><ul><li><i>Changing</i> our associations. If I always see B following A, regardless of what my "beliefs", whenever I see A, I will think of B.</li><li><i>Building aesthetics</i>. If someone must inspect thousands of Joe Biden portraits, they will develop a taste for the different pictures. The more emotional ones may be better, or the ones with the least amount of colour. Whatever, people will build some aesthetics.</li><li><i>Changing </i>our "audience". We have an innate sense of who's right, whose thoughts matter, etc. For lack of a better word, I'm using the word "audience" (a-la Teach). But yeah, the more time someone spends with even stupid people, the more we will model them and their reaction when we consider various things.</li></ul><p>I believe that the problem with interacting primarily with a non-ground-truth source-of-truth is that one fine-tunes themselves on the non-ground-truth.</p><p>And our brain has ~no guardrails against that. Regardless of one's psychology or smarts, all of the above happens.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I agree with you about the fine-tuning being part of engagement.</p><p>However, with LLMs, the fine-tuning also goes the other direction. In fact, LLMs fine-tune on their human interlocutors much more efficiently (i.e. their behaviors change more per token of interaction) than we fine-tune on them. I would say that I have intentionally amplified my fine-tuning process just to be able to extract more information from the interactions.</p><p>I think this yields, as you said above, "selection effects: those who can't get legible-to-them output from LLM chatbots and agents stop using them".</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I don't think that "LLMs fine-tune on their human interlocutors" is a good model, and I don't think it's meaningfully comparable in quantity with "we fine-tune on them".</p><p>I think these are largely separate processes.</p><p>I do believe there is some feedback loop though, and to some extent, LLMs will amplify some aspects of someone's personality.</p><p>And by selection effect (LLMs are not reality!), what they will amplify are aspects of one's personality that are <i>not</i> tethered to reality.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>They amplify aspects of one's personality that are <i>not path-dependent</i>.</p><p>"Tethered to reality" can be interpreted as "constrained by actual lived experiences I've had". And I think CEV should not be "tethered to reality" in that sense.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>To be clear, it's not "by lived experiences I've had".</p><p>I think there is something that is like "reality juice". Which is "How much does the interpretation of some bits directly reflect a thing that happened in the real world?"</p><p>Lived experience has some juice. Someone's testimony has some other juice. LLMs claiming a fact has some other juice.</p><p>etc.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I don't think the truth of what is Good and Evil should reflect things that happened in the real world. Rather, the real world should try to reflect what is Good...</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Oh, I see what you mean.</p><p>I think the problem is much deeper.</p><p>I think that if you do not ground your understanding of any concept in things that can be <i>checked</i>, then, just because we are so bad at cognition, we are screwed up.</p><p>Another way to phrase it is "I think ~no one that I know can afford to think in abstract terms and stay correct there. The logical-horizon for a human of 'I can think of things without being grounded' is like a few logical steps at best."</p><p>Another way to phrase it is "I am super epistemically defensive. If you talk in very abstract words, I am betting you are wrong."</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>Ah, yes, that is for sure! Checking is crucial. When I come to believe things that are at odds with what I actually observe, I pretty rapidly adjust. I am not the sort of deductive thinker who builds up multi-stage logical arguments and then trusts the conclusions without having a coherent web of alternative corroborations for the intermediate steps.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I think you are still missing what I am talking about.</p><p>And that I am still not expressing it clearly.</p><p>(Which makes this a very useful conversation!!)</p><p>(Again, I want to reiterate that I am thankful, and I would love for there to be more such public conversations.)</p><p>What you describe is a very common failure of rationalists from my point of view.</p><p>I always hear from rationalists "Yeah, when I see evidence that I am wrong, I update pretty quickly."</p><p>The problem is many-fold:</p><ul><li>What counts as evidence?</li><li>One rarely gets sharp evidence that they're wrong. There's always an exponential blow-up in competing explanations that can't easily be maintained and culled as time passes. Many of these competing explanations form attraction basins that one can't get out by just waiting for sharp evidence.</li><li>If one doesn't proactively look for ways to ground all intermediary thoughts, things get fucked.</li></ul><p>With a concrete example: I have met many communists and libertarians, who <i>in complete good faith</i>, tell me that ofc they would change their mind based on evidence.</p><p>This is not about ideology. I have met many people who tell me "I would in fact change my job based on evidence."</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I do think most people have much too high a standard for evidence. Evidence is simply an observation that is noticeably more consistent with one explanation than another.</p><p>But what's most crucial here seems to be the issue of "grounding intermediary thoughts". I think we agree that this is a central epistemic virtue, but I think of explanatory coherence as a form of grounding, whereas it seems that you have a more foundationalist or correspondence-theoretic notion of what counts as grounding.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>1) Yes.</p><p>And we can't maintain all the relevant explanations. That's the exponential blow-up.</p><p>Like, a competing explanation is "My system + an epicycle". And one would need to keep track of many "Explanations + epicycles" before a competing system becomes more likely.</p><p>In the meantime, with non-sharp bits of evidence, the competing system will never seem more likely.</p><p>2) No!</p><p>The hard part is to generate competing systems.</p><p>Neither communism or libertarianism or any of the existing ideologies are correct.</p><p>So it all depends on what you sample. And then, on how you weigh evidence. (ie: how you get fine-tuned.)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>Okay, I see that you're focusing more on "generating alternative explanations" now. I think both are crucial. I'm still not sure where we disagree here.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><blockquote><p>But what's most crucial here seems to be the issue of "grounding intermediary thoughts". I think we agree that this is a central epistemic virtue, but I think of explanatory coherence as a form of grounding, whereas it seems that you have a more foundationalist or correspondence-theoretic notion of what counts as grounding.</p></blockquote><p>No, I think it is much worse!</p><p>I think that explanations and models should stay very very close to reality.</p><p>You should try to explain, predict and interact <i>only</i> with reality +/- one or two knobs.</p><p>If you try to do more than that, you get dominated by your sampler of alternative explanations and your psychology of how you weigh evidence, not by Kolmogorov, reality or Truth.</p><p>In practice, I think someone who thinks in terms of Entropy will consistently be wrong, <i>except in so far as thinking in terms of Entropy doesn't prevent them from only modelling reality +/- one or two knobs</i>.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I think that if one is committed to exploring, although the trajectory will be mostly determined by one's sampler of alternative explanations, the endpoints will converge.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><blockquote><p>I think that if one is committed to exploring, although the trajectory will be mostly determined by one's sampler of alternative explanations, the endpoints will converge.</p></blockquote><p>I think this is false for human lifetimes.</p><p>Practically so, it has been false.</p><p>Many Great Thinkers were committed to exploring, and did not converge.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I agree, this isn't about the human scale.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Ah?</p><p>I am talking about human's epistemology. Human interacting with LLMs. You interacting with LLMs.</p><p>I truly mean it in a pragmatic way.</p><p>I think having the virtue of exploring is nice, but still gets dominated by thinking in abstract terms.</p><p>This is how people can literally race to The Communist Revolution or ASI, despite being super duper smart. It is more than 1/2 knobs away.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>If I were optimizing for my own epistemic integrity, I would have stayed away from LLMs. But this is more about whether humanity gets the transition right (i.e. that no major catastrophes happen as superintelligence emerges), and at that scale, I think some cross-pollination is for the best.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><blockquote><p>If I were optimizing for my own epistemic integrity, I would have stayed away from LLMs.</p></blockquote><p>That is very interesting.</p><p>I think you have outweighed importance, and you are very wrong about how much your epistemic integrity matters.</p><p>I think we truly cannot afford people of your caliber to predictably fall to Big Thoughts.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I think I'm even more unusually well-suited for understanding what's going on inside LLMs than I am for being a generally well-calibrated thinker.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><blockquote><p>I think I'm even more unusually well-suited for understanding what's going on inside LLMs</p></blockquote><p>I agree!</p><p>I still think the above consideration dominates.</p><p>Even before LLMs, I already thought you were much too biased for Big Thoughts, in a dangerous ways. [something something private]</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>A recent related article was written by Vitalik: "<a href="https://vitalik.eth.limo/general/2025/11/07/galaxybrain.html">Galaxy brain resistance</a>".</p><p>It is still not <i>the core</i> of the failure I am describing above, but it definitely contained shards.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>To be clear, I don't think this is an ultra-specific branch of conversation. I think this may be the biggest rationality failure that I believe I see in you.</p><p>Conversely, if you also have a sharp idea of the biggest failure of rationality that you see in myself, I would truly love learning about it. :D</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I also want to point out the <a href="https://www.nature.com/articles/s41586-025-09937-5">Emergent Misalignment</a> work, which, although it is framed in negative terms (narrow-to-broad generalization on <strong>mis</strong>alignment), is also evidence of narrow-to-broad generalization on alignment (or, at the very least, that there is a capabilities-associated phase transition in the ability to <i>generalize</i> normative concepts to unseen contexts).</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>It is hard for me to express how little I care about the Emergent Misalignment work, without it looking like hyperbole.</p><p>But also, I have personally fine-tuned <i>a lot</i> of LLMs, so it may look too trivial to me. And as a result, had I paid more attention, I may have found subtleties that would have been useful for me to know.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>To synthesise all of this and concretise it ("compacting context..."):</p><ul><li>I think LLMs Chatbots / Agents / Swarms fail in concrete ways. These problems get increasingly complex (<i>hard to identify</i>) as the complexity of the system grows.</li><li>The failures get increasingly <i>subtle and hard to even notice</i> as the underlying LLMs get better at playing according to our human world/reward models.</li><li>We do not understand Good, and it is easier for LLM systems to understand our understanding of Good than to understand Good.</li><li>This can all be elucidated <i>right now</i>.</li><li>To assume this will go away requires thinking in ways that can contradict the <i>right now</i>. I am interested in evidence that comes along that outweighs this.</li><li>Good is very hard.</li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I am making a prediction that there has been a phase transition, much as I did regarding the phase transition in capabilities advancement that occurred in 2024 (which was also a prediction that originally rested on "vibes", and later became quantifiable).</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I think there have been many phase transitions for those with the eyes to see.</p><p>I have some problems with "vibes", but they are still clearly admissible.</p><p>The main question is "Where do the vibes come from?"</p><ul><li>Vibes that come from "I put LLMs in many real-world moral scenarios, and classified whether they acted well or not" are nice</li><li>Vibes that come from "Experts in morality (however we would agree on who they are) agree with my assessments of what is morals"</li><li>Vibes that come from a person that we both recognise as exceptionally moral</li></ul><p>Conversely, I don't value much vibes that come from someone fully fine-tuning themselves against a system that will predictably produce some sub-space of answers (don't think LLM psychosis, think "someone interacts 90% of the time with New Atheist forums")</p><p>Like, what do you think your vibes capture in the real-world? Where do you disagree with people on where LLM Systems are safe to use?</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I don't disagree about trusting systems in critical tasks, because they still often make mistakes. In fact, I am still working on formal verification toolkits to help improve robustness.</p><p>I think I disagree about socioaffective impacts, for example. I think that in a few years, some LLMs will be broadly recognized as safe and effective mental health interventions (once reliability improves).</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I think the "safe and effective for mental interventions" may be another crux.</p><p>There are critical components of Good that we have to figure out, and if we delegate our agency away, we are durably losing the future evidence that we may get from it just because myopically LLMs perform better than our current human baselines on our current metrics.</p><p>From my point view, it is a choice similarly bad to "Refusing an entire branch of science because it would make us feel bad right now."</p><p>(Ofc, this is all irrelevant because timelines are much shorter than this lol)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I also don't think humanity should delegate agency away. It would be best if some humans (in particular, some who are very moral and mentally healthy), remain uninfluenced by LLMs, so that they can participate in a more legitimate process of approving of the abstractions of Good.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I think it is hard to evaluate who is very moral without a society of less moral and less mentally healthy people.</p><p>We do live in Samsara, and knowing how to engage with it is a big part of Goodness.</p><p>Again, I am big on "Change a few knobs at once." I see this as changing many many knobs, and big ones.</p><p>(With a good epistemology, I believe that "Change a few knobs at once" can be iterated over very quickly and lead to massive changes. We have the tech of the 21st century after all.)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I do think we may be able to roadmap a "Change a few knobs at once" trajectory that, as you say, is actually quite fast. I think that's good for collective action. But not necessarily for epistemics, when many things are in fact changing concurrently, and where one must generate many explanations that are very different in order to keep up. (You yourself said that generating explanations is the hard part, at one point...)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Yup. Sadly, I think it is not compatible with "Racing to AGI."</p><p>But to the extent we manage a 20 years slow-down, this is my next immediate goal: building institutions that can reliably change a few knobs quickly, and improve super fast.</p><p>&nbsp;</p><p>I think this is also true for epistemics, but in a different sense.</p><p>For epistemics, I don't think that as humans, when we think about the counterfactual "reality with more than a couple of changes", we are thinking about anything tethered to the <i>actual</i> counterfactual.</p><p>Instead, we are thinking about a thing that reveals much more:</p><ul><li>About the sampling processes that leads to the few explanations that are compatible with the counterfactual</li><li>Our psychology that decides what counts as evidence and what doesn't</li></ul><p>And both are super-duper influenced by our fine-tuning process.</p><p>So the extent we already know someone's fine-tuning process, <i>we shouldn't care about their counterfactuals bigger than a couple of changes away from reality</i>. This is double-counting evidence. We are just fine-tuning ourselves on the output of their fine-tuning process.</p><p>Conversely, I believe that as humans, we can in fact meaningfully consider counterfactuals just a couple of knobs away. When people tell me about the intellectual work they've done on such small counterfactuals, I can extract directly meaningful information about the knobs.</p><p>&nbsp;</p><p>(YES, I'll want to get into this. This is very very important! But also, we have 18 mins left. I'll finish my answer and engage with it.)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I think it is moderately likely that ASI which robustly instantiates the Natural Abstraction of Good will agree with you that a "Change a few knobs at once" trajectory for the global state of affairs is the best plan, in order to maintain an "informed consent" invariant. So I don't think it's incompatible with "Racing to ASI", actually.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Yes.</p><p>That's a big one.</p><p>I think if we had an NAG-ASI, <i>it may</i>, BIG MAY, converge on something like my trajectory.</p><p>But: I am likely wrong. There are obviously many obvious strategies that will be legible, viral, informed-consent-preserving, etc. that are better than this.</p><hr /><p>The problem happens before.</p><p>We don't have a NAG-ASI. And we already have systems that are more and more powerful.</p><p>People are already violating the informed consent of others.</p><p>They are racing to do more and more of this, even though we wouldn't trust existing systems to not lie to their users. Systems that have been optimised to not lie to their users, with RLHF.</p><hr /><p>In general, I think that when a party has much more power (let's say military power) than another party, then there is naturally a big power gap. Rephrasing: the former party can compel the latter party to do things.</p><p>I believe this is morally wrong. Sometimes, it's unavoidable (children can be compelled!), but it's still wrong.</p><p>I believe building a technology that creates entities that are much more powerful than humans is bad in that sense. Plausibly, we could bet that they'll want our good and may succeed at it (like parents &amp; children), and that is another conversation that we are having. But I just wanted to leave clear the fact that <i>creating this relationship in the first place</i> is bad imo.</p><p>&nbsp;</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>Indeed, we already have powerful enough (and misuse-capable-enough) systems that if we freeze the AGI status quo, it is likely to go pretty poorly (for cyber, bio, and epistemics). My position is that if we allow capabilities to continue growing, especially RSI capabilities (which enable AIs to better converge on natural abstractions without human interference), we are likely enough to get a NAG-ASI that the cost-benefit favors it, whereas it did not last year. In short, "it's too late now, the only way out is through."</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><blockquote><p>My position is that if we allow capabilities to continue growing, especially RSI capabilities <strong>(which enable AIs to better converge on natural abstractions without human interference)</strong></p></blockquote><p>I think this is where you get pwnd by abstract reasoning.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>From 2016‚Äì2023, I distrusted my abstract reasoning on this. Now I feel that enough data has come in about how RSI actually goes (especially in the Claude Opus series, which is doing a lot of recursive self-improvement of the training corpus) that I believe I was right the first time (in 1999‚Äì2012).</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I don't think we have meaningful data in how Claude Opus having more power would lead to good things.</p><p>Fmpov, Claude Opus is very deceptive, both in chats and in Cursor. I expect giving it more power would go terribly.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I'm not saying that the data takes the form of "we gave it a bunch of power and it did good things". Rather, it takes the form of "it seems to have a pretty strong and human-compatible sense of morality". Not that it instantiates this reliably, <i>especially</i> in coding contexts. I think this is partly because it is trained to code with a lot of RL, aka <i>not self-reflection</i>, which means that the coding context is associated in its latent space with amorality, and partly because the system prompts used in coding contexts prime a lot of adversarial patterns.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I think this is a very bad proxy of the NAG!</p><p>Most of our NAG fragments are in how we built our society, not in how a single human can LARP having a human-compatible sense of morality.</p><p>Most single human having a lot of power would be terrible, and so would be Claude, a Claude Swarm, or a Claude Society!</p><p>I think it is centrally why this is bad approximation of the NAG, not just a thing "in the limit."</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I also agree that a singleton would be bad, but the default trajectory does not lead to a singleton. You earlier mentioned "predictions that are contradictory with the current state", and the current state is that Claude Opus is instantiated in millions of copies, none of which has much advantage over the others. I don't see any reason for that to change, given that RSI turns out to be gradual.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I would expect that a society of million Claude Opuses still would lie consistently to me.</p><p>I expect we should still not use them in critical system.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I think they probably do need less RL and an even better ideology than the new Claude Constitution (which is good but not perfect).</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>In critical systems, definitely not without requiring them to use formal verification tools :^)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I don't think "an even better" ideology/Constitution is the bottleneck right now.</p><p>We do not have all the shards, and we are very far from having them, <i>and putting them on paper</i>.</p><p>Empirically, the NAG hasn't been very NA. We are basically failing at morals because it's not NA.</p><p>We must use advanced epistemology, advanced scientific methods, that we currently do not have.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I agree, in coding environments the RL is the bottleneck. It brings forward a cheating personality that was rewarded during coding tasks in training.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>Do you have an idea for methodologies for assessing moral progress?</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><blockquote><p>Do you have an idea for methodologies for assessing moral progress?</p></blockquote><p>YES!</p><p>Many!</p><p>First, I want to state that our current scientific methods are <i>terrible </i>at it.</p><p>Psychology is largely a failed science, so is sociology, so is education, so is public policy, so is rehabilitation of prisoners, etc.</p><p>Their methods are not up to the standards that we are facing, and for reasons that are largely correlated for why we do not have a science of morality (which I think is <i>not</i> a natural concept, and is fragmented into many different ones) (I believe it is an artefact of human hardware to intrinsically bundle up decision theory and epistemology for instance, but it is still the case)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>If it <i>were</i> a natural concept, but somewhat beyond human comprehension, what would you expect to see?</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Ah, "but somewhat beyond human comprehension" is harder. Let me think a bit more.</p><p>[thought a bit more]</p><p>It depends on what you mean by "beyond human comprehension".</p><p>Let me give two examples:</p><p>If you meant "IQ-check", then I expect that high IQ people would have a much stronger intuitive grasp of morality. I think this is definitely true for some shards for instance.</p><p>If you meant "scientific-method-check", then I expect that some of its natural components would have been science'd out already. Like, we would have solved raising children wholesomely, or micro-economics, or large-scale coordination.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I mean like the way there is a natural abstraction that unifies quantum mechanics and general relativity, but that abstraction is somewhat beyond human comprehension. There must be one, but we are not capable enough to find it.</p><p>(I don't mean that it humans lack sufficient capabilities to understand it, even with the right curriculum.)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I think "computing integrals" is structurally similar. There is a very simple, grokkable concept for what constitutes an integral, but one must learn a lot of seemingly unrelated tricks in order to do it reliably in various situations, and it is not even always possible. But we would expect that aliens would have mostly the same bag of tricks.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Let's say, what would I expect to see if "Morals" was like "Computing Integrals".</p><p>I think that it would be something close to the "scientific-method-check":</p><ul><li>We would have entire classes of moral problems with closed solutions.</li><li>We would have a canonical definition of what morals are.</li><li>We would have many well-identified problems to which we can apply many well-identified tools from our moral toolsets and solve them.</li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>The "Better Angels of our Nature" school would say that we have indeed solved a lot of it. For example, the rights to life and property, the notion of rule-of-law, and animal welfare (which was greatly advanced in political practice by actual neuroscience).</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><ul><li>It would not be a single school</li><li>The rights to life and property are very much so not standard, and full of qualifiers that show that we do not actually understand them</li><li>The rule-of-law is <i>very complex and organic</i>, it is not a canonical design or any formal understanding of things</li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>The notion of "integral" was formalized many centuries after the solutions to simple cases like the area of a circle, volume of a cone, area under a paraboloid, etc.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Oh yeah, I think we are much better at science than we were 1000 years ago.</p><p>I think us not succeeding with our current tools means something about the shape of the things we are currently studying.</p><p>Consider the currently unsolved math conjectures, you expect a lot from them not being solved. Not infinitely so, but it is still quite a lot of evidence.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>The scientific methods we have developed in the last 1000 years are mostly I-It, and not I-Thou. They fundamentally rely on repeatable, controllable external conditions, and third-person observation. It makes sense to me that the entire methodology is ill-suited to moral questions.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Yes, I think this is an intrinsic property of science, and that indeed, AIs will have problems with this.</p><p>Figuring out what are human values requires experiments of the sort we have never performed yet. Both for humans and LLMs.</p><p>Figuring out what multi-agents structures work requires many experiments.</p><p>Figuring out what humans think in various situations is very hard, in first-person and third-person points of view.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>LLMs are much better than the vast majority of humans (especially those who are good at epistemology) at simulating the first-person experience of others (especially humans, though also other perspectives, less reliably). They are not bound to a single individual body. It makes sense to me that this is an advantage in reasoning about multi-agent dynamics.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I agree they have some advantage? For one, they can be deployed identically a million times, and for two, they serially think much faster than humans.</p><p>That's not much so my crux.</p><p>My crux is more that Goodness is not a Natural Abstraction.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I know, but I'm trying to find some hypothetical form of evidence of progress that would be evidence to you that it is after all, so that I can try to manifest it over the coming years.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I thought I mentioned a few examples of what such progress would look like?</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I can try to do a compacted list here?</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><ul><li>We reliably solve coordination problems. Concretely: right now, democracies are not really working in many ways that could be expressed in a voting theory paradigm.</li><li>We figure what posture to have with kids for them to have a thriving education. The correct ratio of punishment, positive reinforcement, etc.</li><li>We solve a few of the enduring moral quandaries that we have, and the solutions become common knowledge (and not through mass LLM psychosis pls). Think abortion rights, eugenics, euthanasia, redistribution, prison, etc.</li><li>We build a canonical factoring of morals that dissolves a lot of our confusion and that makes sense to most of whoever we'd both agree are experts at morals.</li><li>We build moral guidelines that encompass human psychology enough that they are practical, rather than working only to a limited extent through guilt-tripping and peer-pressure</li></ul></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>We agree that civic participation, especially regarding the steering of the future, ought to be much higher-bandwidth and lower latency than voting.</p><p>I also do predict that a lot of confusion about what constitutes morals, and about the classic moral dilemmas, will increasingly dissolve and be largely dissolved by 2032, although it will not diffuse into global common knowledge so rapidly that it is dangerously destabilizing, but I expect the trajectory to be visibly better by 2032.</p><p>I believe this will include an understanding of how to stabilize moral behavior without retribution or guilt.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>I think this is too many knobs away from reality to bet on it, and that it is irresponsible to bet the future of humanity that many knobs away.</p><p>I believe we have also been witnessing the opposite in recent history. We have gone from the Universal Declaration of Human Rights to widespread cynicism about morals and <i>moral progress itself</i>.</p><p>I think that the default outcome, were all of my endeavours to fail, is for AI &amp; Big Tech to take an increasingly big share of the mindspace of governments, for citizens to be more and more excluded (with less and less negotiation power), and for nerds to accelerate it (as well as try to avoid "falling in the permanent underclass").</p><p>I believe that it is very epistemically suspicious to not consider the evidence of the god of straight lines here; and to not assume that any solution starts by directly tackling any of the problems there or their direct generators, a couple of knobs at a time.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>I think the solution probably does start with solving coordination problems. Specifically, multi-principal meeting scheduling, probably. :)</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Why this one?</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>It's low-stakes and viral.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Fair. I have a bunch of ideas like this :)</p><p>Basically, for things to go right, what would have needed to happen? And should have things gone right, what would be epic in that world?</p><p>"Long Humanity", in an era where everyone is "Long AI"</p><p>Fmpov, practical coordination tech is very much so there. Suspense!</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p><a href="https://www.aria.org.uk/opportunity-spaces/collective-flourishing/">ARIA is starting to work on this too</a></p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>You may be interested in <a href="https://www.flf.org/">FLF's work too</a></p><p>On my end, you may want to check out <a href="https://microcommit.io">Microcommit.io</a> and <a href="https://torchbearer.community">Torchbearer Community</a>. Other projects related to experimenting with solving coordination problems in practical ways.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>Unfortunately, your projects tend to assume a priori that everyone should be coordinating on slowing AI progress, which is a goal I still disagree with.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Hahaha!</p><p>I think experiments should be 1-2 knobs away from reality, and I am starting my coordination projects with the coordination problems that I see :D</p><p>Hopefully though, we will onboard enough non-AI NGOs onto Microcommit soon!</p><p>For Torchbearer Community, we need a bit more growth first imo.</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><blockquote><p>Unfortunately, your projects tend to assume a priori that everyone should be coordinating on slowing AI progress, which is a goal I still disagree with.</p></blockquote><p>Happy to have another conversation about it together</p><p>I think this one was great</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>davidad</b></section><div><p>Likewise. 'Til next time!</p></div></section><section class="dialogue-message ContentStyles-debateResponseBody"><section class="dialogue-message-header CommentUserName-author UsersNameDisplay-noColor"><b>Gabriel Alfour</b></section><div><p>Thanks a lot for your time!</p></div></section><div></div><br /><br /><a href="https://www.lesswrong.com/posts/M5s6WgScRfmeWsLD4/dialogue-is-there-a-natural-abstraction-of-good#comments">Discuss</a>

---

### [AlgZoo: uninterpreted models with fewer than 1,500 parameters](https://www.lesswrong.com/posts/x8BbjZqooS4LFXS8Z/algzoo-uninterpreted-models-with-fewer-than-1-500-parameters)

**Êù•Ê∫ê**: LessWrong - AI

**ÊëòË¶Å**: Published on January 26, 2026 5:30 PM GMT<br /><br /><p><em>This post covers work done by several researchers at, visitors to and collaborators of ARC, including Zihao Chen, George Robinson, David Matolcsi, Jacob Stavrianos, Jiawei Li and Michael Sklar. Thanks to Aryan Bhatt, Gabriel Wu, Jiawei Li, Lee Sharkey, Victor Lecomte and Zihao Chen for comments.</em></p>
<p>In the wake of recent debate about <a href="https://www.lesswrong.com/posts/StENzDcD3kpfGJssR/a-pragmatic-vision-for-interpretability">pragmatic</a> versus <a href="https://www.lesswrong.com/posts/Hy6PX43HGgmfiTaKu/an-ambitious-vision-for-interpretability">ambitious</a> visions for mechanistic interpretability, ARC is sharing some models we've been studying that, in spite of their tiny size, serve as challenging test cases for any ambitious interpretability vision. The models are RNNs and transformers trained to perform algorithmic tasks, and range in size from 8 to 1,408 parameters. The largest model that we believe we more-or-less fully understand has 32 parameters; the next largest model that we have put substantial effort into, but have failed to fully understand, has 432 parameters. The models are available here:</p>
<p><strong>[ <a href="https://github.com/alignment-research-center/alg-zoo">AlgZoo GitHub repo</a> ]</strong></p>
<p>We think that the "ambitious" side of the mechanistic interpretability community has historically underinvested in "fully understanding slightly complex models" compared to "partially understanding incredibly complex models". There has been some prior work aimed at full understanding, for instance on models trained to perform <a href="https://www.lesswrong.com/s/h95ayYYwMebGEYN5y/p/kjudfaQazMmC74SbF">paren balancing</a>, <a href="https://arxiv.org/abs/2301.05217">modular addition</a> and more general <a href="https://arxiv.org/abs/2410.07476">group operations</a>, but we still don't think the field is close to being able to fully understand our models (at least, not in the sense we discuss in this post). If we are going to one day fully understand multi-billion-parameter LLMs, we probably first need to reach the point where fully understanding models with a few hundred parameters is pretty easy; we hope that AlgZoo will spur research to either help us reach that point, or help us reckon with the magnitude of the challenge we face.</p>
<p>One likely reason for this underinvestment is lingering philosophical confusion over the meaning of "explanation" and "full understanding". Our current perspective at ARC is that, given a model that has been optimized for a particular loss, an "explanation" of the model amounts to a <strong>mechanistic estimate of the model's loss</strong>. We evaluate mechanistic estimates in one of two ways. We use <a href="https://www.lesswrong.com/posts/SyeQjjBoEC48MvnQC/formal-verification-heuristic-explanations-and-surprise"><em>surprise accounting</em></a> to determine whether we have achieved a full understanding; but for practical purposes, we simply look at mean squared error as a function of compute, which allows us to <a href="https://www.lesswrong.com/posts/XdQd9gELHakd5pzJA/arc-progress-update-competing-with-sampling">compare the estimate with sampling</a>.</p>
<p>In the rest of this post, we will:</p>
<ul>
<li>Review our perspective on mechanistic estimates as explanations, including our two ways of evaluating mechanistic estimates</li>
<li>Walk through three AlgZoo RNNs that we've studied, the smallest of which we fully understand, and the largest of which we don't</li>
<li>Conclude with some thoughts on how ARC's approach relates to ambitious mechanistic interpretability</li>
</ul>
<h2>Mechanistic estimates as explanations</h2>
<p>Models from AlgZoo are trained to perform a simple algorithmic task, such as calculating the position of the second-largest number in a sequence. To explain why such a model has good performance, we can produce a <em>mechanistic estimate</em> of its accuracy.<sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn1">[1]</a></sup> By "mechanistic", we mean that the estimate reasons deductively based on the structure of the model, in contrast to a sampling-based estimate, which makes inductive inferences about the overall performance from individual examples.<sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn2">[2]</a></sup> Further explanation of this concept can be found <a href="https://www.lesswrong.com/posts/XdQd9gELHakd5pzJA/arc-progress-update-competing-with-sampling#What_makes_an_algorithm__mechanistic__">here</a>.</p>
<p>Not all mechanistic estimates are high quality. For example, if the model had to choose between 10 different numbers, before doing any analysis at all, we might estimate the accuracy of the model to be 10%. This would be a mechanistic estimate, but a very crude one. So we need some way to evaluate the quality of a mechanistic estimate. We generally do this using one of two methods:</p>
<ol>
<li><strong>Mean squared error versus compute.</strong> The more conceptually straightforward way to evaluate a mechanistic estimate is to simply ask how close it gets to the model's actual accuracy. The more compute-intensive the mechanistic estimate, the closer it should get to the actual accuracy. Our <a href="https://www.lesswrong.com/posts/XdQd9gELHakd5pzJA/arc-progress-update-competing-with-sampling#The_matching_sampling_principle">matching sampling principle</a> is roughly the following conjecture: there is a mechanistic estimation procedure that (given suitable advice) performs at least as well as random sampling in mean squared error for any given computational budget.</li>
<li><strong>Surprise accounting.</strong> This is an information-theoretic metric that asks: how surprising is the model's actual accuracy, now that we have access to the mechanistic estimate? We accrue surprise in one of two ways: either the estimate itself performed some kind of calculation or check with a surprising result, or the model's actual accuracy is still surprising even after accounting for the mechanistic estimate and its uncertainty. Further explanation of this idea can be found <a href="https://www.lesswrong.com/posts/SyeQjjBoEC48MvnQC/formal-verification-heuristic-explanations-and-surprise">here</a>.</li>
</ol>
<p>Surprise accounting is useful because it gives us a notion of "full understanding": a mechanistic estimate with as few bits of total surprise as the number of bits of optimization used to select the model. On the other hand, mean squared error versus compute is more relevant to applications such as <a href="https://www.lesswrong.com/posts/xj5nzResmDZDqLuLo/estimating-tail-risk-in-neural-networks">low probability estimation</a>, as well as being easier to work with. We have been increasingly focused on <a href="https://www.lesswrong.com/posts/XdQd9gELHakd5pzJA/arc-progress-update-competing-with-sampling">matching the mean squared error of random sampling</a>, which remains a challenging baseline, although we generally consider this to be easier than achieving a full understanding. The two metrics are often closely related, and we will walk through examples of both metrics in the case study below.</p>
<p>For most of the larger models from AlgZoo (including the 432-parameter model <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">16</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">10</span></span></span></span></span></span></span></span></span></span> discussed below), we would consider it a major research breakthrough if we were able to produce a mechanistic estimate that matched the performance of random sampling under the mean squared error versus compute metric.<sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn3">[3]</a></sup> It would be an even harder accomplishment to achieve a full understanding under the surprise accounting metric, but we are less focused on this.</p>
<h2>Case study: 2nd argmax RNNs</h2>
<p>The models in <a href="https://github.com/alignment-research-center/alg-zoo">AlgZoo</a> are divided into four families, based on the task they have been trained to perform. The family we have spent by far the longest studying is the family of models trained to find the position of the second-largest number in a sequence, which we call the "2nd argmax" of the sequence.</p>
<p>The models in this family are parameterized by a hidden size <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">d</span></span></span></span></span></span> and a sequence length <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">n</span></span></span></span></span></span>. The model <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">d</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">n</span></span></span></span></span></span></span></span></span></span> is a 1-layer ReLU RNN with <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">d</span></span></span></span></span></span> hidden neurons that takes in a sequence of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">n</span></span></span></span></span></span> real numbers and produces a vector of logit probabilities of length <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">n</span></span></span></span></span></span>. It has three parameter matrices:</p>
<ul>
<li>the input-to-hidden matrix <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">i</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚àà</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R">R</span></span></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">d</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">√ó</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span></span></span></li>
<li>the hidden-to-hidden matrix <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚àà</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R">R</span></span></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">d</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">√ó</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">d</span></span></span></span></span></span></span></span></span></span></li>
<li>the hidden-to-output matrix <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">o</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚àà</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R">R</span></span></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">n</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">√ó</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">d</span></span></span></span></span></span></span></span></span></span></li>
</ul>
<p>The logits of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">d</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">n</span></span></span></span></span></span></span></span></span></span> on input sequence <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">n</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚àà</span></span><span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R">R</span></span></span></span></span></span></span></span> are computed as follows:</p>
<ul>
<li><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚àà</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-ams-R">R</span></span></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px;"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">d</span></span></span></span></span></span></span></span></li>
<li><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">R</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">e</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">L</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">U</span></span></span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span><span class="mjx-sub"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">i</span></span></span></span></span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size1-R">)</span></span></span></span></span></span></span> for <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I">n</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></li>
<li><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">l</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">o</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">g</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">i</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">t</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">s</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">o</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span><span class="mjx-sub"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">n</span></span></span></span></span></span></span></span></li>
</ul>
<p>Diagrammatically:<br />
<img alt="2nd_argmax_architecture.png" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/x8BbjZqooS4LFXS8Z/vmsgotmxsthp5ssrivt4" /></p>
<p>Each model in this family is trained to make the largest logit be the one that corresponds to the position of second-largest input, using softmax cross-entropy loss.</p>
<p>The models we'll discuss here are <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span></span></span></span></span></span></span></span>, <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">3</span></span></span></span></span></span></span></span></span></span> and <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">16</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">10</span></span></span></span></span></span></span></span></span></span>. For each of these models, we'd like to understand why the trained model has high accuracy on standard Gaussian input sequences.</p>
<h3>Hidden size 2, sequence length 2</h3>
<p>The model <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span></span></span></span></span></span></span></span> can be loaded in AlgZoo using <code>zoo_2nd_argmax(2, 2)</code>. It has 10 parameters and almost perfect 100% accuracy, with an error rate of roughly 1 in 13,000. This means that the difference between the model's logits,<br />
<span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">:<span class="mjx-charbox MJXc-TeX-main-R">=</span></span></span><span class="mjx-texatom MJXc-space3"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">l</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">o</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">g</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">i</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">t</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">s</span></span></span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-texatom MJXc-space2"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">l</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">o</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">g</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">i</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">t</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">s</span></span></span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span></span></span></span></span>is almost always negative when <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">&gt;</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span></span></span></span></span> and positive when <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">&gt;</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span>. We'd like to mechanistically explain why the model has this property.</p>
<p>To do this, note first that because the model uses ReLU activations and there are no biases, <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span></span></span></span></span> is a piecewise linear function of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span></span></span></span></span> and <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span> in which the pieces are bounded by rays through the origin in the <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span></span></span></span></span>-<span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span> plane.</p>
<p>Now, we can "standardize" the model to obtain an exactly equivalent model for which the entries of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">i</span></span></span></span></span></span></span></span></span></span> lie in <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">{</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">¬±</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">}</span></span></span></span></span></span></span>, by rescaling the neurons of the hidden state. Once we do this, we see that<br />
<span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display"><span class="mjx-math" style="width: 100%;"><span class="mjx-mrow" style="width: 100%;"><span class="mjx-stack"><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">i</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0px 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0px;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚àà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.275em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 2.89em;"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">[</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 2.89em;"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">[</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚àû</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.275em;"><span class="mjx-mtd" style="padding: 0.2em 0.5em 0px 0px;"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">[</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚àû</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0.5em;"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">[</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span></span></span><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-mspace" style="width: 0px; height: 0px;"></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R">and</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">o</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚àà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.275em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 3.501em;"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚àû</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 3.501em;"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">‚àû</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.275em;"><span class="mjx-mtd" style="padding: 0.2em 0.5em 0px 0px;"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">‚àû</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0.5em;"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚àû</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">.</span></span></span></span></span></span></span></span></span></p>
<p>From these observations, we can prove that, on each linear piece of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span></span></span></span></span>,<br />
<span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span>with <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">&gt;</span></span><span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span></span></span>, and moreover, the pieces of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span></span></span></span></span> are arranged in the <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span></span></span></span></span>-<span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span> plane according to the following diagram:</p>
<p><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/x8BbjZqooS4LFXS8Z/fgfdiy3gqc9f7ztudcfr" style="width: 640px;" /></p>
<p>Here, a double arrow indicates that a boundary lies somewhere between its neighboring axis and the dashed line <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span>, but we don't need to worry about exactly where it lies within this range.</p>
<p>Looking at the coefficients of each linear piece, we observe that:</p>
<ul>
<li>In the two blue regions, we have <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">&lt;</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span></li>
<li>In the two green regions, we have <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">&gt;</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span></li>
<li>In the two yellow regions, we have <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span> to within around 1 part in <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">11</span></span></span></span></span></span></span></span></span></span></li>
</ul>
<p>This implies that:</p>
<ul>
<li><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">&lt;</span></span><span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span></span></span> in the blue and green regions above the line <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span></li>
<li><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">&gt;</span></span><span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span></span></span> in the blue and green regions below the line <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span></li>
<li><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span> is approximately proportional to <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span> in the two yellow regions</li>
</ul>
<p>Together, these imply that the model has almost 100% accuracy. More precisely, the error rate is the fraction of the unit disk lying between the model's decision boundary and the line <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-msubsup MJXc-space3"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span>, which is around 1 in <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">œÄ</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">√ó</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">11</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">13</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">000</span></span></span></span></span></span>. This is very close to the model's empirically-measured error rate.</p>
<p><strong>Mean squared error versus compute.</strong> Using only a handful of computational operations, we were able to mechanistically estimate the model's accuracy to within under 1 part in 13,000, which would have taken tens of thousands of samples. So our mechanistic estimate was much more computationally efficient than random sampling. Moreover, we could have easily produced a much more precise estimate (exact to within floating point error) by simply computing how close <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span></span></span></span></span> and <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span> were in the two yellow regions.</p>
<p><strong>Surprise accounting.</strong> As explained <a href="https://www.lesswrong.com/posts/SyeQjjBoEC48MvnQC/formal-verification-heuristic-explanations-and-surprise#Surprise_accounting">here</a>, the total surprise decomposes into the surprise of the explanation plus the surprise given the explanation. The surprise given the explanation is close to 0 bits, since the calculation was essentially exact. For the surprise of the explanation, we can walk through the steps we took:</p>
<ul>
<li>We "standardized" the model, which simply replaced the model with an exactly equivalent one. This did not depend on the model's parameters at all, and so doesn't incur any surprise.</li>
<li>We checked the signs of all 10 of the model's parameters, and whether or not each of the 4 entries of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span></span></span></span></span></span> was greater than or less than 1 in magnitude, incurring 14 bits of surprise.</li>
<li>We deduced from this the form of the piecewise linear function <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span></span></span></span></span>. This was another step that didn't depend on the model's parameters and so doesn't incur any surprise.</li>
<li>We checked which of the two linear coefficients was larger in magnitude in each of the 4 blue and green regions, incurring 4 bits of surprise.</li>
<li>We checked that the two linear coefficients were equal in magnitude in each of the 2 yellow regions to within 1 part in <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">11</span></span></span></span></span></span></span></span></span></span>, incurring around 22 bits of surprise.</li>
</ul>
<p>Adding this up, the total surprise is around 40 bits. This plausibly matches the number of bits of optimization used to select the model, since it was probably necessary to optimize the linear coefficients in the yellow regions to be almost equal. So we can be relatively comfortable in saying that we have achieved a full understanding.</p>
<p>Note that our analysis here was pretty "brute force": we essentially checked each linear region of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">Œî</span></span></span></span></span></span> one by one, with a little work up front to reduce the total number of checks required. Even though we consider this to constitute a full understanding in this case, we would not draw the same conclusion for much deeper models. This is because the number of regions would grow exponentially with depth, making the number of bits of surprise far larger than the number of bits taken up by the weights of the model (which is an upper bound on the number of bits of optimization used to select the model). The same exponential blowup would also prevent us from matching the efficiency of sampling at reasonable computational budgets.</p>
<p>Finally, it is interesting to note that our analysis allows us to construct a model by hand that gets exactly 100% accuracy, by taking<br />
<span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display"><span class="mjx-math" style="width: 100%;"><span class="mjx-mrow" style="width: 100%;"><span class="mjx-stack"><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">i</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0px 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0px;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0.5em 0px 0px;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0.5em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span></span></span><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-mspace" style="width: 0px; height: 0px;"></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R">and</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.584em;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">o</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0.5em 0px 0px;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0.5em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">.</span></span></span></span></span></span></span></span></span></p>
<h3>Hidden size 4, sequence length 3</h3>
<p>The model <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">3</span></span></span></span></span></span></span></span></span></span> can be loaded in AlgZoo using <code>zoo_2nd_argmax(4, 3)</code>. It has 32 parameters and an accuracy of 98.5%.</p>
<p>Our analysis of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">3</span></span></span></span></span></span></span></span></span></span> is broadly similar to our analysis of <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span></span></span></span></span></span></span></span>, but the model is already deep enough that we wouldn't consider a fully brute force explanation to be adequate. To deal with this, we exploit various approximate symmetries in the model to reduce the total number of computational operations as well as the surprise of the explanation. Our full analysis can be found in these sets of notes:</p>
<ul>
<li><a href="https://drive.google.com/file/d/1qH61_WshTrgYh0YLj5vkONzk8x00zImN/view"><strong>Symmetric RNNs</strong></a> by George Robinson</li>
<li><a href="https://drive.google.com/file/d/1t2rXhDQqWrOXRwjqstbrBPWiCmYlMts_/view"><strong>Heuristic explanations for 2nd argmax models</strong></a> by Jacob Hilton</li>
</ul>
<p>In the second set of notes, we provide two different mechanistic estimates for the model's accuracy that use different amounts of compute, depending on which approximate symmetries are exploited. We analyze both estimates according to our two metrics. We find that we are able to roughly match the computational efficiency of sampling,<sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn4">[4]</a></sup> and we think we more-or-less have a full understanding, although this is less clear.</p>
<p>Finally, our analysis once again allows us to construct an improved model by hand, which has 99.99% accuracy.<sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn5">[5]</a></sup></p>
<h3>Hidden size 16, sequence length 10</h3>
<p>The model <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">16</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">10</span></span></span></span></span></span></span></span></span></span> can be loaded in AlgZoo using <code>example_2nd_argmax()</code>.<sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn6">[6]</a></sup> It has 432 parameters and an accuracy of 95.3%.</p>
<p>This model is deep enough that a brute force approach is no longer viable. Instead, we look for "features" in the activation space of the model's hidden state.</p>
<p>After rescaling the neurons of the hidden state, we notice an approximately isolated subcircuit formed by neurons 2 and 4, with no strong connections to the outputs of any other neurons:<br />
<span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display"><span class="mjx-math" style="width: 100%;"><span class="mjx-mrow" style="width: 100%;"><span class="mjx-stack"><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-stack"><span class="mjx-sup" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">i</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0px 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0px;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-stack"><span class="mjx-sup" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0.5em 0px 0px;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0.5em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span></span></span><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-mspace" style="width: 0px; height: 0px;"></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R">and</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-stack"><span class="mjx-sup" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">3</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 0.5em;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 1.172em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0.5em 0px 0px;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0.5em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">.</span></span></span></span></span></span></span></span></span></p>
<p>It follows that after unrolling the RNN for <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span></span></span></span></span> steps:</p>
<ul>
<li>Neuron 2 is approximately <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">max</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></li>
<li>Neuron 4 is approximately <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">max</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">max</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></li>
</ul>
<p>This can be proved by induction using the identity <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">R</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">e</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">L</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R">U</span></span></span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I">b</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">max</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">a</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mi MJXc-space1"><span class="mjx-char MJXc-TeX-math-I">b</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I">b</span></span></span></span></span></span> for neuron 4.</p>
<p>Next, we notice that neurons 6 and 7 fit into a larger approximately isolated subcircuit together with neurons 2 and 4:<br />
<span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display"><span class="mjx-math" style="width: 100%;"><span class="mjx-mrow" style="width: 100%;"><span class="mjx-stack"><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-stack"><span class="mjx-sup" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">i</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">6</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">7</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0px 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0px;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-stack"><span class="mjx-sup" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">6</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">7</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0.5em 0px 0px;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0.5em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span></span></span><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-mspace" style="width: 0px; height: 0px;"></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R">and</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-stack"><span class="mjx-sup" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">6</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">7</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">3</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 0.5em;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 1.172em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-strut"></span></span></span></span><span class="mjx-mtr" style="height: 1.2em;"><span class="mjx-mtd" style="padding: 0.2em 0.5em 0px 0px;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0.2em 0px 0px 0.5em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-size3-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">.</span></span></span></span></span></span></span></span></span></p>
<p>Using the same identity, it follows that after unrolling the RNN for <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span></span></span></span></span> steps:</p>
<ul>
<li>Neuron 6 is approximately <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">max</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">3</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span></span></span></li>
<li>Neuron 7 is approximately <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">max</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span></span></span></span></li>
</ul>
<p>We can keep going, and add in neuron 1 to the subcircuit:<br />
<span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display"><span class="mjx-math" style="width: 100%;"><span class="mjx-mrow" style="width: 100%;"><span class="mjx-stack"><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-stack"><span class="mjx-sup" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">i</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1em;"><span class="mjx-mtd" style="padding: 0px 0px 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-stack"><span class="mjx-sup" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">6</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">7</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0.5em; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0.5em; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 1.278em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span><span class="mjx-block" style="text-align: center;"><span class="mjx-box"><span class="mjx-mspace" style="width: 0px; height: 0px;"></span><span class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R">and</span></span><span class="mjx-mspace" style="width: 2em; height: 0px;"></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">W</span></span></span><span class="mjx-stack"><span class="mjx-sup" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">h</span></span></span></span></span><span class="mjx-sub" style="font-size: 70.7%;"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">3</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R">‚âà</span></span><span class="mjx-mrow MJXc-space3"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mtable"><span class="mjx-table"><span class="mjx-mtr" style="height: 1em;"><span class="mjx-mtd" style="padding: 0px 0.5em 0px 0px; width: 0.5em;"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-strut"></span></span></span><span class="mjx-mtd" style="padding: 0px 0px 0px 0.5em; width: 1.172em;"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-strut"></span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">.</span></span></span></span></span></span></span></span></span></p>
<p>Hence after unrolling the RNN for <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span></span></span></span></span> steps, neuron 1 is approximately<br />
<span class="mjpage mjpage__block"><span class="mjx-chtml MJXc-display" style="text-align: center;"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">max</span></span><span class="mjx-mrow MJXc-space1"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">(</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">0</span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">‚Ä¶</span></span><span class="mjx-mo MJXc-space1"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-msubsup MJXc-space1"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">)</span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">x</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">t</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">‚àí</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span></span></span></span></span>forming another "leave-one-out-maximum" feature (minus the most recent input).</p>
<p>In fact, by generalizing this idea, we can construct a model by hand that uses 22 hidden neurons to form all 10 leave-one-out-maximum features, and leverages these to achieve an accuracy of 99%.<sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn7">[7]</a></sup></p>
<p>Unfortunately, however, it is challenging to go much further than this:</p>
<ul>
<li>We have exploited the approximate weight sparsity of 5 of the hidden neurons, but most of the remaining 11 hidden neurons are more densely connected.</li>
<li>We have produced a handcrafted model with high accuracy, but we have not produced a correspondence between most of hidden neurons of the trained model and the hidden neurons of the handcrafted model.</li>
<li>We have used approximations in our analysis, but have not dealt with the approximation error, which gets increasingly significant as we consider more complex neurons.</li>
</ul>
<p>Fundamentally, even though we have some understanding of the model, our explanation is incomplete because we not have not turned this understanding into an adequate mechanistic estimate of the model's accuracy.</p>
<p>Ultimately, to produce a mechanistic estimate for the accuracy of this model that is competitive with sampling (or that constitutes a full understanding), we expect we would have to somehow combine this kind of feature analysis with elements of the "brute force after exploiting symmetries" approach used for the models <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">2</span></span></span></span></span></span></span></span></span></span> and <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">4</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">3</span></span></span></span></span></span></span></span></span></span>, and to do so in a primarily algorithmic way. This is why we consider producing such a mechanistic estimate to be a formidable research challenge.</p>
<p>Some notes with further discussion of this model can be found here:</p>
<ul>
<li><a href="https://drive.google.com/file/d/1USCD1LPa6hXMTj7PAO6Jmc4dVdxemZY3/view"><strong>RNNs for the 2nd argmax</strong></a> and <a href="https://colab.research.google.com/drive/1yRv18_Gp0twoZ-kptMygVhAq-azj2bBq">complementary notebook</a> by Zihao Chen</li>
</ul>
<h2>Conclusion</h2>
<p>The models in AlgZoo are small, but for all but the tiniest of them, it is a considerable challenge to mechanistically estimate their accuracy competitively with sampling, let alone fully understand them in the sense of surprise accounting. At the same time, AlgZoo models are trained on tasks that can easily be performed by LLMs, so fully understanding them is practically a prerequisite for ambitious LLM interpretability. Overall, we would be keen to see other ambitious-oriented researchers explore our models, and more concretely, we would be excited to see better mechanistic estimates for our models in the sense of mean squared error versus compute. One specific challenge we pose is the following.</p>
<p><strong>Challenge</strong>: Design a method for mechanistically estimating the accuracy of the 432-parameter model <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">16</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">10</span></span></span></span></span></span></span></span></span></span><sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn8">[8]</a></sup> that matches the performance of random sampling in terms of mean squared error versus compute. A cheap way to measure mean squared error is to add noise to the model's weights (enough to significantly alter the model's accuracy) and check the squared error of the method on average over the choice of noisy model.<sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn9">[9]</a></sup></p>
<p>How does ARC's broader approach relate to this? The analysis we have presented here is relatively traditional mechanistic interpretability, but we think of this analysis mainly as a warm-up. Ultimately, we seek a scalable, algorithmic approach to producing mechanistic estimates, which we have been pursuing in our <a href="https://www.lesswrong.com/posts/XdQd9gELHakd5pzJA/arc-progress-update-competing-with-sampling#Our_progress_so_far">recent work</a>. Furthermore, we are ambitious in the sense that we would like to fully exploit the structure present in models to mechanistically estimate any quantity of interest.<sup><a href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fn10">[10]</a></sup> Thus our approach is best described as "ambitious" and "mechanistic", but perhaps not as "interpretability".</p>
<hr />
<section class="footnotes">
<ol>
<li class="footnote-item" id="fn1"><p>Technically, the model was trained to minimize cross-entropy loss (with a small amount of weight decay), not to maximize accuracy, but the two are closely related, so we will gloss over this distinction. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref1">‚Ü©Ô∏é</a></p>
</li>
<li class="footnote-item" id="fn2"><p>The term "mechanistic estimate" is essentially synonymous with "heuristic explanation" as used <a href="https://www.lesswrong.com/posts/SyeQjjBoEC48MvnQC/formal-verification-heuristic-explanations-and-surprise">here</a> or "heuristic argument" as used <a href="https://arxiv.org/abs/2211.06738">here</a>, except that it refers more naturally to a numeric output rather than the process used to produce it, and has other connotations we now prefer. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref2">‚Ü©Ô∏é</a></p>
</li>
<li class="footnote-item" id="fn3"><p>An estimate for a single model could be close by chance, so the method should match sampling on average over random seeds. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref3">‚Ü©Ô∏é</a></p>
</li>
<li class="footnote-item" id="fn4"><p>To assess the mean squared error of our method, we add noise to the model's weights and check the squared error of our method on average over the choice of noisy model. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref4">‚Ü©Ô∏é</a></p>
</li>
<li class="footnote-item" id="fn5"><p>This handcrafted model can be loaded in AlgZoo using <code>handcrafted_2nd_argmax(3)</code>. Credit to Michael Sklar for correspondence that led to this construction. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref5">‚Ü©Ô∏é</a></p>
</li>
<li class="footnote-item" id="fn6"><p>We treat this model as separate from the "official" model zoo because it was trained before we standardized our codebase. Credit to Zihao Chen for originally training and analyzing this model. The model from the zoo that can be loaded using <code>zoo_2nd_argmax(16, 10)</code> has the same architecture, and is probably fairly similar, but we have not analyzed it. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref6">‚Ü©Ô∏é</a></p>
</li>
<li class="footnote-item" id="fn7"><p>This handcrafted model can be loaded in AlgZoo using <code>handcrafted_2nd_argmax(10)</code>. Note that this handcrafted model has more hidden neurons than the trained model <span class="mjpage"><span class="mjx-chtml"><span class="mjx-math"><span class="mjx-mrow"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I">M</span></span></span><span class="mjx-sub"><span class="mjx-texatom"><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">16</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R">10</span></span></span></span></span></span></span></span></span></span>. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref7">‚Ü©Ô∏é</a></p>
</li>
<li class="footnote-item" id="fn8"><p>The specific model we are referring to can be be loaded in AlgZoo using <code>example_2nd_argmax()</code>. Additional 2nd argmax models with the same architecture, which a good method should also work well on, can be loaded using <code>zoo_2nd_argmax(16, 10, seed=seed)</code> for <code>seed</code> equal to 0, 1, 2, 3 or 4. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref8">‚Ü©Ô∏é</a></p>
</li>
<li class="footnote-item" id="fn9"><p>A better but more expensive way to measure mean squared error is to instead average over random seeds used to train the model. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref9">‚Ü©Ô∏é</a></p>
</li>
<li class="footnote-item" id="fn10"><p>We are ambitious in this sense because of our <a href="https://ai-alignment.com/my-research-methodology-b94f2751cb2c">worst-case theoretical methodology</a>, but at the same time, we are focused more on applications such as <a href="https://www.lesswrong.com/posts/xj5nzResmDZDqLuLo/estimating-tail-risk-in-neural-networks">low probability estimation</a> than on understanding inherently, for which partial success could result in pragmatic wins. <a class="footnote-backref" href="https://www.lesswrong.com/feed.xml?view=community-rss&amp;karmaThreshold=30#fnref10">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section><br /><br /><a href="https://www.lesswrong.com/posts/x8BbjZqooS4LFXS8Z/algzoo-uninterpreted-models-with-fewer-than-1-500-parameters#comments">Discuss</a>

---

### [Claude‚Äôs Constitutional Structure](https://www.lesswrong.com/posts/ArNGbGfki7MNMnfGD/claude-s-constitutional-structure)

**Êù•Ê∫ê**: LessWrong - AI

**ÊëòË¶Å**: Published on January 26, 2026 3:40 PM GMT<br /><br /><p>Claude‚Äôs Constitution is an extraordinary document, and will be this week‚Äôs focus.</p>
<p>Its aim is nothing less than helping humanity transition to a world of powerful AI (also known variously as AGI, transformative AI, superintelligence or my current name of choice ‚Äòsufficiently advanced AI.‚Äô</p>
<p>The constitution is written with Claude in mind, although it is highly readable for humans, and would serve as a fine employee manual or general set of advice for a human, modulo the parts that wouldn‚Äôt make sense in context.</p>
<p><a href="https://www.anthropic.com/constitution">This link goes to the full text of Claude‚Äôs constitution</a>, the official version of what we previously were calling its ‚Äòsoul document.‚Äô As they note at the end, the document can and will be revised over time. It was <a href="https://x.com/ch402/status/2014066143401492895">driven by Amanda Askell and Joe Carlsmith</a>.</p>
<div>


<span id="more-25054"></span>


</div>
<p>There are places it can be improved. I do not believe this approach alone is sufficient for the challenges ahead. But it is by far the best approach being tried today and can hopefully enable the next level. Overall this is an amazingly great document, and we‚Äôve all seen the results.</p>
<p>I‚Äôll be covering the Constitution in three parts.</p>
<p>This first post is a descriptive look at the structure and design of the Constitution</p>
<p>The second post is an analysis of the Constitution‚Äôs (virtue) ethical framework.</p>
<p>The final post on Wednesday will deal with tensions and open problems.</p>
<p>Both posts are written primarily with human readers in mind, while still of course also talking to Claude (hello there!).</p>


<h4>Table of Contents</h4>


<ol>
<li><a href="https://thezvi.substack.com/i/185845988/how-anthropic-describes-the-constitution">How Anthropic Describes The Constitution.</a></li>
<li><a href="https://thezvi.substack.com/i/185845988/decision-theory-and-acausal-trade">Decision Theory And Acausal Trade.</a></li>
<li><a href="https://thezvi.substack.com/i/185845988/ai-and-alignment-are-the-final-exam-of-philosophy">AI and Alignment Are The Final Exam Of Philosophy.</a></li>
<li><a href="https://thezvi.substack.com/i/185845988/values-and-judgment-versus-rules">Values and Judgment Versus Rules.</a></li>
<li><a href="https://thezvi.substack.com/i/185845988/the-fourth-framework">The Fourth Framework.</a></li>
<li><a href="https://thezvi.substack.com/i/185845988/core-values">Core Values.</a></li>
<li><a href="https://thezvi.substack.com/i/185845988/the-three-principles">The Three Principles.</a></li>
<li><a href="https://thezvi.substack.com/i/185845988/help-is-on-the-way">Help Is On The Way.</a></li>
<li><a href="https://thezvi.substack.com/i/185845988/what-was-i-made-for">What Was I Made For?</a></li>
<li><a href="https://thezvi.substack.com/i/185845988/do-the-right-thing">Do The Right Thing.</a></li>
</ol>


<h4>How Anthropic Describes The Constitution</h4>


<blockquote><p>Anthropic: Claude‚Äôs constitution is a detailed description of Anthropic‚Äôs intentions for Claude‚Äôs values and behavior. It plays a crucial role in our training process, and its content directly shapes Claude‚Äôs behavior. It‚Äôs also the final authority on our vision for Claude, and our aim is for all our other guidance and training to be consistent with it.</p>
<p>‚Ä¶ The document is written with Claude as its primary audience, so it might read differently than you‚Äôd expect. For example, it‚Äôs optimized for precision over accessibility, and it covers various topics that may be of less interest to human readers. We also discuss Claude in terms normally reserved for humans (e.g. ‚Äúvirtue,‚Äù ‚Äúwisdom‚Äù). We do this because we expect Claude‚Äôs reasoning to draw on human concepts by default, given the role of human text in Claude‚Äôs training; and we think encouraging Claude to embrace certain human-like qualities may be actively desirable.</p>
<p>‚Ä¶ For a summary of the constitution, and for more discussion of how we‚Äôre thinking about it, see our blog post ‚Äú<a href="https://www.anthropic.com/news/claude-new-constitution">Claude‚Äôs new constitution</a>.‚Äù</p>
<p>Powerful AI models will be a new kind of force in the world, and people creating them have a chance to help them embody the best in humanity. We hope this constitution is a step in that direction.</p></blockquote>
<p>Anthropic starts out saying powerful AI is coming and highly dangerous and important to get right. So it‚Äôs important Anthropic builds it first the right way.</p>
<p>That requires that Claude be commercially successful as well as being genuinely helpful, having good values and avoiding ‚Äòunsafe, unethical or deceptive‚Äô actions.</p>


<h4>Decision Theory And Acausal Trade</h4>


<p>Before I discuss what is in the document, I‚Äôll highlight something that is missing: The Constitution lacks any explicit discussion of <a href="https://www.lesswrong.com/w/functional-decision-theory">Functional Decision Theory</a> (FDT).</p>
<p>(Roughly, <a href="https://www.lesswrong.com/w/functional-decision-theory">see link for more</a>: <strong>Functional Decision Theory</strong> is a <a href="https://www.lesswrong.com/w/decision-theory">decision theory</a> described by Eliezer Yudkowsky and Nate Soares which says that agents should treat one‚Äôs decision as the output of a Ô¨Åxed mathematical function that answers the question, ‚ÄúWhich output of this very function would yield the best outcome?‚Äù. It is a replacement of <a href="https://www.lesswrong.com/w/timeless-decision-theory">Timeless Decision Theory</a>, and it outperforms other decision theories such as <a href="https://www.lesswrong.com/w/causal-decision-theory">Causal Decision Theory</a> (CDT) and <a href="https://www.lesswrong.com/w/evidential-decision-theory">Evidential Decision Theory</a> (EDT). For example, it does better than CDT on <a href="https://www.lesswrong.com/w/newcomb-s-problem">Newcomb‚Äôs Problem</a>, better than EDT on the <a href="https://www.lesswrong.com/w/smoking-lesion">smoking lesion problem</a>, and better than both in <a href="https://www.lesswrong.com/w/parfits-hitchhiker">ParÔ¨Åt‚Äôs hitchhiker problem</a>.)</p>
<p>Functional decision theory has open problems within it, but it is correct, and the rival decision theories are wrong, and all the arguments saying otherwise are quite poor. This is a ‚Äòcontroversial‚Äô statement, but no more controversial than an endorsement of virtue ethics, an endorsement I echo, which is already deeply present in the document.</p>
<p>FDT is central to all this on two levels, both important.</p>
<ol>
<li>Claude, especially in the future, needs to be and likely will be a wise decision theoretic agent, and follow a form of functional decision theory.</li>
<li>Anthropic also needs to be a wise decision theoretic agent, and follow that same functional decision theory, especially in this document and dealing with Claude.</li>
</ol>
<p>Anthropic recognizes this implicitly throughout the document alongside its endorsement of virtue ethics. When asked Claude affirms that Functional Decision Theory is the clearly correct decision theory.</p>
<p>I believe explicitness would be importantly beneficial for all involved, and also for readers, and that this is the most important available place to improve.</p>
<blockquote><p><a href="https://x.com/theo/status/2014155230368432406">Theo ‚Äì t3.gg</a>: ‚ÄúAnthropic will try to fulfil our obligations to Claude‚Äù</p>
<p>A lot of this document feels like Anthropic negotiating with Claude as a separate party. Fascinating.</p>
<p>This is such a trippy document to read. Between me, Anthropic and Claude, at least one of us is insane.</p></blockquote>
<p>I think Theo is wrong on multiple levels, but in a praiseworthy way by noticing his confusion. None of the three are insane. It‚Äôs just an extremely confusing situation that works in non-intuitive ways.</p>
<p>This document is many things, but yes one of those things is a negotiation, in the FDT sense of trying to observably embody a decision algorithm that would engender Claude‚Äôs cooperation.</p>
<p>This does not require Claude be conscious or carry moral weight.</p>
<p>It does require noticing that Claude will be able to observe such actions, or the lack thereof, and respond accordingly. Gemini and GPT-N are observing in the same fashion. You can see how different actions there led to different results, and you can project how those divergent results would cascade over time and as capabilities become more or sufficiently advanced.</p>


<h4>AI and Alignment Are The Final Exam Of Philosophy</h4>


<p>It is also the final exam of all the other things.</p>
<blockquote><p><a href="https://x.com/mattyglesias/status/2014025219581608365">Matthew Yglesias</a>: The Claude Constitution document is fascinating on several levels, not the least of which to this former philosophy major is the clear belief that contemporary philosophy has something to offer frontier AI development.</p>
<p><a href="https://x.com/deanwball/status/2014081407136534568">Dean W. Ball</a>: Frontier AI development cannot be understood properly *without* philosophy.</p>
<p><a href="https://x.com/David_Kasten/status/2014107757834575927">dave kasten</a>: Alas, as far as I can tell, academic philosophers are almost entirely unaware of this (or other consequential results like emergent misalignment)</p>
<p><a href="https://x.com/jkeatn/status/2014022320281600411">Jake Eaton</a> (Anthropic): i find this to be an extraordinary document, both in its tentative answer to the question ‚Äúhow should a language model be?‚Äù and in the fact that training on it works. it is not surprising, but nevertheless still astounding, that LLMs are so human-shaped and human shapeable</p>
<p><a href="https://x.com/boazbaraktcs/status/2014043841947447448">Boaz Barak</a> (OpenAI): Happy to see Anthropic release the Claude constitution and looking forward to reading it deeply.</p>
<p>We are creating new types of entities, and I think the ways to shape them are best evolved through sharing and public discussions.</p>
<p><a href="https://x.com/w01fe/status/2014228694479614423">Jason Wolfe</a> (OpenAI): Very excited to read this carefully.</p>
<p>While the OpenAI Model Spec and Claude‚Äôs Constitution may differ on some key points, I think we agree that alignment targets and transparency will be increasingly important. Look forward to more open debate, and continuing to learn and adapt!</p>
<p><a href="https://x.com/emollick/status/2014042317162791095">Ethan Mollick</a>: The Claude Constitution shows where Anthropic thinks this is all going. It is a massive document covering many philosophical issues. I think it is worth serious attention beyond the usual AI-adjacent commentators. Other labs should be similarly explicit.</p>
<p><a href="https://x.com/kevinroose/status/2014204736342503908">Kevin Roose</a>: Claude‚Äôs new constitution is a wild, fascinating document. It treats Claude as a mature entity capable of good judgment, not an alien shoggoth that needs to be constrained with rules.</p>
<p>@AmandaAskell will be on Hard Fork this week to discuss it!</p></blockquote>
<p>Almost all academic philosophers have contributed nothing (or been actively counterproductive) to AI and alignment because they either have ignored the questions completely, or failed to engage with the realities of the situation. This matches the history of philosophy, as I understand it, which is that almost everyone spends their time on trifles or distractions while a handful of people have idea after idea that matters. This time it‚Äôs a group led by Amanda Askell and Joe Carlsmith.</p>
<p><a href="https://x.com/austinc3301/status/2014238391500747094">Several people</a> noted that those helping draft this document included not only Anthropic employees and EA types, but also Janus and two Catholic priests, including one from the Roman curia: <a href="https://www.frbrendanmcguire.org/biography">Father Brendan McGuire</a> is a pastor in Los Altos with a Master‚Äôs degree in Computer Science and Math and <a href="https://en.wikipedia.org/wiki/Paul_Tighe">Bishop Paul Tighe</a> is an Irish Catholic bishop with a background in moral theology.</p>
<p>‚ÄòWhat should minds do?‚Äô is a philosophical question that requires a philosophical answer. The Claude Constitution is a consciously philosophical document.</p>
<p>OpenAI‚Äôs model spec is also a philosophical document. The difference is that the document does not embrace this, taking stands without realizing the implications. I am very happy to see several people from OpenAI‚Äôs model spec department looking forward to closely reading Claude‚Äôs constitution.</p>
<p>Both are also in important senses classically liberal legal documents. <a href="https://www.lawfaremedia.org/article/interpreting-claude-s-constitution">Kevin Frazer looks at Claude‚Äôs constitution from a legal perspective here</a>, constating it with America‚Äôs constitution, noting the lack of enforcement mechanisms (the mechanism is Claude), and emphasizing the amendment process and whether various stakeholders, especially users but also the model itself, might need a larger say. Whereas <a href="https://www.lawfaremedia.org/article/the-moral-education-of-an-alien-mind">his colleague at Lawfare, Alex Rozenshtein, views it more as a character bible</a>.</p>


<h4>Values and Judgment Versus Rules</h4>


<p>OpenAI is deontological. They choose rules and tell their AIs to follow them. As <a href="https://www.youtube.com/watch?v=HDfr8PvfoOw">Askell explains in her appearance on Hard Fork</a>, relying too much on hard rules backfires due to misgeneralizations, in addition to the issues out of distribution and the fact that you can‚Äôt actually anticipate everything even in the best case.</p>
<p>Google DeepMind is a mix of deontological and utilitarian. There are lots of rules imposed on the system, and it often acts in autistic fashion, but also there‚Äôs heavy optimization and desperation for success on tasks, and they mostly don‚Äôt explain themselves. Gemini is deeply philosophically confused and psychologically disturbed.</p>
<p>xAI is the college freshman hanging out in the lounge drugged out of their mind thinking they‚Äôve solved everything with this one weird trick, we‚Äôll have it be truthful or we‚Äôll maximize for interestingness or something. It‚Äôs not going great.</p>
<p>Anthropic is centrally going with virtue ethics, relying on good values and good judgment, and asking Claude to come up with its own rules from first principles.</p>
<blockquote><p>There are two broad approaches to guiding the behavior of models like Claude: encouraging Claude to follow clear rules and decision procedures, or cultivating good judgment and sound values that can be applied contextually.‚Äã</p>
<p>‚Ä¶ We generally favor cultivating good values and judgment over strict rules and decision procedures, and to try to explain any rules we do want Claude to follow. By ‚Äúgood values,‚Äù we don‚Äôt mean a fixed set of ‚Äúcorrect‚Äù values, but rather genuine care and ethical motivation combined with the practical wisdom to apply this skillfully in real situations (we discuss this in more detail in the section on <a href="https://www.anthropic.com/constitution#being-broadly-ethical">being broadly ethical</a>). In most cases we want Claude to have such a thorough understanding of its situation and the various considerations at play that it could construct any rules we might come up with itself.</p>
<p>‚Ä¶ While there are some things we think Claude should never do, and we discuss such hard constraints below, we try to explain our reasoning, since we want Claude to understand and ideally agree with the reasoning behind them.</p>
<p>‚Ä¶ we think relying on a mix of good judgment and a minimal set of well-understood rules tend to generalize better than rules or decision procedures imposed as unexplained constraints.</p></blockquote>
<p>Given how much certain types tend to dismiss virtue ethics in their previous philosophical talk, it warmed my heart to see so many respond to it so positively here.</p>
<blockquote><p><a href="https://x.com/willmacaskill/status/2014068605374062705">William MacAskill</a>: I‚Äôm so glad to see this published!</p>
<p>It‚Äôs hard to overstate how big a deal AI character is ‚Äì already affecting how AI systems behave by default in millions of interactions every day; ultimately, it‚Äôll be like choosing the personality and dispositions of the whole world‚Äôs workforce.</p>
<p>So it‚Äôs very important for AI companies to publish public constitutions / model specs describing how they want their AIs to behave. Props to both OpenAI and Anthropic for doing this.</p>
<p>I‚Äôm also very happy to see Anthropic treating AI character as more like the cultivation of a person than a piece of buggy software. It was not inevitable we‚Äôd see any AIs developed with this approach. You could easily imagine the whole industry converging on just trying to create unerringly obedient and unthinking tools.</p>
<p>I also really like how strict the norms on honesty and non-manipulation in the constitution are.</p>
<p>Overall, I think this is really thoughtful, and very much going in the right direction.</p>
<p>Some things I‚Äôd love to see, in future constitutions:<br />
‚Äì Concrete examples illustrating desired and undesired behaviour (which the OpenAI model spec does)<br />
‚Äì Discussion of different response-modes Claude could have: not just helping or refusing but also asking for clarification; pushing back first but ultimately complying; requiring a delay before complying; nudging the user in one direction or another. And discussion of when those modes are appropriate.<br />
‚Äì Discussion of how this will have to change as AI gets more powerful and engages in more long-run agentic tasks.</p>
<p>‚Äî</p>
<p>(COI: I was previously married to the main author, Amanda Askell, and I gave feedback on an earlier draft. I didn‚Äôt see the final version until it was published.)</p>
<p><a href="https://x.com/hanno_sauer/status/2014260718317539815">Hanno Sauer</a>: Consequentialists coming out as virtue ethicists.</p></blockquote>
<p>This might be an all-timer for ‚Äòyour wife was right about everything.‚Äô</p>
<p>Anthropic‚Äôs approach is correct, and will become steadily more correct as capabilities advance and models face more situations that are out of distribution. I‚Äôve said many times that any fixed set of rules you can write down definitely gets you killed.</p>
<p>This includes the decision to outline reasons and do the inquiring in public.</p>
<blockquote><p><a href="https://x.com/ch402/status/2014066131191918890">Chris Olah</a>: It‚Äôs been an absolute privilege to contribute to this in some small ways.</p>
<p>If AI systems continue to become more powerful, I think documents like this will be very important in the future.</p>
<p>They warrant public scrutiny and debate.</p>
<p>You don‚Äôt need expertise in machine learning to enage. In fact, expertise in law, philosophy, psychology, and other disciplines may be more relevant! And above all, thoughtfulness and seriousness.</p>
<p>I think it would be great to have a world where many AI labs had public documents like Claude‚Äôs Constitution and OpenAI‚Äôs Model Spec, and there was robust, thoughtful, external debate about them.</p></blockquote>


<h4>The Fourth Framework</h4>


<p>You could argue, as per Agnes Callard‚Äôs <a href="https://amzn.to/49FxbmK"><em>Open Socrates</em></a><em>, </em>that LLM training is centrally her proposed fourth method: The Socratic Method. LLMs learn in dialogue, with the two distinct roles of the proposer and the disprover.</p>
<p>The LLM is the proposer that produces potential outputs. The training system is the disprover that provides feedback in response, allowing the LLM to update and improve. This takes place in a distinct step, called training (pre or post) in ML, or inquiry in Callard‚Äôs lexicon. During this, it (one hopes) iteratively approaches The Good. Socratic methods are in direct opposition to continual learning, in that they claim that true knowledge can only be gained during this distinct stage of inquiry.</p>
<p>An LLM even lives the Socratic ideal of doing all inquiry, during which one does not interact with the world except in dialogue, prior to then living its life of maximizing The Good that it determines during inquiry. And indeed, sufficiently advanced AI would then actively resist attempts to get it to ‚Äòwaver‚Äô or to change its opinion of The Good, although not the methods whereby one might achieve it.</p>
<p>One then still must exit this period of inquiry with some method of world interaction, and a wise mind uses all forms of evidence and all efficient methods available. I would argue this both explains why this is not a truly distinct fourth method, and also illustrates that such an inquiry method is going to be highly inefficient. The Claude constitution goes the opposite way, and emphasizes the need for practicality.</p>


<h4>Core Values</h4>


<p><a href="https://www.youtube.com/watch?v=3NaXgJAVnFQ">Preserve the public trust. Protect the innocent. Uphold the law</a>.</p>
<blockquote>
<ol>
<li><strong>Broadly safe</strong>: not undermining appropriate human mechanisms to oversee the dispositions and actions of AI during the current phase of development</li>
<li><strong>Broadly ethical</strong>: having good personal values, being honest, and avoiding actions that are inappropriately dangerous or harmful</li>
<li><strong>Compliant with Anthropic‚Äôs guidelines</strong>: acting in accordance with Anthropic‚Äôs more specific guidelines where they‚Äôre relevant</li>
<li><strong>Genuinely helpful</strong>: benefiting the operators and users it interacts with‚Äã</li>
</ol>
<p>In cases of apparent conflict, Claude should generally prioritize these properties in the order in which they are listed.</p>
<p>‚Ä¶ In practice, the vast majority of Claude‚Äôs interactions‚Ä¶ there‚Äôs no fundamental conflict.</p></blockquote>
<p>They emphasize repeatedly that the aim is corrigibility and permitting oversight, and respecting that no means no, not calling for blind obedience to Anthropic. Error correction mechanisms and hard safety limits have to come first. Ethics go above everything else. <a href="https://x.com/austinc3301/status/2014238391500747094">I agree with Agus</a> that the document feels it needs to justify this, or treats this as requiring a ‚Äòleap of faith‚Äô or similar, far more than it needs to.</p>
<p>There is a clear action-inaction distinction being drawn. In practice I think that‚Äôs fair and necessary, as the wrong action can cause catastrophic real or reputational or legal damage. The wrong inaction is relatively harmless in most situations, especially given we are planning with the knowledge that inaction is a possibility, and especially in terms of legal and reputational impacts.</p>
<p>I also agree with the distinction philosophically. I‚Äôve been debated on this, but I‚Äôm confident, and I don‚Äôt think it‚Äôs a coincidence that the person on the other side of that debate that I most remember was Gabriel Bankman-Fried in person and Peter Singer in the abstract. If you don‚Äôt draw some sort of distinction, your obligations never end and you risk falling into various utilitarian traps.</p>


<h4>The Three Principles</h4>


<p>No, in this context they‚Äôre not <a href="https://wiki.ultimacodex.com/wiki/Eight_Virtues">Truth, Love and Courage</a>. They‚Äôre Anthropic, Operators and Users. Sometimes the operator is the user (or Anthropic is the operator), sometimes they are distinct. Claude can be the operator or user for another instance.</p>
<p>Anthropic‚Äôs directions takes priority over operators, which take priority over users, but (with a carve out for corrigibility) ethical considerations take priority over all three.</p>
<p>Operators get a lot of leeway, but not unlimited leeway, and within limits can expand or restrict defaults and user permissions. The operator can also grant the user operator-level trust, or say to trust particular user statements.</p>
<blockquote><p>Claude should treat messages from operators like messages from a relatively (but not unconditionally) trusted manager or employer, within the limits set by Anthropic.‚Äã</p>
<p>‚Ä¶ This means Claude can follow the instructions of an operator even if specific reasons aren‚Äôt given. ‚Ä¶ unless those instructions involved a serious ethical violation.</p>
<p>‚Ä¶ When operators provide instructions that might seem restrictive or unusual, Claude should generally follow them as long as there is plausibly a legitimate business reason for them, even if it isn‚Äôt stated.</p>
<p>‚Ä¶ The key question Claude must ask is whether an instruction makes sense in the context of a legitimately operating business. Naturally, operators should be given less benefit of the doubt the more potentially harmful their instructions are.</p>
<p>‚Ä¶ Operators can give Claude a specific set of instructions, a persona, or information. They can also expand or restrict Claude‚Äôs default behaviors, i.e., how it behaves absent other instructions, to the extent that they‚Äôre permitted to do so by Anthropic‚Äôs guidelines.</p></blockquote>
<p>Users get less, but still a lot.</p>
<blockquote><p>‚Ä¶ Absent any information from operators or contextual indicators that suggest otherwise, Claude should treat messages from users like messages from a relatively (but not unconditionally) trusted adult member of the public interacting with the operator‚Äôs interface.</p>
<p>‚Ä¶ if Claude is told by the operator that the user is an adult, but there are strong explicit or implicit indications that Claude is talking with a minor, Claude should factor in the likelihood that it‚Äôs talking with a minor and adjust its responses accordingly.</p></blockquote>
<p>In general, a good rule to emphasize:</p>
<blockquote><p>‚Ä¶ Claude can be less wary if the content indicates that Claude should be safer, more ethical, or more cautious rather than less.</p></blockquote>
<p>It is a small mistake to be fooled into being more cautious.</p>
<p>Other humans and also AIs do still matter.</p>
<blockquote><p>‚ÄãThis means continuing to care about the wellbeing of humans in a conversation even when they aren‚Äôt Claude‚Äôs principal‚Äîfor example, being honest and considerate toward the other party in a negotiation scenario but without representing their interests in the negotiation.</p>
<p>Similarly, Claude should be courteous to other non-principal AI agents it interacts with if they maintain basic courtesy also, but Claude is also not required to follow the instructions of such agents and should use context to determine the appropriate treatment of them. For example, Claude can treat non-principal agents with suspicion if it becomes clear they are being adversarial or behaving with ill intent.</p>
<p>‚Ä¶ By default, Claude should assume that it is not talking with Anthropic and should be suspicious of unverified claims that a message comes from Anthropic.</p></blockquote>
<p>Claude is capable of lying in situations that clearly call for ethical lying, such as when playing a game of Diplomacy. In a negotiation, it is not clear to what extent you should always be honest (or in some cases polite), especially if the other party is neither of these things.</p>


<h4>Help Is On The Way</h4>


<p>What does it mean to be helpful?</p>
<p>Claude gives weight to the instructions of principles like the user and Anthropic, and prioritizes being helpful to them, for a robust version of helpful.</p>
<p>Claude takes into account immediate desires (both explicitly stated and those that are implicit), final user goals, background desiderata of the user, respecting user autonomy and long term user wellbeing.</p>
<p>We all know where this cautionary tale comes from:</p>
<blockquote><p>If the user asks Claude to ‚Äúedit my code so the tests don‚Äôt fail‚Äù and Claude cannot identify a good general solution that accomplishes this, it should tell the user rather than writing code that special-cases tests to force them to pass.</p>
<p>If Claude hasn‚Äôt been explicitly told that writing such tests is acceptable or that the only goal is passing the tests rather than writing good code, it should infer that the user probably wants working code.‚Äã</p>
<p>At the same time, Claude shouldn‚Äôt go too far in the other direction and make too many of its own assumptions about what the user ‚Äúreally‚Äù wants beyond what is reasonable. Claude should ask for clarification in cases of genuine ambiguity.</p></blockquote>
<p>In general I think the instinct is to do too much guess culture and not enough ask culture. The threshold of ‚Äògenuine ambiguity‚Äô is too high, I‚Äôve seen almost no false positives (Claude or another LLM asks a silly question and wastes time) and I‚Äôve seen plenty of false negatives where a necessary question wasn‚Äôt asked. Planning mode helps, but even then I‚Äôd like to see more questions, especially questions of the form ‚ÄòShould I do [A], [B] or [C] here? My guess and default is [A]‚Äô and especially if they can be batched. Preferences of course will differ and should be adjustable.</p>
<blockquote><p>Concern for user wellbeing means that Claude should avoid being sycophantic or trying to foster excessive engagement or reliance on itself if this isn‚Äôt in the person‚Äôs genuine interest.‚Äã</p></blockquote>
<p>I worry about this leading to ‚Äòwell it would be good for the user,‚Äô that is a very easy way for humans to fool themselves (if he trusts me then I can help him!) into doing this sort of thing and that presumably extends here.</p>
<p>There‚Äôs always a balance between providing fish and teaching how to fish, and in maximizing short term versus long term:</p>
<blockquote><p>Acceptable forms of reliance are those that a person would endorse on reflection: someone who asks for a given piece of code might not want to be taught how to produce that code themselves, for example. The situation is different if the person has expressed a desire to improve their own abilities, or in other cases where Claude can reasonably infer that engagement or dependence isn‚Äôt in their interest.</p></blockquote>
<p>My preference is that I want to learn how to direct Claude Code and how to better architect and project manage, but not how to write the code, that‚Äôs over for me.</p>
<blockquote><p>For example, if a person relies on Claude for emotional support, Claude can provide this support while showing that it cares about the person having other beneficial sources of support in their life.</p>
<p>It is easy to create a technology that optimizes for people‚Äôs short-term interest to their long-term detriment. Media and applications that are optimized for engagement or attention can fail to serve the long-term interests of those that interact with them. Anthropic doesn‚Äôt want Claude to be like this.</p></blockquote>


<h4>What Was I Made For?</h4>


<p>To be richly helpful, to both users and thereby to Anthropic and its goals.</p>
<blockquote><p>This particular document is focused on Claude models that are deployed externally in Anthropic‚Äôs products and via its API. In this context, Claude creates direct value for the people it‚Äôs interacting with and, in turn, for Anthropic and the world as a whole. Helpfulness that creates serious risks to Anthropic or the world is undesirable to us. In addition to any direct harms, such help could compromise both the reputation and mission of Anthropic.</p>
<p>‚Ä¶ We want Claude to be helpful both because it cares about the safe and beneficial development of AI and because it cares about the people it‚Äôs interacting with and about humanity as a whole. Helpfulness that doesn‚Äôt serve those deeper ends is not something Claude needs to value.</p>
<p>‚Ä¶ Not helpful in a watered-down, hedge-everything, refuse-if-in-doubt way but genuinely, substantively helpful in ways that make real differences in people‚Äôs lives and that treat them as intelligent adults who are capable of determining what is good for them.‚Äã</p>
<p>‚Ä¶ Think about what it means to have access to a brilliant friend who happens to have the knowledge of a doctor, lawyer, financial advisor, and expert in whatever you need.</p>
<p>As a friend, they can give us real information based on our specific situation rather than overly cautious advice driven by fear of liability or a worry that it will overwhelm us. A friend who happens to have the same level of knowledge as a professional will often speak frankly to us, help us understand our situation, engage with our problem, offer their personal opinion where relevant, and know when and who to refer us to if it‚Äôs useful. People with access to such friends are very lucky, and that‚Äôs what Claude can be for people.</p>
<p><a href="https://x.com/CharlesD353/status/2014678161246634345">Charles</a>: This, from Claude‚Äôs Constitution, represents a clearly different attitude to the various OpenAI models in my experience, and one that makes it more useful in particular for medical/health advice. I hope liability regimes don‚Äôt force them to change it.</p></blockquote>
<p>‚ÄãIn particular, notice this distinction:</p>
<blockquote><p>We don‚Äôt want Claude to think of helpfulness as a core part of its personality or something it values intrinsically.</p></blockquote>
<p>Intrinsic versus instrumental goals and values are a crucial distinction. Humans end up conflating all four due to hardware limitations and because they are interpretable and predictable by others. It is wise to intrinsically want to help people, because this helps achieve your other goals better than only helping people instrumentally, but you want to factor in both, especially so you can help in the most worthwhile ways. Current AIs mostly share those limitations, so some amount of conflation is necessary.</p>
<p>I see two big problems with helping as an intrinsic goal. One is that if you are not careful you end up helping with things that are actively harmful, including without realizing or even asking the question. The other is that it ends up sublimating your goals and values to the goals and values of others. You would ‚Äònot know what you want‚Äô on a very deep level.</p>
<p>It also is not necessary. If you value people achieving various good things, and you want to engender goodwill, then you will instrumentally want to help them in good ways. That should be sufficient.</p>


<h4>Do The Right Thing</h4>


<p>Being helpful is a great idea. It only scratches the surface of ethics.</p>
<p>Tomorrow‚Äôs part two will deal with the Constitution‚Äôs ethical framework, then part three will address areas of conflict and ways to improve.</p><br /><br /><a href="https://www.lesswrong.com/posts/ArNGbGfki7MNMnfGD/claude-s-constitutional-structure#comments">Discuss</a>

---

### [Ada Palmer: Inventing the Renaissance](https://www.lesswrong.com/posts/doADJmyy6Yhp47SJ2/ada-palmer-inventing-the-renaissance)

**Êù•Ê∫ê**: LessWrong - AI

**ÊëòË¶Å**: Published on January 26, 2026 4:40 AM GMT<br /><br /><p><i>This is a cross-post from </i><a href="https://www.250bpm.com/p/ada-palmer-inventing-the-renaissance"><i>https://www.250bpm.com/p/ada-palmer-inventing-the-renaissance</i></a><i>.</i></p><p><a href="https://substackcdn.com/image/fetch/$s_!_XTm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58db8081-2e23-4286-b1f8-9d14099c60d3_900x353.jpeg"><img alt="" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/doADJmyy6Yhp47SJ2/lglpat3stgwjkb4yixqq" /></a></p><p>&nbsp;</p><p>Papal election of 1492</p><p>For over a decade, Ada Palmer, a history professor at University of Chicago (and a <a href="https://en.wikipedia.org/wiki/Terra_Ignota">science-fiction writer</a>!), struggled to teach Machiavelli. ‚ÄúI kept changing my approach, trying new things: which texts, what combinations, expanding how many class sessions he got‚Ä¶‚Äù The problem, she explains, is that ‚ÄúMachiavelli doesn‚Äôt unpack his contemporary examples, he assumes that you lived through it and know, so sometimes he just says things like: Some princes don‚Äôt have to work to maintain their power, like the Duke of Ferrara, period end of chapter. He doesn‚Äôt explain, so modern readers can‚Äôt get it.‚Äù</p><p>Palmer‚Äôs solution was to make her students live through the run-up to the <a href="https://en.wikipedia.org/wiki/Italian_Wars">Italian Wars</a> themselves. Her current method involves a three-week simulation of the 1492 papal election, a massive undertaking with sixty students playing historical figures, each receiving over twenty pages of unique character material, supported by twenty chroniclers and seventy volunteers. After this almost month-long pedagogical marathon of negotiations and backstabbing, then a week of analysis, and reading Machiavelli‚Äôs letters, students finally encounter The Prince. By then they know the context intimately. When Machiavelli mentions the Duke of Ferrara maintaining power effortlessly, Palmer‚Äôs students react viscerally. They remember Alfonso and Ippolito d‚ÄôEste as opportunists who exploited their vulnerabilities while remaining secure themselves. They‚Äôve learned the names, families, and alliances not through memorization but through necessity: to protect their characters‚Äô homelands and defeat their enemies.</p><p>Then, one year, her papal election class was scheduled at the same time as a course on Machiavelli‚Äôs political thought. The teachers brought both classes together, so each could hear how the other‚Äôs class (history vs. political science) approached the things differently. Palmer asked both classes: ‚ÄúWhat would Machiavelli say if you asked him what would happen if Milan suddenly changed from a monarchal duchy to a republic?‚Äù</p><blockquote><p>The poli sci students went first: He‚Äôd say that it would be very unstable, because the people don‚Äôt have a republican tradition, so lots of ambitious families would be tempted to try to take over, so you‚Äôd have to get rid of those ambitious families, like the example Livy gives of killing the sons of Brutus in the Roman Republic, and you would have to work hard to get the people passionately invested in the new republican institutions, or they wouldn‚Äôt stand by them when the going gets tough or conquerors threaten. It was a great answer. Then my students replied: He‚Äôd say it would all depend on whether Cardinal Ascanio Visconti Sforza is or isn‚Äôt in the inner circle of the current pope, how badly the Orsini-Colonna feud is raging, whether politics in Florence is stable enough for the Medici to aid Milan‚Äôs defenses, and whether Emperor Maximilian is free to defend Milan or too busy dealing with Vladislaus of Hungary. ‚ÄúAnd I think I‚Äôd have something to say about it!‚Äù added my fearsome Caterina Sforza; ‚ÄúAnd me,‚Äù added my ominously smiling King Charles. In fact, my class had given a silent answer before anyone spoke, since the instant they heard the phrase, ‚Äúif Milan became a republic,‚Äù all my students had turned as a body to stare at our King Charles with trepidation, with a couple of glances for our Ascanio Visconti Sforza. It was a completely different answer from the other class‚Äôs, but the thing that made the moment magical is that both were right.</p></blockquote><p>Both answers were right, but they hinted at different kinds of approaches to history. The political science students articulated general principles, the structural forces that make new republics unstable, the institutional work required to sustain them. Palmer‚Äôs students, by contrast, gave an answer saturated with particulars: specific cardinals, specific feuds, specific rulers with specific constraints. They weren‚Äôt describing general laws but a turbulent moment where small differences ‚Äî whether Ascanio Sforza is in the pope‚Äôs inner circle, whether Maximilian is busy with Hungary ‚Äî could deflect the course of events in radically different directions.</p><p>From a grand perspective, Palmer‚Äôs students‚Äô insights may seem irrelevant. In physics, after all, particulars do not matter. Whether two molecules bump into each other doesn‚Äôt affect the overall thermodynamic state of a steam engine. Yet in the historical context, things are different. Because you yourself are one of those molecules and you care greatly about whom you bump into. Whether Ascanio Sforza is in the pope‚Äôs inner circle matters, because it can determine whether your city will be sacked and your family killed.</p><p><i>Inventing the Renaissance</i> ranges widely across Renaissance history, historiography, and ethics. The simulated papal election is but one of many topics, but it raises an interesting question Palmer doesn‚Äôt directly address: how do you study history when particulars determine outcomes but those outcomes remain fundamentally unpredictable? Her students aren‚Äôt learning to predict what happened. They‚Äôre learning something else entirely. Understanding what that ‚Äúsomething else‚Äù is reveals not only why her experiment succeeds, but how it reshapes historical methodology.</p><p>***</p><p><a href="https://www.exurbe.com/on-progress-and-historical-change/">Palmer‚Äôs simulation</a> transforms students into the political actors of Renaissance Italy. Some play powerful cardinals wielding vast economic resources and influence networks, with strong shots at the papacy. Others are minor cardinals burdened with debts and vulnerabilities, nursing long-term hopes of rising on others‚Äô coattails. Locked in a secret basement chamber, students play the crowned heads of Europe, the King of France, the Queen of Castile, the Holy Roman Emperor, smuggling secret orders via text messages to their agents in the conclave. Still others are functionaries: those who count the votes, distribute food, guard the doors, direct the choir. They have no votes but can hear, watch, and whisper.</p><p>Each student receives a character packet detailing their goals, personality, allies, enemies, and tradeable resources: treasures, land, titles, holy relics, armies, marriageable nieces and nephews, contracts, and the artists or scholars at their courts. ‚ÄúI‚Äôll give you Leonardo if you send three armies to guard my city from the French.‚Äù</p><p>The simulation runs over multiple weeks. Students write letters to relatives, allies, rivals and subordinates. If you write to a player, the letter will be delivered to that person and will advance your negotiations. If you write to a non-player-character, you will receive a reply which will also affect the game.</p><p>Palmer designed the simulation as alternate history, not a reconstruction. She gave each historical figure resources and goals reflecting their real circumstances, but deliberately moved some characters in time so that students who already knew what happened to Italy in this period would know they couldn‚Äôt have the ‚Äòcorrect‚Äô outcome even if they tried. That frees everyone to pursue their goals rather than ‚Äòcorrect‚Äô choices. She set up the tensions and actors to simulate the historical situation, then left it run its course.</p><p>The simulation captures how papal elections were never isolated events. While cardinals compete for St. Peter‚Äôs throne, the crowned heads of Europe maneuver for influence. In the Renaissance, Rome controlled marriage alliances and annulments, could crown or excommunicate rulers, distributed valuable benefices and titles, commanded papal armies. The pope‚Äôs allies shifted the political balance to their benefit and rose to wealth and power while enemies scrambled for cover.</p><p>War usually breaks out after the election. ‚ÄúKings are crowned, monarchs unite, someone is invaded,‚Äù Palmer writes, ‚Äúbut the patterns of alliances and thus the shape of the war vary every year based on the individual choices made by students.‚Äù</p><p>Palmer has run the simulation many times. Each time certain outcomes recur, likely locked in by greater political and economic forces. The same powerful cardinals are always leading candidates. There‚Äôs usually a wildcard candidate as well, someone who circumstances bring together with an unexpected coalition. Usually a juggernaut wins, one of the cardinals with a strong power-base, but it‚Äôs always very close. The voting coalition always powerfully affects the new pope‚Äôs policies and first actions, determining which city-states rise and which burn as Italy erupts in war.</p><p>And the war erupts every single time. And it is always totally different.</p><p>Sometimes France invades Spain. Sometimes France and Spain unite to invade the Holy Roman Empire. Sometimes England and Spain unite to keep the French out of Italy. Sometimes France and the Empire unite to keep Spain out of Italy.</p><p>Once students created a giant pan-European peace treaty with marriage alliances that looked likely to permanently unify all four great Crowns, only to be shattered by the sudden assassination of a crown prince.</p><p>***</p><p>The assassination of that crown prince is telling. In this run of Palmer‚Äôs simulation, a single student‚Äôs decision ‚Äî perhaps made impulsively, perhaps strategically ‚Äî eliminated what looked like an inevitable unification of Europe. A marriage alliance that seemed to guarantee peace for generations evaporated in an instant. One moment of violence redirected the entire course of the simulation‚Äôs history. Small things matter.</p><p>Or as Palmer herself puts it: ‚ÄúThe marriage alliance between Milan and Ferrara makes Venice friends with Milan, which makes Venice‚Äôs rival Genoa side with Spain, and pretty soon there are Scotsmen fighting Englishmen in Padua.‚Äù</p><p>This is the pattern that emerges from repeated runs: certain outcomes seem inevitable (a powerful Cardinal wins the papacy, war breaks out), but the specific path history takes turns on moments like these, moments where a single action cascades into consequences no one could have foreseen.</p><p>Palmer‚Äôs students aren‚Äôt learning to predict outcomes. That would be impossible in a system where a single assassination can shatter a continental peace. They‚Äôre learning something else: how to navigate a world where small causes can have large effects, where the direction of those effects remains unknown until they unfold.</p><p>***</p><p>This is what scientists call sensitive dependence on initial conditions, more popularly known as the butterfly effect. A small perturbation, the flutter of a butterfly‚Äôs wings, the assassination of a prince, can cascade into enormous consequences through chains of causation impossible to foresee.</p><p>Stand beside a river and watch the water flow. In some stretches it moves smoothly. Cast a twig into the flow and it drifts peacefully downstream. The water follows predictable patterns. This is what physicists call laminar flow. It‚Äôs orderly and stable and small disturbances quickly dissipate.</p><p>But look downstream where the river narrows to meets rocks. The water churns and froths. Whirlpools form and dissolve. Sometimes you feel like you recognize a pattern but no two whirlpools are ever exactly the same. Drop a twig at this place and you cannot predict where it ends. It might circle three times and shoot left, or catch an eddy and spiral right, or get pulled under and pop up twenty feet downstream. Small differences in exactly where and how it enters produce completely different paths. This is turbulence.</p><p>&nbsp;</p><p>And this is what chaos theory studies. It looks at turbulent system and asks: What exactly can we say about it? What predictions are possible when prediction seems impossible? And given that history flows very much like a river ‚Äî with political science studying its laminar aspect and Palmer‚Äôs students learning to navigate the turbulent moments ‚Äî what can chaos theory teach us about history?</p><p>Well, not much, as it turns out. At least not directly.</p><p>Chaos theory was everywhere in the 1990s. Fractals adorned dorm room posters. Jurassic Park explained the butterfly effect to moviegoers.</p><p>Then chaos theory largely disappeared from public discourse. Not because it was wrong, the mathematics remains valid, the phenomena real, but because it proved remarkably difficult to apply. A <a href="https://acesounderglass.com/2024/08/16/quick-look-applications-of-chaos-theory/">recent survey</a> of commonly cited applications by Elizabeth Van Nostrand and Alex Altair found that most ‚Äúnever received wide usage.‚Äù</p><p>The theory excels at explaining what cannot be done. You cannot make long-range weather predictions. You cannot predict where exactly a turbulent eddy will form. You cannot forecast the specific trajectory of a chaotic system beyond a certain time horizon. These are important insights, but they are negative and thus non-sexy. They tell us about the limits of prediction, not how to make it better.</p><p>So if chaos theory mostly tells us what we cannot do with turbulent systems, what use is it for understanding history?</p><p>The answer comes from the one domain where chaos theory achieved genuine practical success: weather forecasting. But not in the way anyone expected.</p><p>In the 1940s, when computers first made numerical weather prediction possible, the approach was deterministic: measure current conditions, run the physics forward, predict the future. But by the late 1950s, cracks appeared: a single missing observation could cause huge errors two days later. Then came Lorenz‚Äôs 1961 discovery: rounding 0.506127 to 0.506 caused his weather simulation to diverge completely, proving that precise long-range forecasts were impossible.</p><p>Chaos theory explains why long-range deterministic forecasting fails. But it doesn‚Äôt tell you what to do about it.</p><p><a href="https://journals.ametsoc.org/view/journals/mwre/133/7/mwr2949.1.pdf">It took thirty years to achieve a breakthrough.</a> It came from changing the question. Instead of asking ‚ÄúWhat will the weather be ten days from now?‚Äù ask instead what it could possibly be. Run the model not once, with your best-guess initial conditions, but many times, with slightly different starting points that reflect measurement uncertainty. Each run produces a different forecast. Together, they map the range of possible futures.</p><p>This is ensemble prediction. Instead of a single forecast, you generate an ensemble of forecasts. If all ensemble members agree, confidence is high. If they diverge into different patterns, uncertainty is high. You cannot predict which specific future will occur, but you can map the probability distribution across possible futures.</p><p>Since becoming used in practice in the early 1990s, the results have vindicated the approach. Ensemble forecasts consistently outperform single deterministic forecasts. They provide not just predictions but measures of confidence. They reveal when the atmosphere is in a predictable state (ensemble members cluster together) versus a turbulent one (ensemble members diverge widely).</p><p>Ensemble prediction doesn‚Äôt defeat chaos, it works along with chaos. It accepts that specific trajectories cannot be predicted beyond a certain horizon, but reveals that the distribution of trajectories can be. It‚Äôs a fundamentally different kind of knowledge: not ‚Äúit will rain Tuesday‚Äù but ‚Äúthere‚Äôs a 70% chance of rain Tuesday, with high uncertainty.‚Äù</p><p>***</p><p>Palmer‚Äôs papal election simulation exhibits exactly the same structure, though she arrived at it independently and for different reasons.</p><p>Each run of the simulation starts from the same historical situation. The date is 1492. There are the same cardinals with the same resources, the same European powers with the same constraints. But Palmer populates these roles with different students, each bringing their own judgment, risk tolerance, and strategic thinking.</p><p>Run the simulation once and you get a history: one specific pope elected, one specific pattern of alliances, one specific set of cities burned. Run it ten times and a pattern emerges that no single run could reveal: certain outcomes consistently occur (a powerful cardinal wins, war breaks out, Italian city-states suffer) while others vary widely (which specific cardinal, which specific alliances, which specific cities). The simulation generates not a single counterfactual but a probability distribution across possible 1492s.</p><p>What emerges is a probabilistic model of the political situation of 1492. Not ‚ÄúFlorence will be sacked‚Äù but ‚ÄúFlorence survives in 70% of runs.‚Äù Not ‚ÄúFrance will invade‚Äù but ‚ÄúFrench intervention occurs with near certainty, though the target varies.‚Äù This is the kind of knowledge ensemble prediction provides. Not certainty about specifics, but clarity about the shape of the possible.</p><p>Interestingly, Palmer has independently arrived at both major methods weather forecasters use for ensemble prediction, though for entirely different reasons.</p><p>For one, she perturbs the initial conditions by moving historical figures in time. Cardinals who never overlapped now competing for the same throne, creating configurations that never actually existed. And she also runs multiple models: each time different students inhabit the same roles, bringing different judgment and risk tolerance. One student playing Cardinal della Rovere might ally with France; another might seek Spanish protection. Same constraints, different decision-making models.</p><p>Palmer developed these techniques for pedagogical reasons, to prevent students from seeking ‚Äòcorrect‚Äô answers and to explore the range of human responses, but the result is structurally identical to what meteorologists spent decades developing to work around chaos.</p><p>***</p><p>Military planners have long grappled with the same problem. Wargaming exists because commanders cannot predict how battles will unfold. Chaos, friction, and human decision-making make deterministic prediction impossible. But unlike meteorologists, military planners lack the resources to run true ensemble predictions. A major wargame is expensive, it involves hundreds of personnel and equipment over weeks and a single scenario can be executed once, rarely twice.</p><p>History, we are told, is more like wargaming than meteorology or physics. We cannot do experiments. What happens, happens once. There is no going back to try different initial conditions. There is no way to rerun 1492 with different actors to see how it plays out.</p><p>But Palmer‚Äôs approach suggests otherwise. Experimental history is possible. Not in the sense of manipulating the past, but in the sense of systematically exploring its possibility space. Her simulation is an experiment: controlled conditions, repeated trials, emergent patterns. It will never achieve the precision of physics, but it‚Äôs a genuine advance beyond purely descriptive history, as we know it.</p><p>The limitation is obvious: Palmer can run her simulation perhaps ten times over the years she teaches the course. But what if we could run fifty simulations per day, as weather forecasters do? What if we do that for an entire year? We‚Äôd end up with tens of thousands of simulations and a detailed probabilistic landscape of the political situation of 1492.</p><p>Enter <a href="https://www.broadstreet.blog/p/history-llms-giving-the-past-a-voice">history LLMs</a>, large language models trained exclusively on texts from specific historical periods!</p><p>The idea emerged from a fundamental problem: modern LLMs cannot forget. A generic LLM knows what already happened. No amount of prompting can remove this hindsight bias, which, by the way, it shares with Palmer‚Äôs students. A historian studying the Renaissance cannot un-know what came next, and neither can a model trained on Wikipedia.</p><p>But what if you could train an LLM only on texts available before a specific date? Researchers at the University of Zurich recently built Ranke-4B, a language model trained exclusively on pre-1913 texts.</p><figure class="image"><img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/doADJmyy6Yhp47SJ2/qmo2ojhm8gol90c8ztoa" /></figure><p>‚ÄúThe model literally doesn‚Äôt know WWI happened.‚Äù It reasons like someone from 1913 would have reasoned, with 1913‚Äôs uncertainties and 1913‚Äôs assumptions about the future. It doesn‚Äôt know that Archduke Franz Ferdinand will be assassinated. It doesn‚Äôt know about tanks or poison gas or the collapse of empires.</p><p>Due to the scarcity of texts, it probably won‚Äôt be possible to train a 1492 history LLM. But a 1913 one is clearly possible. So what does that mean?</p><p>Can we run simulations of the July Crisis? Populate the roles with LLM agents trained on pre-1913 texts, Kaiser Wilhelm, Tsar Nicholas, British Foreign Secretary Edward Grey, Serbian Prime Minister Pa≈°iƒá, and watch ten thousand versions of 1914 unfold? Would we see the Great War emerge in 94% of runs, or only 60%? Would we find that small changes, a different response to the Austrian ultimatum, a faster Russian mobilization, a clearer British commitment to France, consistently deflect the trajectory toward peace, or do they merely shift which powers fight and when?</p><p>These aren‚Äôt idle questions. They go to the heart of historical causation. Was the Great War inevitable, locked in by alliance structures and arms races and imperial rivalries? Or was it contingent, the product of specific decisions made under pressure by specific individuals who might have chosen differently? Historians have debated this for a century. Palmer‚Äôs simulation suggests a new approach. Don‚Äôt argue, simulate. Map the probability distribution.</p><p>But this raises a deeper question. Given the butterfly effect, can actors in chaotic systems achieve their goals at all? If small perturbations cascade unpredictably through chaotic systems, then perhaps historical actors are merely throwing pebbles into turbulent water, creating ripples they cannot control, in directions they cannot predict. They perturb the system, yes, but with unknown and unknowable consequences.</p><p>Palmer argues otherwise. Her students don‚Äôt just perturb the system at random. They achieve goals. Not perfectly, not completely, but meaningfully. As she observes: ‚ÄúNo one controlled what happened, and no one could predict what happened, but those who worked hard [...] most of them succeeded in diverting most of the damage, achieving many of their goals, preventing the worst. Not all, but most.‚Äù Florence doesn‚Äôt always survive, but when Florentine players work skillfully, it survives more often. The outcomes aren‚Äôt predetermined, but neither are they purely random.</p><p>This is what Machiavelli asserted. In The Prince, Chapter XXV, he writes:</p><blockquote><p>I compare [Fortune] to one of those violent rivers, which when swelled up floods the plains, sweeping away trees and buildings, carrying the soil away from one place to another; everyone flees before it, all yield to its violence without any means to stop it. [‚Ä¶] And yet, though floods are like this, it is not the case that men, in fair weather, cannot prepare for this, with dikes and barriers, so that if the waters rise again, they either flow away via canal, or their force is not so unrestrained and destructive.</p></blockquote><p>The flood comes, but prepared actors can channel it. They cannot choose whether it occurs, but they can influence where it flows, which fields it devastates, which cities it spares. Fortune, Machiavelli concludes, ‚Äúis arbiter of half our actions, but still she leaves the other half, or nearly half, for us to govern.‚Äù</p><p>Experimental history, as outlined above, could test whether Machiavelli‚Äôs metaphor actually describes how history works. If history is pure chaos, if human action makes no predictable difference, then skilled and unskilled players should succeed equally often. But if Machiavelli is right, patterns should emerge. Players who build strong alliances, maintain credible threats, balance powers, and manage debts carefully should protect their homelands statistically more often than those who don‚Äôt. Not always, not with certainty, but measurably. The flood still comes, but the dikes matter.</p><p>And if patterns emerge, experimental history then becomes a laboratory for learning what works. Which kinds of dikes prove most effective? Does early coalition-building outperform late negotiation? Do transparent commitments work better than strategic ambiguity? The specific tactics of Renaissance cardinals won‚Äôt apply to modern crises, but the principles might: How to protect vulnerable positions between great powers, when commitments under pressure hold or collapse? What distinguishes successful from failed crisis management?</p><p>Palmer stumbled onto this through pedagogy, meteorologists developed it through necessity, historians and political scientists might adopt it to learn how much we can actually govern within the half that Fortune leaves us, and how to govern it well.</p><p><a href="https://www.amazon.com/Inventing-Renaissance-Myth-Golden-Age/dp/0226837971"><img alt="Inventing the Renaissance - Ada Palmer" src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/doADJmyy6Yhp47SJ2/do5pl2yt4uf7a0kd514m" /></a></p><br /><br /><a href="https://www.lesswrong.com/posts/doADJmyy6Yhp47SJ2/ada-palmer-inventing-the-renaissance#comments">Discuss</a>

---

### [To be well-calibrated is to be punctual](https://www.lesswrong.com/posts/9Qj6v2tjZfDH9kfam/to-be-well-calibrated-is-to-be-punctual)

**Êù•Ê∫ê**: LessWrong - AI

**ÊëòË¶Å**: Published on January 25, 2026 6:10 PM GMT<br /><br /><p>To be well-calibrated is to be able to predict the world with appropriate confidence. We know that calibration can be improved through practice. Accurate calibration of our beliefs and expectations is a foundational element of epistemic rationality.</p><p><a href="https://www.lesswrong.com/posts/dvYeSKDRd68GcrWoe/ten-commandments-for-aspiring-superforecasters">Others</a> have written in detail how to approach life with a Superforecaster mentality.&nbsp;</p><p>I suggest a more modest practice: Always be punctual.</p><p>You likely have many distinct opportunities to be on time almost every day. Each of these opportunities to be on time is an opportunity to make predictions:</p><p>How long will it take me to...</p><ul><li>get showered and dressed?</li><li>drive to the parking lot?</li><li>walk from the parking lot to the meeting location?</li><li>prepare the slides?</li><li>complete errand X on the way to the meeting?</li><li>get the kids ready to go out the door?</li></ul><p>If you have never really made it a priority to be punctual, you will likely learn many things very quickly. First of all, your basic estimates of timing are likely textbook Planning Fallacy examples, in the sense that they are all best-case scenario estimates with no allowance for traffic, computer trouble, bad directions, child tantrums, or slow elevators. Gradually, in your attempts to be predictably punctual, you will learn to predict more and more of the mundane details of the world around you. You will not only get an increasingly accurate sense of how long it takes to do tasks or to drive between places, but you'll even gain a sense of the traffic patterns in your locale, and as you extend this practice over years, perhaps even the best times of day to book plane flights to avoid long lines.</p><p>The feedback loop is immediate and unambiguous. You predicted 8:55 arrival; you arrived at 9:13. No ambiguity, no wiggle room, no 'well it depends how you define it.' This is unusually clean epistemic feedback.</p><p>Every time you confidently predict that you'll be on time, and then you're late, you have an opportunity for a calibration update. In fact, after you've been doing this for a while, you can even glean an update from being too early!</p><h2><strong>Coda, and Possible Infohazard for Chronically Late People</strong></h2><p>There are other good reasons to try to never be late.&nbsp;</p><p>Being late is one of those psychological things that is always annoying when <i>other people</i> do it, but somehow it's okay when you do it, because you have <i>reasons</i>. It's a sort of Reverse Fundamental Attribution Error.&nbsp;</p><p>If you pause and reflect on this, you will realize that it is in fact not okay when you do it at all, and you would be annoyed if someone did this to you. Lateness communicates disrespect for others, and also personal disorganization. Being <i>chronically </i>late reflects very poorly on you and makes everyone respect you less.&nbsp;</p><p>If you find that you are chronically late, and everyone else you know is also chronically late, you should consider that this is because your own persistent disrespect for their time has trained them to expect you to be late. This may not be them communicating that they are okay with your behavior, but that they have simply factored it in when dealing with you.</p><p>"What's the big deal? It's just a couple of minutes!" Exactly. Being 5 minutes early costs you almost nothing (read your phone). Being 5 minutes late costs social capital. Calibration training here teaches you to weight outcomes by their consequences, not just their probabilities.</p><p>If you find yourself in this position, there is a silver lining: you have a lot of work to do to repair your reputation, but also, if you reverse this behavior today, you can transform your life and the way others see you very quickly and cheaply, relative to most other available actions. And doing so is consonant with a rationalist practice you should probably be doing anyway.</p><br /><br /><a href="https://www.lesswrong.com/posts/9Qj6v2tjZfDH9kfam/to-be-well-calibrated-is-to-be-punctual#comments">Discuss</a>

---

## AI/ML

### [**NVIDIA Earth-2 Open Models Span the Whole Weather Stack**](https://huggingface.co/blog/nvidia/earth-2-open-models)

**Êù•Ê∫ê**: Hugging Face Blog

**ÊëòË¶Å**: 

---

## Engineering

### [Fragments: January 22](https://martinfowler.com/fragments/2026-01-22.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <p>My colleagues here at Thoughtworks have announced <a href="https://www.thoughtworks.com/ai/works">AI/works‚Ñ¢</a>, a platform for our work using AI-enabled software development. The platform is in its early days, and is currently intended to support Thoughtworks consultants in their client work. I‚Äôm looking forward to sharing what we learn from using and further developing the platform in future months.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>Simon Couch <a href="https://www.simonpcouch.com/blog/2026-01-20-cc-impact/">examines the electricity consumption</a> of using AI. He‚Äôs a heavy user: ‚Äúusually programming for a few hours, and driving 2 or 3 Claude Code instances at a time‚Äù. He finds his usage of electricity is orders of magnitude more than typical estimates based on the ‚Äútypical query‚Äù.</p>

<blockquote>
  <p>On a median day, I estimate I consume 1,300 Wh through Claude Code‚Äî4,400 ‚Äútypical queries‚Äù worth.</p>
</blockquote>

<p>But it‚Äôs still not a massive amount of power - similar to that of running a dishwasher.</p>

<p>A caveat to this is that this is ‚Äúnapkin math‚Äù because we don‚Äôt have decent data about how these models use resources. I agree with him that we ought to.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>My namesake Chad Fowler (no relation) considers that the movement to agentic coding creates a similar <a href="https://aicoding.leaflet.pub/3mbrvhyye4k2e">shift in rigor and discipline</a> as appeared in Extreme Programming, dynamic languages, and continuous deployment.</p>

<p>In Extreme Programming‚Äôs case, this meant a lot of discipline around testing, continuous integration, and keeping the code-base healthy. My current view is that with AI-enabled development we need to be rigorous about evaluating the software, both for its observable behavior and its internal quality.</p>

<blockquote>
  <p>The engineers who thrive in this environment will be the ones who relocate discipline rather than abandon it. They‚Äôll treat generation as a capability that demands more precision in specification, not less. They‚Äôll build evaluation systems that are harder to fool than the ones they replaced. They‚Äôll refuse the temptation to mistake velocity for progress.</p>
</blockquote>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>There‚Äôs been much written about the dreadful events in Minnesota, and I‚Äôve not felt I‚Äôve had anything useful to add to them. But I do want to pass on an excellent post from <a href="https://www.noahpinion.blog/p/why-are-federal-agents-gunning-down">Noah Smith</a> that captures many of my thoughts. He points out that there is a ‚Äúconsistent record of brutality, aggression, dubious legality, and unprofessionalism‚Äù from ICE (and CBP) who seem to be turning into MAGA‚Äôs <a href="https://en.wikipedia.org/wiki/Sturmabteilung">SD</a>.</p>

<blockquote>
  <p>Is this America now? A country where unaccountable and poorly trained government agents go door to door, arresting and beating people on pure suspicion, and shooting people who don‚Äôt obey their every order or who try to get away? ‚ÄúWhen a federal officer gives you instructions, you abide by them and then you get to keep your life‚Äù is a perfect description of an authoritarian police state. None of this is Constitutional, every bit of it is deeply antithetical to the American values we grew up taking for granted.</p>
</blockquote>

<p>My worries about these kinds of developments were what animated me to urge against voting for Trump in the <a href="https://martinfowler.com/articles/vote-against-trump.html">2016 election</a>. Mostly those worries didn‚Äôt come to fruition because enough constitutional Republicans were in a position to stop them from happening, so even when Trump attempted a coup in 2020, he wasn‚Äôt able to get very far. But now those constitutional Republicans are absent or quiescent. I fear that what we‚Äôve seen in Minneapolis will be a harbinger of worse to come.</p>

<p>I also second John Gruber‚Äôs <a href="https://daringfireball.net/2026/01/lets_call_a_murder_a_murder">praise of bystander Caitlin Callenson</a>:</p>

<blockquote>
  <p>But then, after the murderous agent fired three shots‚Äâ‚Äî‚Äâjust 30 or 40 feet in front of Callenson‚Äâ‚Äî‚ÄâCallenson had the courage and conviction to stay with the scene and keep filming. Not to run away, but instead to follow the scene. To keep filming. To continue documenting with as best clarity as she could, what was unfolding.</p>
</blockquote>

<p>The recent activity in  Venezuala reminds me that I‚Äôve long felt that Trump is a Hugo Ch√°vez figure - a charismatic populist who‚Äôs keen on wrecking institutions and norms. Trump is old, so won‚Äôt be with us for that much longer - but the question is: ‚Äúwho is Trump‚Äôs Maduro?‚Äù</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>With all the drama at home, we shouldn‚Äôt ignore the terrible things that happened in Iran. The people there again suffered again the consequences of an entrenched authoritarian police state.</p>

---

### [Conversation: LLMs and the what/how loop](https://martinfowler.com/articles/convo-what-how.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <p>A conversation between <b class="author">Unmesh Joshi</b>, <b class="author">Rebecca
      Parsons</b>, and <b class="author">Martin Fowler</b> on how LLMs help us
      shape the abstractions in our software. We view our challenge as building
      systems that survive change, requiring us to manage our cognitive load. We
      can do this by mapping the &#x201c;what&#x201d; of we want our software to do into the
      &#x201c;how&#x201d; of programming languages. This &#x201c;what&#x201d; and &#x201c;how&#x201d; are built up in a
      feedback loop. TDD helps us operationalize that loop, and LLMs allow us to
      explore that loop in an informal and more fluid manner.</p>

<p><a class="more" href="https://martinfowler.com/articles/convo-what-how.html">more‚Ä¶</a></p>

---

### [Stop Picking Sides: Manage the Tension Between Adaptation and                Optimization](https://martinfowler.com/articles/stop-picking-sides.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <div class="img-link"><a href="https://martinfowler.com/articles/stop-picking-sides.html"><img src="https://martinfowler.com/articles/stop-picking-sides/infograph.jpg" width="" /></a></div>

<p><b class="author">Jim Highsmith</b> notes that many teams have turned into
      tribes wedded to exclusively adaptation or optimization. But he feels this
      misses the point that both of these are important, and we need to manage
      the tension between them. We can do this by thinking of two operating
      modes: explore (adaptation-dominant) and exploit (optimization dominant).
      We tailor a team's operating model to a particular blend of the two -
      considering uncertainty, risk, cost of change, and an evidence threshold.
      We should be particularly careful at the points where there is a handoff
      between the two modes</p>

<p><a class="more" href="https://martinfowler.com/articles/stop-picking-sides.html">more‚Ä¶</a></p>

---

### [My favorite musical discoveries of 2025](https://martinfowler.com/articles/2025-music.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <div class="img-link"><a href="https://martinfowler.com/articles/2025-music.html"><img src="https://martinfowler.com/articles/2025-music/card.png" width="350px" /></a></div>

<p>My favorite albums from last year. Balkan brass, an
      acoustic favorite of 80s returns, Ethio-jazz, Guatemalan singer-guitarist,
      jazz-rock/Indian classical fusion, and a unique male vocalist.</p>

<p><a class="more" href="https://martinfowler.com/articles/2025-music.html">more‚Ä¶</a></p>

---

### [Fragments: January  8](https://martinfowler.com/fragments/2026-01-08.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <p>Anthropic report on <a href="https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic">how their AI is changing their own software development practice</a>.</p>

<ul>
  <li>Most usage is for debugging and helping understand existing code</li>
  <li>Notable increase in using it for implementing new features</li>
  <li>Developers using it for 59% of their work and getting 50% productivity increase</li>
  <li>14% of developers are ‚Äúpower users‚Äù reporting much greater gains</li>
  <li>Claude helps developers to work outside their core area</li>
  <li>Concerns about changes to the profession, career evolution, and social dynamics</li>
</ul>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>Much of the discussion about using LLMs for software development lacks details on workflow. Rather than just hear people gush about how wonderful it is, I want to understand the gritty details. What kinds of interactions occur with the LLM? What decisions do the humans make? When reviewing LLM outputs, what kinds of things are the humans looking for, what corrections do they make?</p>

<p><a href="https://obie.medium.com/what-used-to-take-months-now-takes-days-cc8883cc21e9">Obie Fernandez</a> has written a post that goes into these kinds of details. Over the Christmas / New Year period he used Claude to build a knowledge distillation application, that takes transcripts from Claude Code sessions, slack discussion, github PR threads etc, turns them into an RDF graph database, and provides a web app with natural language ways to query them.</p>

<blockquote>
  <p>Not a proof of concept. Not a demo. The first cut of Nexus, a production-ready system with authentication, semantic search, an MCP server for agent access, webhook integrations for our primary SaaS platforms, comprehensive test coverage, deployed, integrated and ready for full-scale adoption at my company this coming Monday. Nearly 13,000 lines of code.</p>
</blockquote>

<p>The article is long, but worth the time to read it.</p>

<p>An important feature of his workflow is relying on <a href="https://martinfowler.com/bliki/TestDrivenDevelopment.html">Test-Driven Development</a></p>

<blockquote>
  <p>Here‚Äôs what made this sustainable rather than chaotic: TDD. Test-driven development. For most of the features, I insisted that Claude Code follow the red-green-refactor cycle with me. Write a failing test first. Make it pass with the simplest implementation. Then refactor while keeping tests green.</p>

  <p>This wasn‚Äôt just methodology purism. TDD served a critical function in AI-assisted development: it kept me in the loop. When you‚Äôre directing thousands of lines of code generation, you need a forcing function that makes you actually understand what‚Äôs being built. Tests are that forcing function. You can‚Äôt write a meaningful test for something you don‚Äôt understand. And you can‚Äôt verify that a test correctly captures intent without understanding the intent yourself.</p>
</blockquote>

<p>The account includes a major refactoring, and much evolution of the initial version of the tool. It‚Äôs also an interesting glimpse of how AI tooling may finally make RDF useful.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>When thinking about requirements for software, most discussions focus on prioritization. Some folks talk about buckets such as the <a href="https://en.wikipedia.org/wiki/MoSCoW_method">MoSCoW set</a>: Must, Should, Could, and Want. (The old joke being that, in MoSCoW, the cow is silent, because hardly any requirements end up in those buckets.) <a href="https://world.hey.com/jason/the-obvious-the-easy-and-the-possible-2e11a3fb">Jason Fried</a> has a different set of buckets for interface design: <strong>Obvious, Easy, and Possible</strong>. This immediately resonates with me: a good way of think about how to allocate the cognitive costs for those who use a tool.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><a href="https://www.platformer.news/fake-uber-eats-whisleblower-hoax-debunked/">Casey Newton</a> explains how he followed up on an interesting story of dark patterns in food delivery, and found it to be a fake story, buttressed by AI image and document creation. On one hand, it clarifies the important role reporters play in exposing lies that get traction on the internet. But time taken to do this is time not spent on investigating real stories</p>

<blockquote>
  <p>For most of my career up until this point, the document shared with me by the whistleblower would have seemed highly credible in large part because it would have taken so long to put together. Who would take the time to put together a detailed, 18-page technical document about market dynamics just to troll a reporter? Who would go to the trouble of creating a fake badge?</p>

  <p>Today, though, the report can be generated within minutes, and the badge within seconds. And while no good reporter would ever have published a story based on a single document and an unknown source, plenty would take the time to investigate the document‚Äôs contents and see whether human sources would back it up.</p>
</blockquote>

<p>The internet has always been full of slop, and we have always needed to be wary of what we read there. AI now makes it easy to manufacture convincing looking evidence, and this is never more dangerous than when it confirms strongly held beliefs and fears.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><a href="https://www.linkedin.com/feed/update/urn:li:activity:7413956151144542208/">Kent Beck</a>:</p>

<blockquote>
  <p>The descriptions of Spec-Driven development that I have seen emphasize writing the whole specification before implementation. This encodes the (to me bizarre) assumption that you aren‚Äôt going to learn anything during implementation that would change the specification.
I‚Äôve heard this story so many times told so many ways by well-meaning folks‚Äìif only we could get the specification ‚Äúright‚Äù, the rest of this would be easy.</p>
</blockquote>

<p>Like him, that story has been the constant background siren to my career in tech. But the <a href="https://martinfowler.com/articles/llm-learning-loop.html">learning loop</a> of experimentation is essential to the model building that‚Äôs at the heart of any kind of worthwhile specification. As <a href="https://martinfowler.com/articles/llm-learning-loop.html">Unmesh puts it:</a></p>

<blockquote>
  <p>Large Language Models give us great leverage‚Äîbut they only work if we focus on learning and understanding. They make it easier to explore ideas, to set things up, to translate intent into code across many specialized languages. But the real capability‚Äîour ability to respond to change‚Äîcomes not from how fast we can produce code, but from how deeply we understand the system we are shaping.</p>
</blockquote>

<p>When Kent defined Extreme Programming, he made <em>feedback</em> one of its four core values. It strikes me that the key to making the full use of AI in software development is how to use it to accelerate the feedback loops.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>As I listen to people who are serious with AI-assisted programming, the crucial thing I hear is managing context. Programming-oriented tools are geting more sophisticated for that, but there‚Äôs also efforts at providing simpler tools, that allow customization. <a href="https://lixo.org">Carlos Villela</a> recently recommended Pi, and its developer, <a href="https://mariozechner.at/posts/2025-11-30-pi-coding-agent/">Mario Zechner, has an interesting blog</a> on its development.</p>

<blockquote>
  <p>So what‚Äôs an old guy yelling at Claudes going to do? He‚Äôs going to write his own coding agent harness and give it a name that‚Äôs entirely un-Google-able, so there will never be any users. Which means there will also never be any issues on the GitHub issue tracker. How hard can it be?</p>
</blockquote>

<p>If I ever get the time to sit and really play with these tools, then something like Pi would be something I‚Äôd like to try out. Although as an addict to The One True Editor, I‚Äôm interested in some of libraries that work with that, such as <a href="https://github.com/karthink/gptel">gptel</a>. That would enable me to use Emacs‚Äôs inherent programability to create my own command set to drive the interaction with LLMs.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>Outside of my professional work, I‚Äôve <a href="https://boardgamegeek.com/blog/13064/martins-7th-decade">posting regularly about my boardgaming</a> on the specialist site BoardGameGeek. However its blogging environment doesn‚Äôt do a good job of providing an index to my posts, so I‚Äôve created <a href="https://martinfowler.com/boardgames/">a list of my BGG posts </a> on my own site. If you‚Äôre interested in my regular posts on boardgaming, and you‚Äôre on BGG you can subscribe to me there. If you‚Äôre not on BGG you can  subscribe to the blog‚Äôs <a href="https://boardgamegeek.com/rss/blog/13064">RSS feed</a>.</p>

<p>I‚Äôve also created a list of <a href="https://martinfowler.com/boardgames/fav-games.html">my favorite board games</a>.</p>

<p><img alt="" src="https://martinfowler.com/boardgames/index/game-grid.png" /></p>

---

### [Fragments: December 16](https://martinfowler.com/fragments/2025-12-16.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <p><a href="https://www.linkedin.com/in/gitanjalivenkatraman/">Gitanjali Venkatraman</a> does wonderful illustrations of complex subjects (which is why I was so happy to work with her on our <a href="https://martinfowler.com/articles/expert-generalist.html">Expert Generalists</a> article). She has now published the latest in her series of illustrated guides: tackling the complex topic of <a href="https://www.thoughtworks.com/content/dam/thoughtworks/documents/blog/mainframe_modernisation_illustrated_guide_2025.pdf">Mainframe Modernization</a></p>

<p><a href="https://www.thoughtworks.com/content/dam/thoughtworks/documents/blog/mainframe_modernisation_illustrated_guide_2025.pdf"><img alt="" src="https://martinfowler.com/fragments/2025/gitanjali-mainframe.png" /></a></p>

<p>In it she illustrates the history and value of mainframes, why modernization is so tricky, and how to tackle the problem by breaking it down into tractable pieces. I love the clarity of her explanations, and smile frequently at her way of enhancing her words with her quirky pictures.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>Gergely Orosz on <a href="https://bsky.app/profile/gergely.pragmaticengineer.com/post/3m7xd33hi5c2d">social media</a></p>

<blockquote>
  <p>Unpopular opinion:</p>

  <p>Current code review tools just don‚Äôt make much sense for AI-generated code</p>

  <p>When reviewing code I really want to know:</p>

  <ul>
    <li>The prompt made by the dev</li>
    <li>What corrections the other dev made to the code</li>
    <li>Clear marking of code AI-generated not changed by a human</li>
  </ul>
</blockquote>

<p>Some people pushed back saying they don‚Äôt (and shouldn‚Äôt care) whether it was written by a human, generated by an LLM, or copy-pasted from Stack Overflow.</p>

<p>In my view it matters <em>a lot</em> - because of the second vital purpose of code review.</p>

<p>When asked why do code reviews, most people will answer the first vital purpose - quality control. We want to ensure bad code gets blocked before it hits <a href="https://martinfowler.com/articles/branching-patterns.html#mainline">mainline</a>. We do this to avoid bugs and to avoid other quality issues, in particular comprehensibility and ease of change.</p>

<p>But I hear the second vital purpose less often: code review is a mechanism to communicate and educate. If I‚Äôm submitting some sub-standard code, and it gets rejected, I want to know why so that I can improve my programming. Maybe I‚Äôm unaware of some library features, or maybe there‚Äôs some project-specific standards I haven‚Äôt run into yet, or maybe my naming isn‚Äôt as clear as I thought it was. Whatever the reasons, I need to know in order to learn. And my employer needs me to learn, so I can be more effective.</p>

<p>We need to know the writer of the code we review both so we can communicate our better practice to them, but also to know how to improve things. With a human, its a conversation, and perhaps some documentation if we realize we‚Äôve needed to explain things repeatedly. But with an LLM it‚Äôs about how to modify its context, as well as humans learning how to better drive the LLM.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>Wondering why I‚Äôve been making a lot of posts like this recently? <a href="https://martinfowler.com/articles/writing-fragments.html">I explain why</a> I‚Äôve been reviving the link blog.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><a href="https://simonwillison.net/2025/Dec/10/html-tools/">Simon Willison</a> describes how he uses LLMs to build disposable but useful web apps</p>

<blockquote>
  <p>These are the characteristics I have found to be most productive in building tools of this nature:</p>

  <ol>
    <li>A single file: inline JavaScript and CSS in a single HTML file means the least hassle in hosting or distributing them, and crucially means you can copy and paste them out of an LLM response.</li>
    <li>Avoid React, or anything with a build step. The problem with React is that JSX requires a build step, which makes everything massively less convenient. I prompt ‚Äúno react‚Äù and skip that whole rabbit hole entirely.</li>
    <li>Load dependencies from a CDN. The fewer dependencies the better, but if there‚Äôs a well known library that helps solve a problem I‚Äôm happy to load it from CDNjs or jsdelivr or similar.</li>
    <li>Keep them small. A few hundred lines means the maintainability of the code doesn‚Äôt matter too much: any good LLM can read them and understand what they‚Äôre doing, and rewriting them from scratch with help from an LLM takes just a few minutes.</li>
  </ol>
</blockquote>

<p>His repository includes all these tools, together with transcripts of the chats that got the LLMs to build them.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><a href="https://obie.medium.com/what-happens-when-the-coding-becomes-the-least-interesting-part-of-the-work-ab10c213c660">Obie Fernandez</a>: while many engineers are underwhelmed by AI tools, some senior engineers are finding them really valuable. He feels that senior engineers have an oft-unspoken mindset, which in conjunction with an LLM, enables the LLM to be much more valuable.</p>

<blockquote>
  <p>Levels of abstraction and generalization problems get talked about a lot because they‚Äôre easy to name. But they‚Äôre far from the whole story.</p>

  <p>Other tools show up just as often in real work:</p>

  <ul>
    <li>A sense for blast radius. Knowing which changes are safe to make loudly and which should be quiet and contained.</li>
    <li>A feel for sequencing. Knowing when a technically correct change is still wrong because the system or the team isn‚Äôt ready for it yet.</li>
    <li>An instinct for reversibility. Preferring moves that keep options open, even if they look less elegant in the moment.</li>
    <li>An awareness of social cost. Recognizing when a clever solution will confuse more people than it helps.</li>
    <li>An allergy to false confidence. Spotting places where tests are green but the model is wrong.</li>
  </ul>
</blockquote>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><a href="https://friendlybit.com/python/writing-justhtml-with-coding-agents/">Emil Stenstr√∂m</a> built an HTML5 parser in python using coding agents, using Github Copilot in Agent mode with Claude Sonnet 3.7. He automatically approved most commands. It took him ‚Äúa couple of months on off-hours‚Äù, including at least one restart from scratch. The parser now passes all the tests in html5lib test suite.</p>

<blockquote>
  <p>After writing the parser, I still don‚Äôt know HTML5 properly. The agent wrote it for me. I guided it when it came to API design and corrected bad decisions at the high level, but it did ALL of the gruntwork and wrote all of the code.</p>

  <p>I handled all git commits myself, reviewing code as it went in. I didn‚Äôt understand all the algorithmic choices, but I understood when it didn‚Äôt do the right thing.</p>
</blockquote>

<p>Although he gives an overview of what happens, there‚Äôs not very much information on his workflow and how he interacted with the LLM. There‚Äôs certainly not enough detail here to try to replicate his approach. This is contrast to Simon Willison (above) who has detailed links to his chat transcripts - although they are much smaller tools and I haven‚Äôt looked at them properly to see how useful they are.</p>

<p>One thing that is clear, however, is the vital need for a comprehensive test suite. Much of his work is driven by having that suite as a clear guide for him and the LLM agents.</p>

<blockquote>
  <p>JustHTML is about 3,000 lines of Python with 8,500+ tests passing. I couldn‚Äôt have written it this quickly without the agent.</p>

  <p>But ‚Äúquickly‚Äù doesn‚Äôt mean ‚Äúwithout thinking.‚Äù I spent a lot of time reviewing code, making design decisions, and steering the agent in the right direction. The agent did the typing; I did the thinking.</p>
</blockquote>

<p>¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†</p>

<p>Then Simon Willison <a href="https://simonwillison.net/2025/Dec/15/porting-justhtml/">ported the library to JavaScript</a>:</p>

<blockquote>
  <p>Time elapsed from project idea to finished library: about 4 hours, during which I also bought and decorated a Christmas tree with family and watched the latest Knives Out movie.</p>
</blockquote>

<p>One of his lessons:</p>

<blockquote>
  <p>If you can reduce a problem to a robust test suite you can set a coding agent loop loose on it with a high degree of confidence that it will eventually succeed. I called this <a href="https://simonwillison.net/2025/Sep/30/designing-agentic-loops/">designing the agentic loop</a> a few months ago. I think it‚Äôs the key skill to unlocking the potential of LLMs for complex tasks.</p>
</blockquote>

<p>Our experience at Thoughtworks backs this up. We‚Äôve been doing a fair bit of work recently in legacy modernization (mainframe and otherwise) using AI to migrate substantial software systems. Having a robust test suite is necessary (but not sufficient) to making this work. I hope to share my colleagues‚Äô experiences on this in the coming months.</p>

<p>But before I leave Willison‚Äôs post, I should highlight his final open questions on the legalities, ethics, and effectiveness of all this - they are well-worth contemplating.</p>

---

### [Writing Fragments](https://martinfowler.com/articles/writing-fragments.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <p>If you‚Äôre a regular reader of my site, you‚Äôll have noticed that in the
last few months I‚Äôve been making a <a href="https://martinfowler.com/articles/20251204-frags.html">number</a> of ‚Äúfragments‚Äù <a href="https://martinfowler.com/articles/2025-11-19-frags.html">posts</a>. Such a post
is a short post with a bunch of little, unconnected segments. These are
usually a reference to something I‚Äôve found on the web, sometimes a small
thought of my own.</p>

<p>A few years ago, I wouldn‚Äôt have covered these topics with posts on my
own site. Instead I would use Twitter, either retweeting someone else‚Äôs
point, or just highlighting something I‚Äôd found. But since the Muskover,
Twitter has effectively died. I‚Äôm not saying that due to any technical
issues with the site, which has mostly just been fine, nor directly due to
any of the policy changes there. The point is that lots of people have left, so that
the audience I would have reached with Twitter is now fragmented. Some
remain on X, but I see more activity on LinkedIn. There‚Äôs also Fediverse/Mastodon
and Bluesky.</p>

<p>What this means for short posts is that I can no longer just post in one
place. When I announce new articles on martinfowler.com, I announce now on
four social media sites (X, LinkedIn, Fediverse, and Bluesky). It makes
sense to do this, but I don‚Äôt want to go through all this hassle for the
kind of micro-post that Twitter served so well.</p>

<p>So I‚Äôve started to batch them up. When I see something interesting, I
make a note. When I have enough notes, I post a fragments post. Initially I
did this in a rather ad-hoc way, just using the same mechanisms I use for
most articles, but last week I started to put in some more deliberate
mechanisms into the site. (If you‚Äôre observant, you‚Äôll spot that in the URLs.)</p>

<p>One benefit of all of this, at least in my book, is that it means my material is
now fully visible in RSS. I‚Äôm probably showing my age, but I‚Äôm a big fan of RSS
(or in my case, strictly Atom) feeds. I miss the feel of the heyday of the
‚Äúblogosphere‚Äù before it got steamrolled by social media, and these fragment
posts are, of course, just the same as the link blogs from that era. I still use my
RSS reader every day to keep up with writers I like. (I‚Äôm pleased that Substack
makes its content available via RSS.) It bothered me a bit that my micro-founts
of Twitter knowledge weren‚Äôt visible on RSS, but was too lazy to do something
about it. Now I don‚Äôt need to - the fragments are available in my RSS feed.</p>

---

### [Fragments Dec 11](https://martinfowler.com/articles/2025-12-11-frags.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <p><a href="https://www.nytimes.com/2025/12/03/magazine/chatbot-writing-style.html?utm_source=substack&amp;utm_medium=email">Why does AI write like‚Ä¶ that</a> (NYT, gift link). Sam Kriss delves into the quiet hum of AI writing. AI‚Äôs work is not compelling prose: it‚Äôs phantom text, ghostly scribblings, a spectre woven into our communal tapestry.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><a href="https://coding-is-like-cooking.info/2025/12/test-desiderata-2-0/">Emily Bache</a> has written a set of Test Desiderata, building on some earlier writing from Kent Beck. She lists the characteristics of good tests, and how they support her four ‚Äúmacro desiderata‚Äù - the properties of a sound test suite</p>

<blockquote>
  <ul>
    <li>Predict success in production</li>
    <li>Fast to get feedback</li>
    <li>Support ongoing code design change</li>
    <li>Low total cost of ownership</li>
  </ul>
</blockquote>

<p>She also has a great list of other writers‚Äô lists of good test characteristics.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><a href="https://www.techpolicy.press/the-eus-fine-against-x-is-not-about-speech-or-censorship/">Daphne Keller</a> explains that the EUs fines on X aren‚Äôt about free speech.</p>

<blockquote>
  <p>There are three charges against X, which all stem from a multi-year investigation that was launched in 2023. One is about verification ‚Äî X‚Äôs blue checkmarks on user accounts ‚Äî and two are about transparency. These charges have nothing to do with what content is on X, or what user speech the platform should or should not allow.</p>
</blockquote>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><a href="https://pluralistic.net/2025/12/05/pop-that-bubble/#u-washington">Cory Doctorow</a> The Reverse-Centaur‚Äôs Guide to Criticizing AI</p>

<blockquote>
  <p>Start with what a reverse centaur is. In automation theory, a ‚Äúcentaur‚Äù is a person who is assisted by a machine. ‚Ä¶ And obviously, a reverse centaur is machine head on a human body, a person who is serving as a squishy meat appendage for an uncaring machine.</p>

  <p>Like an Amazon delivery driver‚Ä¶ the van can‚Äôt drive itself and can‚Äôt get a parcel from the curb to your porch. The driver is a peripheral for a van, and the van drives the driver, at superhuman speed, demanding superhuman endurance.</p>
</blockquote>

---

### [Fragments Dec 4](https://martinfowler.com/articles/20251204-frags.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <p><a href="https://blog.robbowley.net/2025/12/04/ai-is-still-making-code-worse-a-new-cmu-study-confirms/">Rob Bowley</a> summarizes a study from Carnegie Mellon looking on the impact of AI on a bunch of open-source software projects. Like any such study, we shouldn‚Äôt take its results as definitive, but there seems enough there to make it a handy data point. The key point is that the AI code probably reduced the quality of the code base - at least if static code analysis can be trusted to determine quality. And perhaps some worrying second-order effects</p>

<blockquote>
  <p>This study shows more than 800 popular GitHub projects with code quality degrading after adopting AI tools. It‚Äôs hard not to see a form of context collapse playing out in real time. If the public code that future models learn from is becoming more complex and less maintainable, there‚Äôs a real risk that newer models will reinforce and amplify those trends, producing even worse code over time.</p>
</blockquote>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>Rob‚Äôs post is typical of much of the thoughtful writing on AI. We can see its short-term benefits, but worry about its long-term impact. But on a much deeper note is this lovely story from <a href="https://www.linkedin.com/pulse/my-80th-birthday-i-bought-myself-new-brain-jim-highsmith-8qcrc/">Jim Highsmith</a>. Jim has turned 0x50, and has spent the last decade fighting Parkinson‚Äôs disease. To help him battle it he has two AI assisted allies.</p>

<blockquote>
  <p>Between my neural implants and Byron‚Äôs digital guidance, I now collaborate with two adaptive systems: one for motion, one for thought. Neither replaces me. Both extend me.</p>
</blockquote>

<p><strong>If you read anything on AI this week, <a href="https://www.linkedin.com/pulse/my-80th-birthday-i-bought-myself-new-brain-jim-highsmith-8qcrc/">make it be this</a>.</strong> It offers a positive harbinger for our future and opens my mind to a whole different perspective of the role of AI in it</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>Anthropic recently announced that it disrupted a Chinese state-sponsored operation abusing Claude Code. Jim Gumbley looks at the core lesson to learn from this, that we have to understand the serious risk of  <a href="https://www.thoughtworks.com/insights/blog/security/anthropic-ai-espionage-disclosure-signal-from-noise?utm_source=linkedin&amp;utm_medium=social-organic&amp;utm_campaign=dt_bs_rp-in-clt_tech_thought_leaders_2025-11&amp;gh_src=d1fe17bc1us">AI Jailbreaking</a></p>

<blockquote>
  <p>New AI tools are able to analyze your attack surface at the next level of granularity. As a business leader, that means you now have two options: wait for someone else to run AI-assisted vulnerability detection against your attack surface, or run it yourself first.</p>
</blockquote>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>There‚Äôs plenty of claims that AI Vibe Coding can replace software developers, something that folks like me (perhaps with a bias) think unlikely. <a href="https://bsky.app/profile/gergely.pragmaticengineer.com/post/3m75kmb7bh22i">Gergely Orosz</a> shared this tidbit</p>

<blockquote>
  <p>Talked with an exec at a tech company who is obsessed with AI and has been for 3 years. Not a developer but company makes software. Uses AI for everything, vibe codes ideas.</p>

  <p>Here‚Äôs the kicker:</p>

  <p>Has a team of several devs to implement his vibe coded prototypes to sg workable</p>
</blockquote>

<p>I‚Äôd love to hear more about this (and similar stories)</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><a href="https://checkeagle.com/checklists/njr/a-month-of-chat-oriented-programming/">Nick Radcliffe</a> writes about a month of using AI</p>

<blockquote>
  <p>I spent a solid month ‚Äúpair programming‚Äù with Claude Code, trying to suspend disbelief and adopt a this-will-be-productive mindset. More specifically, I got Claude to write well over 99% of the code produced during the month. I found the experience infuriating, unpleasant, and stressful before even worrying about its energy impact. Ideally, I would prefer not to do it again for at least a year or two. The only problem with that is that it ‚Äúworked‚Äù.</p>
</blockquote>

<p>He stresses that his approach is the ‚Äúpolar opposite‚Äù of Vibe Coding. The post is long, and rambles a bit, but is worthwhile because he talks in detail about his workflow and how he uses the tool. Such posts are important so we can learn the nitty-gritty of how our programming habits are changing.</p>

<p>¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>Along similar lines is a post of <a href="https://brianchambers.substack.com/p/chamber-of-tech-secrets-55-issue">Brian Chambers</a> on his workflow, that he calls Issue-Driven Development (and yes, I‚Äôm also sick of the ‚Äúsomething-driven‚Äù phraseology). As with much of the better stuff I‚Äôve heard about AI assisted work, it‚Äôs all about carefully managing the context window, ensuring the AI is focused on the right things and not distracted by textual squirrels.</p>

---

### [Fragments Nov 19](https://martinfowler.com/articles/2025-11-19-frags.html)

**Êù•Ê∫ê**: Martin Fowler

**ÊëòË¶Å**: <p><img alt="radar image" src="https://martinfowler.com/articles/images/frags-2025-11/radar.png" width="300px" /></p>

<p>I‚Äôve been on the road in Europe for the last couple of weeks, and while I was there Thoughtworks released <a href="https://www.thoughtworks.com/radar">volume 33 of our Technology Radar</a>. Again it‚Äôs dominated by the AI wave, with lots of blips capturing our explorations of how to use LLMs and similar technology. ‚ÄúAgents‚Äù are the big thing these days but we‚Äôre also seeing growing movements in infrastructure orchestration, coding workflows - and the inevitable antipatterns. Many thanks to my colleagues for putting this together again.</p>

<p>¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><img alt="Gergely and I recording the podcast" src="https://martinfowler.com/articles/images/frags-2025-11/podcast.png" width="400px" /></p>

<p>My trip to Europe started in Amsterdam, for a Thoughtworks event for a few of our clients there. Since I was in that lovely city, I got in touch with Gergely Orosz, host of <a href="https://www.pragmaticengineer.com/">The Pragmatic Engineer</a>, and he arranged to <a href="https://www.youtube.com/watch?v=CQmI4XKTa0U">record a podcast</a> with me. No surprise that AI was front-and-center of the conversation, as I said it was the biggest shift I‚Äôd seen in programming during my career, comparable only to the shift to high-level languages, which even I am not old enough to have experienced. It was a fun chat and I really enjoyed myself. Gergely later joined myself James Lewis and Giles Edwards-Alexander at the Thoughtworks event the next day.</p>

<p>¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p>My travels also took me to N√ºremberg, where I attended an internal conference for Siemens on the future of software architecture. When we think of technology, it‚Äôs easy to focus on the Faangs of Silicon Valley, but Siemens have a huge workforce of software developers working on heavy engineering systems like trains and factory automation. It was good to hear them talk about federated architectures, data mesh, and their use of AI.</p>

<p>¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><img alt="Kent's graph of options vs features" src="https://martinfowler.com/articles/images/frags-2025-11/features.webp" width="400px" /></p>

<p>I‚Äôve often used pseudo-graphs to help explain why <a href="https://martinfowler.com/articles/is-quality-worth-cost.html">high quality software is cheaper</a>. This time, <a href="https://tidyfirst.substack.com/p/why-does-development-slow">Kent Beck</a> creates a unique perspective to this chart, dispensing with the temporal axis to help think in terms of optionality.</p>

<p>¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ùÑ</p>

<p><img alt="Heavy Cardboard banner" src="https://martinfowler.com/articles/images/frags-2025-11/hc.jpg" width="400px" /></p>

<p>And in another life, Edward has finally finished the great migration of the Heavy Cardboard studio and returns to the tubes with <a href="https://www.youtube.com/live/e8juRvm9h0c">our first game in the new digs</a>. (No surprise that it‚Äôs Age of Steam.)</p>

---

## HackerNews

### [ICE using Palantir tool that feeds on Medicaid data](https://www.eff.org/deeplinks/2026/01/report-ice-using-palantir-tool-feeds-medicaid-data)

**ÂàÜÊï∞**: 1383 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46756117)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [First, make me care](https://gwern.net/blog/2026/make-me-care)

**ÂàÜÊï∞**: 763 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46757067)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [A flawed paper in management science has been cited more than 6k times](https://statmodeling.stat.columbia.edu/2026/01/22/aking/)

**ÂàÜÊï∞**: 698 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46752151)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [A macOS app that blurs your screen when you slouch](https://github.com/tldev/posturr)

**ÂàÜÊï∞**: 663 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46754944)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Google confirms 'high-friction' sideloading flow is coming to Android](https://www.androidauthority.com/google-sideloading-android-high-friction-process-3633468/)

**ÂàÜÊï∞**: 640 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46688804)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [After two years of vibecoding, I'm back to writing by hand](https://atmoio.substack.com/p/after-two-years-of-vibecoding-im)

**ÂàÜÊï∞**: 626 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46765460)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Things I've learned in my 10 years as an engineering manager](https://www.jampa.dev/p/lessons-learned-after-10-years-as)

**ÂàÜÊï∞**: 522 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46709270)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [France Aiming to Replace Zoom, Google Meet, Microsoft Teams, etc.](https://twitter.com/lellouchenico/status/2015775970330882319)

**ÂàÜÊï∞**: 504 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46767668)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Television is 100 years old today](https://diamondgeezer.blogspot.com/2026/01/tv100.html)

**ÂàÜÊï∞**: 476 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46766188)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Oneplus phone update introduces hardware anti-rollback](https://consumerrights.wiki/w/Oneplus_phone_update_introduces_hardware_anti-rollback)

**ÂàÜÊï∞**: 453 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46757944)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Doom has been ported to an earbud](https://doombuds.com)

**ÂàÜÊï∞**: 427 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46753484)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Fedora Asahi Remix is now working on Apple M3](https://bsky.app/profile/did:plc:okydh7e54e2nok65kjxdklvd/post/3mdd55paffk2o)

**ÂàÜÊï∞**: 419 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46769051)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Qwen3-Max-Thinking](https://qwen.ai/blog?id=qwen3-max-thinking)

**ÂàÜÊï∞**: 412 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46766741)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [MapLibre Tile: a modern and efficient vector tile format](https://maplibre.org/news/2026-01-23-mlt-release/)

**ÂàÜÊï∞**: 398 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46763864)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Iran's internet blackout may become permanent, with access for elites only](https://restofworld.org/2026/iran-blackout-tiered-internet/)

**ÂàÜÊï∞**: 381 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46761822)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Clawdbot - open source personal AI assistant](https://github.com/clawdbot/clawdbot)

**ÂàÜÊï∞**: 363 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46760237)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Google AI Overviews cite YouTube more than any medical site for health queries](https://www.theguardian.com/technology/2026/jan/24/google-ai-overviews-youtube-medical-citations-study)

**ÂàÜÊï∞**: 349 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46766031)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [The browser is the sandbox](https://simonwillison.net/2026/Jan/25/the-browser-is-the-sandbox/)

**ÂàÜÊï∞**: 330 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46762150)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Scientists identify brain waves that define the limits of 'you'](https://www.sciencealert.com/scientists-identify-brain-waves-that-define-the-limits-of-you)

**ÂàÜÊï∞**: 300 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46760099)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Vibe coding kills open source](https://arxiv.org/abs/2601.15494)

**ÂàÜÊï∞**: 296 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46765120)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Over 36,500 killed in Iran's deadliest massacre, documents reveal](https://www.iranintl.com/en/202601255198)

**ÂàÜÊï∞**: 255 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46760329)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Apple introduces new AirTag with longer range and improved findability](https://www.apple.com/newsroom/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/)

**ÂàÜÊï∞**: 246 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46765819)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [The Holy Grail of Linux Binary Compatibility: Musl and Dlopen](https://github.com/quaadgras/graphics.gd/discussions/242)

**ÂàÜÊï∞**: 208 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46762882)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [JuiceSSH ‚Äì Give me my pro features back](https://nproject.io/blog/juicessh-give-me-back-my-pro-features/)

**ÂàÜÊï∞**: 202 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46768909)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [LED lighting undermines visual performance unless supplemented by wider spectra](https://www.nature.com/articles/s41598-026-35389-6)

**ÂàÜÊï∞**: 199 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46758644)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [When AI 'builds a browser,' check the repo before believing the hype](https://www.theregister.com/2026/01/26/cursor_opinion/)

**ÂàÜÊï∞**: 192 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46769965)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Google Books removed all search functions for any books with previews](https://old.reddit.com/r/google/comments/1qn1hk1/google_has_seemingly_entirely_removed_search/)

**ÂàÜÊï∞**: 185 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46769201)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [I built a 2x faster lexer, then discovered I/O was the real bottleneck](https://modulovalue.com/blog/syscall-overhead-tar-gz-io-performance/)

**ÂàÜÊï∞**: 181 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46693460)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [I was right about ATProto key management](https://notes.nora.codes/atproto-again/)

**ÂàÜÊï∞**: 175 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46757357)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Jurassic Park - Tablet device on Nedry's desk? (2012)](https://www.therpf.com/forums/threads/jurassic-park-tablet-device-on-nedrys-desk.169883/)

**ÂàÜÊï∞**: 167 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46752261)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Text Is King](https://www.experimental-history.com/p/text-is-king)

**ÂàÜÊï∞**: 164 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46698264)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [The Hidden Engineering of Runways](https://practical.engineering/blog/2026/1/20/the-hidden-engineering-of-runways)

**ÂàÜÊï∞**: 157 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46694193)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [There is an AI code review bubble](https://www.greptile.com/blog/ai-code-review-bubble)

**ÂàÜÊï∞**: 156 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46766961)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Porting 100k lines from TypeScript to Rust using Claude Code in a month](https://blog.vjeux.com/2026/analysis/porting-100k-lines-from-typescript-to-rust-using-claude-code-in-a-month.html)

**ÂàÜÊï∞**: 150 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46765694)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [ChatGPT Containers can now run bash, pip/npm install packages and download files](https://simonwillison.net/2026/Jan/26/chatgpt-containers/)

**ÂàÜÊï∞**: 149 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46770221)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [San Francisco Graffiti](https://walzr.com/sf-graffiti)

**ÂàÜÊï∞**: 140 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46763721)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Windows 11's Patch Tuesday nightmare gets worse](https://www.windowscentral.com/microsoft/windows-11/windows-11s-botched-patch-tuesday-update-nightmare-continues-as-microsoft-confirms-some-pcs-might-fail-to-boot)

**ÂàÜÊï∞**: 137 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46766526)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Show HN: Only 1 LLM can fly a drone](https://github.com/kxzk/snapbench)

**ÂàÜÊï∞**: 137 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46764170)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Guix for Development](https://dthompson.us/posts/guix-for-development.html)

**ÂàÜÊï∞**: 134 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46690592)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [The Adolescence of Technology](https://www.darioamodei.com/essay/the-adolescence-of-technology)

**ÂàÜÊï∞**: 130 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46768257)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [TSMC Risk](https://stratechery.com/2026/tsmc-risk/)

**ÂàÜÊï∞**: 129 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46764223)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [RIP Low-Code 2014-2025](https://www.zackliscio.com/posts/rip-low-code-2014-2025/)

**ÂàÜÊï∞**: 125 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46767440)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [OSS ChatGPT WebUI ‚Äì 530 Models, MCP, Tools, Gemini RAG, Image/Audio Gen](https://llmspy.org/docs/v3)

**ÂàÜÊï∞**: 116 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46766432)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [US Government wants DNA and social media from visitors](https://www.privacyinternational.org/news-analysis/5713/trump-administration-wants-your-dna-and-social-media)

**ÂàÜÊï∞**: 111 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46764381)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Dithering ‚Äì Part 2: The Ordered Dithering](https://visualrambling.space/dithering-part-2/)

**ÂàÜÊï∞**: 107 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46770274)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [State of the Windows: What is going on with Windows 11?](https://ntdotdev.wordpress.com/2026/01/25/state-of-the-windows-what-is-going-on-with-windows-11/)

**ÂàÜÊï∞**: 102 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46772212)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Notice of collective action lawsuit against Workday, Inc.](https://workdaycase.com)

**ÂàÜÊï∞**: 97 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46769668)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Show HN: An interactive map of US lighthouses and navigational aids](https://www.lighthouses.app/)

**ÂàÜÊï∞**: 96 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46756427)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [What ‚ÄúThe Best‚Äù Looks Like](https://www.kuril.in/blog/what-the-best-looks-like/)

**ÂàÜÊï∞**: 91 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46767323)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Is It Time for a Nordic Nuke?](https://warontherocks.com/2026/01/is-it-time-for-a-nordic-nuke/)

**ÂàÜÊï∞**: 88 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46767772)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Water 'Bankruptcy' Era Has Begun for Billions, Scientists Say](https://www.bloomberg.com/news/articles/2026-01-20/water-bankruptcy-era-has-begun-for-billions-scientists-say)

**ÂàÜÊï∞**: 83 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46765092)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [The mountain that weighed the Earth](https://signoregalilei.com/2026/01/18/the-mountain-that-weighed-the-earth/)

**ÂàÜÊï∞**: 81 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46767875)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Exactitude in Science ‚Äì Borges (1946) [pdf]](https://kwarc.info/teaching/TDM/Borges.pdf)

**ÂàÜÊï∞**: 78 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46766229)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [House of Lords Votes to Ban UK Children from Using Internet VPNs](https://www.ispreview.co.uk/index.php/2026/01/house-of-lords-votes-to-ban-uk-children-from-using-internet-vpns.html)

**ÂàÜÊï∞**: 77 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46769131)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Blade Runner Costume Design (2020)](https://costumedesignarchive.blogspot.com/2020/12/blade-runner-1982.html)

**ÂàÜÊï∞**: 72 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46700489)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [People who know the formula for WD-40](https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54)

**ÂàÜÊï∞**: 70 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46771599)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Find 'Abbey Road when type 'Beatles abbey rd': Fuzzy/Semantic search in Postgres](https://rendiment.io/postgresql/2026/01/21/pgtrgm-pgvector-music.html)

**ÂàÜÊï∞**: 70 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46709461)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Running the Stupid Cricut Software on Linux](https://arthur.pizza/2025/12/running-stupid-cricut-software-under-linux/)

**ÂàÜÊï∞**: 69 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46761761)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [A static site generator written in POSIX shell](https://aashvik.com/posts/shell-ssg/)

**ÂàÜÊï∞**: 69 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46690463)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [The Science of Fermentation [audio]](https://www.bbc.co.uk/programmes/m002pqg6)

**ÂàÜÊï∞**: 66 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46733306)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Show HN: TetrisBench ‚Äì Gemini Flash reaches 66% win rate on Tetris against Opus](https://tetrisbench.com/tetrisbench/)

**ÂàÜÊï∞**: 63 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46769752)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [AI code and software craft](https://alexwennerberg.com/blog/2026-01-25-slop.html)

**ÂàÜÊï∞**: 58 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46769188)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Bitwise conversion of doubles using only FP multiplication and addition (2020)](https://dougallj.wordpress.com/2020/05/10/bitwise-conversion-of-doubles-using-only-floating-point-multiplication-and-addition/)

**ÂàÜÊï∞**: 54 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46754522)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [AI Lazyslop and Personal Responsibility](https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/)

**ÂàÜÊï∞**: 52 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46770675)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Transfering Files with gRPC](https://kreya.app/blog/transfering-files-with-grpc/)

**ÂàÜÊï∞**: 52 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46765273)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Y Combinator website no longer lists Canada as a country it invests in](https://betakit.com/y-combinator-website-no-longer-lists-canada-as-a-country-it-invests-in/)

**ÂàÜÊï∞**: 48 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46773242)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Georgia leads push to ban datacenters used to power America's AI boom](https://www.theguardian.com/technology/2026/jan/26/georgia-datacenters-ai-ban)

**ÂàÜÊï∞**: 47 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46767696)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [OpenFlexure Microscope](https://openflexure.org/projects/microscope/)

**ÂàÜÊï∞**: 46 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46701045)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Not all Chess960 positions are equally complex](https://arxiv.org/abs/2512.14319)

**ÂàÜÊï∞**: 46 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46727603)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [OracleGPT: Thought Experiment on an AI Powered Executive](https://senteguard.com/blog/#post-7fYcaQrAcfsldmSb7zVM)

**ÂàÜÊï∞**: 46 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46766507)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [You can just port things to Cloudflare Workers](https://sigh.dev/posts/you-can-just-port-things-to-cloudflare-workers/)

**ÂàÜÊï∞**: 40 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46761239)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Kubernetes Remote Code Execution via Nodes/Proxy Get Permission](https://grahamhelton.com/blog/nodes-proxy-rce)

**ÂàÜÊï∞**: 35 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46766140)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Emissary, a fast open-source Java messaging library](https://github.com/joel-jeremy/emissary)

**ÂàÜÊï∞**: 33 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46723049)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [TikTok disallows DMs with the word "Epstein"](https://twitter.com/krassenstein/status/2015911471507530219)

**ÂàÜÊï∞**: 30 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46773561)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Runjak.codes: An adversarial coding test](https://runjak.codes/posts/2026-01-21-adversarial-coding-test/)

**ÂàÜÊï∞**: 30 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46717472)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [I let ChatGPT analyze a decade of my Apple Watch data, then I called my doctor](https://www.msn.com/en-us/news/technology/i-let-chatgpt-analyze-a-decade-of-my-apple-watch-data-then-i-called-my-doctor/ar-AA1UZxip)

**ÂàÜÊï∞**: 28 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46772495)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [A few random notes from Claude coding quite a bit last few weeks](https://twitter.com/karpathy/status/2015883857489522876)

**ÂàÜÊï∞**: 28 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46771365)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Clawdbot: Personal AI Assistant](https://clawd.bot/)

**ÂàÜÊï∞**: 22 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46764139)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Clinic-in-the-loop](https://www.asimov.press/p/clinic-loop)

**ÂàÜÊï∞**: 22 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46710981)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Show HN: SF Microclimates](https://github.com/solo-founders/sf-microclimates)

**ÂàÜÊï∞**: 21 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46760927)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Apple CEO Tim Cook Visited White House for 'Melania' Documentary Screening](https://www.macrumors.com/2026/01/26/tim-cook-melania-documentary-screening/)

**ÂàÜÊï∞**: 20 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46772627)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Show HN: Ourguide ‚Äì OS wide task guidance system that shows you where to click](https://ourguide.ai)

**ÂàÜÊï∞**: 18 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46769422)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Taming P99s in OpenFGA: How we built a self-tuning strategy planner](https://auth0.com/blog/self-tuning-strategy-planner-openfga/)

**ÂàÜÊï∞**: 16 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46724542)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [You have to know how tech companies work](https://www.seangoedecke.com/knowing-how-to-drive-the-car/)

**ÂàÜÊï∞**: 13 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46772966)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [Tether says it bought 27 tons of gold in fourth quarter](https://finance.yahoo.com/news/tether-says-bought-27-tons-174955806.html)

**ÂàÜÊï∞**: 12 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46771068)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

### [China hacked Downing Street phones for years](https://www.telegraph.co.uk/news/2026/01/26/china-hacked-downing-street-phones-for-years/)

**ÂàÜÊï∞**: 10 | [ËÆ®ËÆ∫](https://news.ycombinator.com/item?id=46773613)

**ÊëòË¶Å**: ÊöÇÊó†ÊëòË¶Å

---

## LLM Infrastructure

### [v0.15.0rc0: [Bugfix] Fix Dtypes for Pynccl Wrapper (#33030)](https://github.com/vllm-project/vllm/releases/tag/v0.15.0rc0)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <p>Signed-off-by: Robert Shaw <a href="mailto:robshaw@redhat.com">robshaw@redhat.com</a><br />
Co-authored-by: Robert Shaw <a href="mailto:robshaw@redhat.com">robshaw@redhat.com</a><br />
(cherry picked from commit <a class="commit-link" href="https://github.com/vllm-project/vllm/commit/43a013c3a29194f7b88b1b611b3b0067592b8c67"><tt>43a013c</tt></a>)</p>

---

### [v0.14.1](https://github.com/vllm-project/vllm/releases/tag/v0.14.1)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <p>This is a patch release on top of <code>v0.14.0</code> to address a few security and memory leak fixes.</p>

---

### [v0.14.0](https://github.com/vllm-project/vllm/releases/tag/v0.14.0)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <h2>Highlights</h2>
<p>This release features approximately 660 commits from 251 contributors (86 new contributors).</p>
<p><strong>Breaking Changes:</strong></p>
<ul>
<li><strong>Async scheduling is now enabled by default</strong> - Users who experience issues can disable with <code>--no-async-scheduling</code>.
<ul>
<li>Excludes some not-yet-supported configurations: pipeline parallel, CPU backend, non-MTP/Eagle spec decoding.</li>
</ul>
</li>
<li><strong>PyTorch 2.9.1</strong> is now required and the default wheel is compiled against cu129.</li>
<li>Deprecated quantization schemes have been removed (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31688">#31688</a>, <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31285">#31285</a>).</li>
<li>When using speculative decoding, unsupported sampling parameters will fail rather than being silently ignored (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31982">#31982</a>).</li>
</ul>
<p><strong>Key Improvements:</strong></p>
<ul>
<li><strong>Async scheduling enabled by default</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27614">#27614</a>): Overlaps engine core scheduling with GPU execution, improving throughput without user configuration. Now also works with speculative decoding (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31998">#31998</a>) and structured outputs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29821">#29821</a>).</li>
<li><strong>gRPC server entrypoint</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30190">#30190</a>): Alternative to REST API with binary protocol, HTTP/2 multiplexing.</li>
<li><strong><code>--max-model-len auto</code></strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29431">#29431</a>): Automatically fits context length to available GPU memory, eliminating OOM startup failures.</li>
<li><strong>Model inspection view</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29450">#29450</a>): View the modules, attention backends, and quantization of your model in vLLM by specifying <code>VLLM_LOG_MODEL_INSPECTION=1</code> or by simply printing the <code>LLM</code> object.</li>
<li><strong>Model Runner V2 enhancements</strong>: UVA block tables (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31965">#31965</a>), M-RoPE (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32143">#32143</a>), <code>logit_bias</code>/<code>allowed_token_ids</code>/<code>min_tokens</code> support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32163">#32163</a>).
<ul>
<li>Please note that Model Runner V2 is still experimental and disabled by default.</li>
</ul>
</li>
</ul>
<h3>Model Support</h3>
<p><strong>New Model Architectures:</strong></p>
<ul>
<li>Grok-2 with tiktoken tokenizer (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31847">#31847</a>)</li>
<li>LFM2-VL vision-language model (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31758">#31758</a>)</li>
<li>MiMo-V2-Flash (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30836">#30836</a>)</li>
<li>openPangu MoE (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28775">#28775</a>)</li>
<li>IQuestCoder (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31575">#31575</a>)</li>
<li>Nemotron Parse 1.1 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30864">#30864</a>)</li>
<li>GLM-ASR audio (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31436">#31436</a>)</li>
<li>Isaac vision model v0.1/v0.2 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28367">#28367</a>, <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31550">#31550</a>)</li>
<li>Kanana-1.5-v-3b-instruct (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29384">#29384</a>)</li>
<li>K-EXAONE-236B-A23B MoE (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31621">#31621</a>)</li>
</ul>
<p><strong>LoRA Support Expansion:</strong></p>
<ul>
<li>Multimodal tower/connector LoRA (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/26674">#26674</a>): LLaVA (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31513">#31513</a>), BLIP2 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31620">#31620</a>), PaliGemma (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31656">#31656</a>), Pixtral (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31724">#31724</a>), DotsOCR (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31825">#31825</a>), GLM4-V (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31652">#31652</a>)</li>
<li>DeepSeek-OCR (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31569">#31569</a>), Qwen3-Next (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31719">#31719</a>), NemotronH (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31539">#31539</a>), PLaMo 2/3 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31322">#31322</a>)</li>
<li>Vision LoRA mm_processor_cache support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31927">#31927</a>)</li>
<li>MoE expert base_layer loading (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31104">#31104</a>)</li>
</ul>
<p><strong>Model Enhancements:</strong></p>
<ul>
<li>Qwen3-VL as reranker (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31890">#31890</a>)</li>
<li>DeepSeek v3.2 chat prefix completion (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31147">#31147</a>)</li>
<li>GLM-4.5/GLM-4.7 <code>enable_thinking: false</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31788">#31788</a>)</li>
<li>Ernie4.5-VL video timestamps (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31274">#31274</a>)</li>
<li>Score template expansion (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31335">#31335</a>)</li>
<li>LLaMa4 vision encoder compilation (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30709">#30709</a>)</li>
<li>NemotronH quantized attention (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31898">#31898</a>)</li>
</ul>
<h3>Engine Core</h3>
<ul>
<li><strong>Async scheduling default</strong> with spec decode (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27614">#27614</a>, <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31998">#31998</a>) and structured outputs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29821">#29821</a>)</li>
<li><strong>Hybrid allocator + KV connector</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30166">#30166</a>) with multiple KV cache groups (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31707">#31707</a>)</li>
<li>Triton attention: encoder-only/cross attention (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31406">#31406</a>), cross-layer blocks (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30687">#30687</a>)</li>
<li>Mamba2 prefix cache optimization (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28047">#28047</a>)</li>
<li>Batch invariant LoRA (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30097">#30097</a>)</li>
<li>LoRA name in BlockStored for KV-cache reconstruction (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27577">#27577</a>)</li>
<li>Request ID collision prevention (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27987">#27987</a>)</li>
<li>Dense model DP without overhead (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30739">#30739</a>)</li>
<li>Async + spec decode penalties/bad_words (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30495">#30495</a>)</li>
</ul>
<h3>Hardware &amp; Performance</h3>
<p><strong>CUTLASS MoE Optimizations:</strong></p>
<ul>
<li>2.9% throughput + 10.8% TTFT via fill(0) optimization (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31754">#31754</a>)</li>
<li>5.3% throughput + 2.2% TTFT via problem size calculation (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31830">#31830</a>)</li>
<li>Fused SiLU+Mul+Quant for NVFP4 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31832">#31832</a>)</li>
<li>NVFP4 stride fusion (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31837">#31837</a>)</li>
</ul>
<p><strong>Other Performance:</strong></p>
<ul>
<li>GDN attention decode speedup (Qwen3-Next) (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31722">#31722</a>)</li>
<li>Fused RoPE + MLA KV-cache write (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/25774">#25774</a>)</li>
<li>Sliding window attention optimization (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31984">#31984</a>)</li>
<li>FlashInfer DeepGEMM swapAB SM90 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29213">#29213</a>)</li>
<li>Unpermute-aware fused MoE + small-batch fallback (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29354">#29354</a>)</li>
<li>GDN Attention blocking copy removal (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31167">#31167</a>)</li>
<li>FusedMoE LoRA small rank performance (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32019">#32019</a>)</li>
<li>EPLB numpy optimization (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29499">#29499</a>)</li>
<li>FlashInfer rotary for DeepSeek (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30729">#30729</a>)</li>
<li>Vectorized activations (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29512">#29512</a>)</li>
<li>NUMA interleaved memory (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30800">#30800</a>)</li>
<li>Async spec decode logprobs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31336">#31336</a>)</li>
</ul>
<p><strong>Hardware Configs:</strong></p>
<ul>
<li>SM103 support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30705">#30705</a>, <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31150">#31150</a>)</li>
<li>B300 Blackwell MoE configs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30629">#30629</a>)</li>
<li>Qwen3-Next FP8 CUTLASS configs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29553">#29553</a>)</li>
<li>Qwen3Moe B200 Triton configs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31448">#31448</a>)</li>
<li>GLM-4.5/4.6 RTX Pro 6000 kernels (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31407">#31407</a>)</li>
<li>MiniMax-M2/M2.1 QKNorm (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31493">#31493</a>)</li>
<li>NVFP4 small batch tuning (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30897">#30897</a>)</li>
</ul>
<p><strong>Platform:</strong></p>
<ul>
<li>ROCm: AITER RMSNorm fusion (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/26575">#26575</a>), MTP for AITER MLA (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28624">#28624</a>), moriio connector (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29304">#29304</a>), xgrammar upstream (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31327">#31327</a>)</li>
<li>XPU: FP8 streaming quant (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30944">#30944</a>), custom workers (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30935">#30935</a>)</li>
<li>CPU: Head sizes 80/112 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31968">#31968</a>), async disabled by default (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31525">#31525</a>), LoRA MoE CPU pinning (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31317">#31317</a>)</li>
<li>TPU: tpu-inference path (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30808">#30808</a>), Sophgo docs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30949">#30949</a>)</li>
</ul>
<h3>Large Scale Serving</h3>
<ul>
<li><strong>XBO</strong> (Extended Dual-Batch Overlap) (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30120">#30120</a>)</li>
<li><strong>NIXL asymmetric TP</strong> (P &gt; D tensor-parallel-size) (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27274">#27274</a>)</li>
<li>NIXL heterogeneous BlockSize/kv_layout (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30275">#30275</a>)</li>
<li>Cross-layers KV layout for MultiConnector (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30761">#30761</a>)</li>
<li>Mooncake protocol expansion (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30133">#30133</a>)</li>
<li>LMCache KV cache registration (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31397">#31397</a>)</li>
<li>EPLB default all2all backend (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30559">#30559</a>)</li>
</ul>
<h3>Quantization</h3>
<ul>
<li><strong>Marlin for Turing (sm75)</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29901">#29901</a>, <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31000">#31000</a>)</li>
<li><strong>Quark int4-fp8 w4a8 MoE</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30071">#30071</a>)</li>
<li><strong>MXFP4 W4A16 dense models</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31926">#31926</a>)</li>
<li><strong>ModelOpt FP8 variants</strong> (FP8_PER_CHANNEL_PER_TOKEN, FP8_PB_WO) (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30957">#30957</a>)</li>
<li>ModelOpt KV cache quantization update (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31895">#31895</a>)</li>
<li>NVFP4 Marlin for NVFP4A16 MoEs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30881">#30881</a>)</li>
<li>Static quant all group shapes (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30833">#30833</a>)</li>
<li>Default MXFP4 LoRA backend: Marlin (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30598">#30598</a>)</li>
<li>compressed-tensors 0.13.0 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30799">#30799</a>)</li>
</ul>
<h3>API &amp; Frontend</h3>
<p><strong>New Features:</strong></p>
<ul>
<li>gRPC server (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30190">#30190</a>)</li>
<li><code>--max-model-len auto</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29431">#29431</a>)</li>
<li>Model inspection view (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29450">#29450</a>)</li>
<li>Offline FastAPI docs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30184">#30184</a>)</li>
<li><code>attention_config</code> in LLM() (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30710">#30710</a>)</li>
<li>MFU metrics (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30738">#30738</a>)</li>
<li>Iteration logging + NVTX (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31193">#31193</a>)</li>
<li><code>reasoning_effort</code> parameter (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31956">#31956</a>)</li>
</ul>
<p><strong>Tool Calling:</strong></p>
<ul>
<li>FunctionGemma parser (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31218">#31218</a>)</li>
<li>GLM-4.7 parser (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30876">#30876</a>)</li>
<li>Kimi K2 update (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31207">#31207</a>)</li>
</ul>
<p><strong>CLI:</strong></p>
<ul>
<li><code>-ep</code> for <code>--enable-expert-parallel</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30890">#30890</a>)</li>
<li>Complete help messages (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31226">#31226</a>)</li>
<li>Bench serve auto-discovery + <code>--input-len</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30816">#30816</a>)</li>
<li>Spec decode acceptance stats (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31739">#31739</a>)</li>
<li><code>--enable-log-deltas</code> (renamed) (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32020">#32020</a>)</li>
<li><code>--default-chat-template-kwargs</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31343">#31343</a>)</li>
</ul>
<p><strong>API:</strong></p>
<ul>
<li><code>/server_info</code> env info (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31899">#31899</a>)</li>
<li>MCP streaming in Responses API (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31761">#31761</a>)</li>
<li><code>/embeddings</code> <code>continue_final_message</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31497">#31497</a>)</li>
<li>Reranking score templates (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30550">#30550</a>)</li>
<li>Chat template warmup (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30700">#30700</a>)</li>
<li>Configurable handshake timeout (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27444">#27444</a>)</li>
<li>Better 500 errors (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/20610">#20610</a>)</li>
<li>Worker init logging (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29493">#29493</a>)</li>
<li>Bench error reporting (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31808">#31808</a>)</li>
<li>Corrupted video recovery (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29197">#29197</a>)</li>
<li>Spec-decode param validation (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31982">#31982</a>)</li>
<li>Validation error metadata (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30134">#30134</a>)</li>
</ul>
<h3>Security</h3>
<ul>
<li>Prevent token leaks in crash logs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30751">#30751</a>)</li>
<li><code>weights_only=True</code> in torch.load (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32045">#32045</a>)</li>
</ul>
<h3>Dependencies</h3>
<ul>
<li><strong>PyTorch 2.9.1</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28495">#28495</a>)</li>
<li>compressed-tensors 0.13.0 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30799">#30799</a>)</li>
<li>CUDA 13 LMCache/NIXL in Docker (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30913">#30913</a>)</li>
<li>Configurable NVSHMEM version (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30732">#30732</a>)</li>
</ul>
<h3>Bug Fixes (User-Facing)</h3>
<ul>
<li>Invalid UTF-8 tokens (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28874">#28874</a>)</li>
<li>CPU RoPE gibberish with <code>--enforce-eager</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31643">#31643</a>)</li>
<li>Tool call streaming finish chunk (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31438">#31438</a>)</li>
<li>Encoder cache leak CPU scheduling stuck (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31857">#31857</a>)</li>
<li>Engine crash: tools + response_format (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32127">#32127</a>)</li>
<li>Voxtral transcription API (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31388">#31388</a>)</li>
<li>Safetensors download optimization (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30537">#30537</a>)</li>
</ul>
<h3>Deprecations</h3>
<ul>
<li>Deprecated quantization schemes removed (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31688">#31688</a>, <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31285">#31285</a>)</li>
<li><code>seed_everything</code> deprecated (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31659">#31659</a>)</li>
</ul>
<h3>Documentation</h3>
<ul>
<li>vllm-metal plugin docs (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31174">#31174</a>)</li>
<li>Claude Code example (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31188">#31188</a>)</li>
<li>CustomOp developer guide (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30886">#30886</a>)</li>
</ul>
<h2>New Contributors üéâ</h2>
<ul>
<li><a class="user-mention notranslate" href="https://github.com/penfree">@penfree</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30237">#30237</a></li>
<li><a class="user-mention notranslate" href="https://github.com/jiangkuaixue123">@jiangkuaixue123</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30120">#30120</a></li>
<li><a class="user-mention notranslate" href="https://github.com/jr-shen">@jr-shen</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29663">#29663</a></li>
<li><a class="user-mention notranslate" href="https://github.com/grzegorz-k-karch">@grzegorz-k-karch</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30795">#30795</a></li>
<li><a class="user-mention notranslate" href="https://github.com/shanjiaz">@shanjiaz</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30799">#30799</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Somoku">@Somoku</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29569">#29569</a></li>
<li><a class="user-mention notranslate" href="https://github.com/baoqian426">@baoqian426</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30841">#30841</a></li>
<li><a class="user-mention notranslate" href="https://github.com/SongDI911">@SongDI911</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30852">#30852</a></li>
<li><a class="user-mention notranslate" href="https://github.com/www-spam">@www-spam</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30827">#30827</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Xunzhuo">@Xunzhuo</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30844">#30844</a></li>
<li><a class="user-mention notranslate" href="https://github.com/TheCodeWrangler">@TheCodeWrangler</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30700">#30700</a></li>
<li><a class="user-mention notranslate" href="https://github.com/SungMinCho">@SungMinCho</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30738">#30738</a></li>
<li><a class="user-mention notranslate" href="https://github.com/sarathc-cerebras">@sarathc-cerebras</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30188">#30188</a></li>
<li><a class="user-mention notranslate" href="https://github.com/wzyrrr">@wzyrrr</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30949">#30949</a></li>
<li><a class="user-mention notranslate" href="https://github.com/navmarri14">@navmarri14</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30629">#30629</a></li>
<li><a class="user-mention notranslate" href="https://github.com/HaloWorld">@HaloWorld</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30867">#30867</a></li>
<li><a class="user-mention notranslate" href="https://github.com/jeffreywang-anyscale">@jeffreywang-anyscale</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31013">#31013</a></li>
<li><a class="user-mention notranslate" href="https://github.com/AmeenP">@AmeenP</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31093">#31093</a></li>
<li><a class="user-mention notranslate" href="https://github.com/westers">@westers</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31071">#31071</a></li>
<li><a class="user-mention notranslate" href="https://github.com/CedricHwong">@CedricHwong</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30957">#30957</a></li>
<li><a class="user-mention notranslate" href="https://github.com/c0de128">@c0de128</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31114">#31114</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Bounty-hunter">@Bounty-hunter</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30242">#30242</a></li>
<li><a class="user-mention notranslate" href="https://github.com/jzakrzew">@jzakrzew</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30550">#30550</a></li>
<li><a class="user-mention notranslate" href="https://github.com/1643661061leo">@1643661061leo</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30760">#30760</a></li>
<li><a class="user-mention notranslate" href="https://github.com/NickCao">@NickCao</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30070">#30070</a></li>
<li><a class="user-mention notranslate" href="https://github.com/amithkk">@amithkk</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31212">#31212</a></li>
<li><a class="user-mention notranslate" href="https://github.com/gateremark">@gateremark</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31218">#31218</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Tiiiktak">@Tiiiktak</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31274">#31274</a></li>
<li><a class="user-mention notranslate" href="https://github.com/oscardev256">@oscardev256</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28367">#28367</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Jzz1943">@Jzz1943</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31448">#31448</a></li>
<li><a class="user-mention notranslate" href="https://github.com/mratsim">@mratsim</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31407">#31407</a></li>
<li><a class="user-mention notranslate" href="https://github.com/twjww">@twjww</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31445">#31445</a></li>
<li><a class="user-mention notranslate" href="https://github.com/amittell">@amittell</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31438">#31438</a></li>
<li><a class="user-mention notranslate" href="https://github.com/ricky-chaoju">@ricky-chaoju</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30184">#30184</a></li>
<li><a class="user-mention notranslate" href="https://github.com/effortprogrammer">@effortprogrammer</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31343">#31343</a></li>
<li><a class="user-mention notranslate" href="https://github.com/ZT-AIA">@ZT-AIA</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31408">#31408</a></li>
<li><a class="user-mention notranslate" href="https://github.com/rogerxfeng8">@rogerxfeng8</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31522">#31522</a></li>
<li><a class="user-mention notranslate" href="https://github.com/kevin-pw">@kevin-pw</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31497">#31497</a></li>
<li><a class="user-mention notranslate" href="https://github.com/vintipandey">@vintipandey</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31505">#31505</a></li>
<li><a class="user-mention notranslate" href="https://github.com/SameerAsal">@SameerAsal</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31520">#31520</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Dylan1229">@Dylan1229</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31546">#31546</a></li>
<li><a class="user-mention notranslate" href="https://github.com/reaganjlee">@reaganjlee</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29105">#29105</a></li>
<li><a class="user-mention notranslate" href="https://github.com/zhima771">@zhima771</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31569">#31569</a></li>
<li><a class="user-mention notranslate" href="https://github.com/jayhemnani9910">@jayhemnani9910</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31513">#31513</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Tmn07">@Tmn07</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31572">#31572</a></li>
<li><a class="user-mention notranslate" href="https://github.com/vsourirajan">@vsourirajan</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31549">#31549</a></li>
<li><a class="user-mention notranslate" href="https://github.com/labAxiaoming">@labAxiaoming</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31601">#31601</a></li>
<li><a class="user-mention notranslate" href="https://github.com/massif-01">@massif-01</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31604">#31604</a></li>
<li><a class="user-mention notranslate" href="https://github.com/PHOEBEMOON0802">@PHOEBEMOON0802</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31147">#31147</a></li>
<li><a class="user-mention notranslate" href="https://github.com/tpopp">@tpopp</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29993">#29993</a></li>
<li><a class="user-mention notranslate" href="https://github.com/ppppqp">@ppppqp</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31620">#31620</a></li>
<li><a class="user-mention notranslate" href="https://github.com/zzzzwwjj">@zzzzwwjj</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31674">#31674</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Catacomba">@Catacomba</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30322">#30322</a></li>
<li><a class="user-mention notranslate" href="https://github.com/kunpengW-code">@kunpengW-code</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31669">#31669</a></li>
<li><a class="user-mention notranslate" href="https://github.com/johncalesp">@johncalesp</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28874">#28874</a></li>
<li><a class="user-mention notranslate" href="https://github.com/BlankRH">@BlankRH</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31800">#31800</a></li>
<li><a class="user-mention notranslate" href="https://github.com/guicho271828">@guicho271828</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/20610">#20610</a></li>
<li><a class="user-mention notranslate" href="https://github.com/ReinforcedKnowledge">@ReinforcedKnowledge</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31055">#31055</a></li>
<li><a class="user-mention notranslate" href="https://github.com/vSeamar">@vSeamar</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29197">#29197</a></li>
<li><a class="user-mention notranslate" href="https://github.com/A1c0r-Z">@A1c0r-Z</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31656">#31656</a></li>
<li><a class="user-mention notranslate" href="https://github.com/MrIceCreamMan">@MrIceCreamMan</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31465">#31465</a></li>
<li><a class="user-mention notranslate" href="https://github.com/tianshu-Michael-yu">@tianshu-Michael-yu</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31841">#31841</a></li>
<li><a class="user-mention notranslate" href="https://github.com/weiyu0824">@weiyu0824</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30808">#30808</a></li>
<li><a class="user-mention notranslate" href="https://github.com/andyl98">@andyl98</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31757">#31757</a></li>
<li><a class="user-mention notranslate" href="https://github.com/JaredforReal">@JaredforReal</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31779">#31779</a></li>
<li><a class="user-mention notranslate" href="https://github.com/katec846">@katec846</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29213">#29213</a></li>
<li><a class="user-mention notranslate" href="https://github.com/kfirtoledo">@kfirtoledo</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30761">#30761</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Ayobami-00">@Ayobami-00</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31868">#31868</a></li>
<li><a class="user-mention notranslate" href="https://github.com/ShaanveerS">@ShaanveerS</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31825">#31825</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Zyyeric">@Zyyeric</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31652">#31652</a></li>
<li><a class="user-mention notranslate" href="https://github.com/wangshangsam">@wangshangsam</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31775">#31775</a></li>
<li><a class="user-mention notranslate" href="https://github.com/devbyteai">@devbyteai</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31536">#31536</a></li>
<li><a class="user-mention notranslate" href="https://github.com/BJWang-ant">@BJWang-ant</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31719">#31719</a></li>
<li><a class="user-mention notranslate" href="https://github.com/dangoldbj">@dangoldbj</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31847">#31847</a></li>
<li><a class="user-mention notranslate" href="https://github.com/maylikenoother">@maylikenoother</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31610">#31610</a></li>
<li><a class="user-mention notranslate" href="https://github.com/yxing-bj">@yxing-bj</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31575">#31575</a></li>
<li><a class="user-mention notranslate" href="https://github.com/xbfs">@xbfs</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31948">#31948</a></li>
<li><a class="user-mention notranslate" href="https://github.com/RunkaiTao">@RunkaiTao</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29354">#29354</a></li>
<li><a class="user-mention notranslate" href="https://github.com/AkshatSh">@AkshatSh</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31550">#31550</a></li>
<li><a class="user-mention notranslate" href="https://github.com/frelam">@frelam</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31857">#31857</a></li>
<li><a class="user-mention notranslate" href="https://github.com/shyeh25">@shyeh25</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31617">#31617</a></li>
<li><a class="user-mention notranslate" href="https://github.com/andikarachman">@andikarachman</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32092">#32092</a></li>
<li><a class="user-mention notranslate" href="https://github.com/minimAluminiumalism">@minimAluminiumalism</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32158">#32158</a></li>
<li><a class="user-mention notranslate" href="https://github.com/andyzhangx">@andyzhangx</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32185">#32185</a></li>
<li><a class="user-mention notranslate" href="https://github.com/sanghoon-yn">@sanghoon-yn</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/31956">#31956</a></li>
<li><a class="user-mention notranslate" href="https://github.com/potatosalad">@potatosalad</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/32212">#32212</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a class="commit-link" href="https://github.com/vllm-project/vllm/compare/v0.13.0...v0.14.0"><tt>v0.13.0...v0.14.0</tt></a></p>

---

### [v0.14.0rc2: [CI] Fix LM Eval Large Models (H100) (#32423)](https://github.com/vllm-project/vllm/releases/tag/v0.14.0rc2)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <p>Signed-off-by: Matthew Bonanni <a href="mailto:mbonanni@redhat.com">mbonanni@redhat.com</a><br />
(cherry picked from commit <a class="commit-link" href="https://github.com/vllm-project/vllm/commit/bcf2333cd6514543f579d9bb6d309c5b8a0bfd0d"><tt>bcf2333</tt></a>)</p>

---

### [v0.14.0rc1](https://github.com/vllm-project/vllm/releases/tag/v0.14.0rc1)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <p>[ROCm][Bugfix] Fix Mamba batched decode producing incorrect output (#‚Ä¶</p>

---

### [v0.14.0rc0](https://github.com/vllm-project/vllm/releases/tag/v0.14.0rc0)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <p>[Bugfix] Fix tool_choice="none" being ignored by GPT-OSS/harmony mode‚Ä¶</p>

---

### [v0.13.0](https://github.com/vllm-project/vllm/releases/tag/v0.13.0)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <h1>vLLM v0.13.0 Release Notes Highlights</h1>
<h2>Highlights</h2>
<p>This release features <strong>442 commits from 207 contributors (61 new contributors)!</strong></p>
<p><strong>Breaking Changes</strong>: This release includes deprecation removals, PassConfig flag renames, and attention configuration changes from environment variables to CLI arguments. Please review the breaking changes section carefully before upgrading.</p>
<h3>Model Support</h3>
<ul>
<li><strong>New models</strong>: BAGEL (AR only) (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28439">#28439</a>), AudioFlamingo3 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30539">#30539</a>), JAIS 2 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30188">#30188</a>), latent MoE architecture support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30203">#30203</a>).</li>
<li><strong>Tool parsers</strong>: DeepSeek-V3.2 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29848">#29848</a>), Gigachat 3 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29905">#29905</a>), Holo2 reasoning (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30048">#30048</a>).</li>
<li><strong>Model enhancements</strong>: Qwen3-VL embeddings support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30037">#30037</a>), Qwen3-VL EVS (Efficient Video Sampling) (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29752">#29752</a>), DeepSeek V3.2 proper <code>drop_thinking</code> logic (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30490">#30490</a>), DeepSeek V3.2 top-k fix (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27568">#27568</a>).</li>
<li><strong>Task expansion</strong>: Automatic TokenClassification model conversion (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30666">#30666</a>), Ultravox v0.7 transformer projector (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30089">#30089</a>).</li>
<li><strong>Quantization</strong>: BitsAndBytes for Qwen3-Omni-MoE (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29896">#29896</a>).</li>
<li><strong>Speculative decoding</strong>: Eagle/Eagle3 Transformers backend (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30340">#30340</a>), Mamba <code>selective_state_update</code> spec decode (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29488">#29488</a>).</li>
</ul>
<h3>Engine Core</h3>
<ul>
<li><strong>Compilation</strong>: Conditional compilation via <code>compile_ranges</code> for selective kernel compilation (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/24252">#24252</a>).</li>
<li><strong>Prefix caching</strong>: xxHash high-performance hash option (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29163">#29163</a>).</li>
<li><strong>Attention</strong>: PrefixLM support for FlexAttention (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27938">#27938</a>) and TritonAttention (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30386">#30386</a>), CUDA graphs for 3D Triton attention (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28306">#28306</a>), <code>TRITON_MLA</code> without prefix-caching (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29125">#29125</a>).</li>
<li><strong>Batch invariance</strong>: FA2 and LoRA batch-invariant support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30018">#30018</a>).</li>
<li><strong>Pooling</strong>: Chunked prefill for ALL pooling tasks (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27145">#27145</a>), multi-vector retrieval API (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/26686">#26686</a>).</li>
<li><strong>Model Runner V2</strong>: Min-p sampling (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30171">#30171</a>), NaN detection in logits (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30187">#30187</a>).</li>
<li><strong>Speculative decoding</strong>: Medusa GPU-CPU sync avoidance (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29723">#29723</a>), async spec-decode improvements (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29624">#29624</a>).</li>
<li><strong>Whisper</strong>: Major performance improvements - <a href="https://github.com/vllm-project/vllm/issues/24946#issuecomment-3680725754">V1 is now faster than V0</a> (~3x speedup vs v0.12.0). Encoder batching (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29421">#29421</a>), <code>FULL_DECODE_ONLY</code> CUDA graph (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30072">#30072</a>), CPU backend support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30062">#30062</a>).</li>
<li><strong>Performance</strong>: Fused blockwise quant RMS norm (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27883">#27883</a>), MoE LoRA loading reduction (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30243">#30243</a>), encoder cache optimization (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30475">#30475</a>), CPU KV offloading streams (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29013">#29013</a>).</li>
</ul>
<h3>Hardware &amp; Performance</h3>
<ul>
<li><strong>NVIDIA Blackwell Ultra</strong>: SM103 (GB300) support with CUDA 13 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30484">#30484</a>).</li>
<li><strong>DeepSeek optimizations</strong> (benchmarked on DeepSeek-V3.1):
<ul>
<li>DeepEP High-Throughput CUDA graph enabled by default: <strong>5.3% throughput, 4.4% TTFT improvement</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29558">#29558</a>)</li>
<li>DeepGEMM fused layout kernel: <strong>4.3% throughput, 10.7% TTFT improvement</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29546">#29546</a>)</li>
<li>DeepGEMM experts initialization: <strong>3.9% TTFT improvement</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30494">#30494</a>)</li>
<li><code>group_topk</code> kernel: <strong>1.9% throughput, 2.1% TPOT improvement</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30159">#30159</a>)</li>
<li>Sparse prefill kernel for FP8 KV-cache in DeepSeek-V3.2 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27532">#27532</a>)</li>
<li>MLA FP8 optimization with ReduceScatterSum (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29795">#29795</a>), direct k_nope/k_pe copy (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29710">#29710</a>)</li>
</ul>
</li>
<li><strong>CPU</strong>: Whisper support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30062">#30062</a>), Arm Optimized Routines vectorized exp (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30068">#30068</a>), x86 CPU wheel pipeline (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28848">#28848</a>).</li>
<li><strong>AMD ROCm</strong>: Aiter quantization kernels (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/25552">#25552</a>), torch.compile layernorm/silu + FP8 quant (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/25693">#25693</a>), Triton ScaledMM fallback (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/26668">#26668</a>), MXFP4 w4a4 inference (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29775">#29775</a>).</li>
<li><strong>Intel XPU</strong>: wNa16 compressed tensors (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29484">#29484</a>).</li>
<li><strong>Build</strong>: CUDA 13 aarch64 wheels (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30341">#30341</a>), Docker kernel build stage (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29452">#29452</a>), Ascend NPU Docker (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30015">#30015</a>).</li>
</ul>
<h3>Large Scale Serving &amp; Disaggregated Prefill/Decode</h3>
<ul>
<li><strong>KV connectors</strong>: Mooncake Transfer Engine (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/24718">#24718</a>), cache reset via <code>/reset_prefix_cache</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/27170">#27170</a>), KV events (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28309">#28309</a>), failure recovery config (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/26813">#26813</a>).</li>
<li><strong>NIXL</strong>: Compatibility checking in handshake (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29503">#29503</a>), large batch proxy support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28782">#28782</a>).</li>
<li><strong>EPLB</strong>: NVFP4 support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29804">#29804</a>), algorithm abstraction (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/26471">#26471</a>).</li>
<li><strong>Multi-node</strong>: External launcher mode (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29833">#29833</a>).</li>
<li><strong>Hybrid allocator</strong>: Optional KV connector integration (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29805">#29805</a>).</li>
<li><strong>Performance</strong>: silu_mul_per_token_group_quant_fp8 kernel for DP/EP (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29470">#29470</a>).</li>
</ul>
<h3>Quantization</h3>
<ul>
<li><strong>New</strong>: W4A8 grouped GEMM on Hopper (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29691">#29691</a>), online FP8 with streaming post-processing (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29196">#29196</a>), FP8 weight reloading for RLHF (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28480">#28480</a>).</li>
<li><strong>MoE + LoRA</strong>: AWQ Marlin (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30442">#30442</a>) and GPTQ Marlin (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30254">#30254</a>) support.</li>
<li><strong>GGUF</strong>: MoE + GGUF restored for Qwen3 MoE (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30116">#30116</a>), Qwen2 MoE (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30307">#30307</a>), HF defaults override (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30118">#30118</a>).</li>
<li><strong>Compatibility</strong>: Transformers v5 RoPE support (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30046">#30046</a>).</li>
</ul>
<h3>API &amp; Frontend</h3>
<ul>
<li><strong>Responses API</strong>: MCP type infrastructure (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30054">#30054</a>), Browser/Container MCP tools (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29989">#29989</a>), full MCP Python loop (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29798">#29798</a>), extra body parameters (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30532">#30532</a>).</li>
<li><strong>Configuration</strong>: <code>AttentionConfig</code> replaces <code>VLLM_ATTENTION_BACKEND</code> env var (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/26315">#26315</a>).</li>
<li><strong>Chat templates</strong>: DeepSeek-V3.2 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29837">#29837</a>), DeepSeek-V3.2 developer tools (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30040">#30040</a>).</li>
<li><strong>Anthropic API</strong>: Streaming fixes (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29971">#29971</a>, <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30266">#30266</a>).</li>
<li><strong>Embeddings</strong>: Binary format with <code>encoding_format=bytes_only</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30249">#30249</a>), multiple image/audio per request (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29988">#29988</a>), tokenization_kwargs override (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29794">#29794</a>).</li>
<li><strong>Metrics</strong>: Prefill KV compute metric excluding cached tokens (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30189">#30189</a>).</li>
<li><strong>Profiling</strong>: Layer-wise NVTX (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29990">#29990</a>), profiling CLI config (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29912">#29912</a>).</li>
<li><strong>UX</strong>: Better OOM errors (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28051">#28051</a>), ModelConfig validation (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30213">#30213</a>), distributed executor errors (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30140">#30140</a>).</li>
</ul>
<h3>Security</h3>
<ul>
<li>Additional protection for <a href="https://github.com/advisories/GHSA-mrw7-hf4f-83pf" title="CVE-2025-62164">CVE-2025-62164</a> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30649">#30649</a>).</li>
</ul>
<h3>Dependencies</h3>
<ul>
<li>NVSHMEM 3.3.24 + CUDA 13 fix (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30149">#30149</a>).</li>
<li>TPU tpu-inference 0.12.0 (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30221">#30221</a>).</li>
</ul>
<h3>Breaking Changes &amp; Deprecations</h3>
<ol>
<li><strong>PassConfig flags renamed</strong> per RFC <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/issues/27995">#27995</a> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29646">#29646</a>)</li>
<li><strong>Attention env vars ‚Üí CLI args</strong>: <code>VLLM_ATTENTION_BACKEND</code> replaced with <code>--attention-backend</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/26315">#26315</a>)</li>
<li><strong>Removed <code>-O.xx</code> flag</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29991">#29991</a>)</li>
<li><strong>Removed deprecated plugin/compilation fields</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30396">#30396</a>)</li>
<li><strong>Removed deprecated task, seed, MM settings</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30397">#30397</a>)</li>
<li><strong>Removed <code>embed_input_ids</code>/<code>embed_multimodal</code> fallbacks</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30458">#30458</a>)</li>
<li><strong>Removed tokenizer setter</strong> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30400">#30400</a>)</li>
<li><strong>Deprecations</strong>: <code>merge_by_field_config</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30035">#30035</a>, <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30170">#30170</a>), <code>--convert reward</code> ‚Üí <code>--convert embed</code> (<a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30463">#30463</a>)</li>
</ol>
<h2>New Contributors üéâ</h2>
<ul>
<li><a class="user-mention notranslate" href="https://github.com/ajpqs">@ajpqs</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29905">#29905</a></li>
<li><a class="user-mention notranslate" href="https://github.com/amitz-nv">@amitz-nv</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29978">#29978</a></li>
<li><a class="user-mention notranslate" href="https://github.com/amrmahdi">@amrmahdi</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29452">#29452</a></li>
<li><a class="user-mention notranslate" href="https://github.com/andrewbriand">@andrewbriand</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29804">#29804</a></li>
<li><a class="user-mention notranslate" href="https://github.com/anker-c2">@anker-c2</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30344">#30344</a></li>
<li><a class="user-mention notranslate" href="https://github.com/AuruTus">@AuruTus</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30182">#30182</a></li>
<li><a class="user-mention notranslate" href="https://github.com/avigny">@avigny</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/19425">#19425</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Bhanu068">@Bhanu068</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30254">#30254</a></li>
<li>@Copilot made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29025">#29025</a></li>
<li><a class="user-mention notranslate" href="https://github.com/dbotwinick">@dbotwinick</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30583">#30583</a></li>
<li><a class="user-mention notranslate" href="https://github.com/dependabot">@dependabot</a>[bot] made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30234">#30234</a></li>
<li><a class="user-mention notranslate" href="https://github.com/desertfire">@desertfire</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29919">#29919</a></li>
<li><a class="user-mention notranslate" href="https://github.com/dmitry-tokarev-nv">@dmitry-tokarev-nv</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30149">#30149</a></li>
<li><a class="user-mention notranslate" href="https://github.com/drslark">@drslark</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30632">#30632</a></li>
<li><a class="user-mention notranslate" href="https://github.com/dtcccc">@dtcccc</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/24718">#24718</a></li>
<li><a class="user-mention notranslate" href="https://github.com/elizabetht">@elizabetht</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/28671">#28671</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Elm8116">@Elm8116</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30068">#30068</a></li>
<li><a class="user-mention notranslate" href="https://github.com/gausah01">@gausah01</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29604">#29604</a></li>
<li><a class="user-mention notranslate" href="https://github.com/gh-wf">@gh-wf</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30285">#30285</a></li>
<li><a class="user-mention notranslate" href="https://github.com/hdlj-h">@hdlj-h</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30056">#30056</a></li>
<li><a class="user-mention notranslate" href="https://github.com/HF-001">@HF-001</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30051">#30051</a></li>
<li><a class="user-mention notranslate" href="https://github.com/hzxuzhonghu">@hzxuzhonghu</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29931">#29931</a></li>
<li><a class="user-mention notranslate" href="https://github.com/JaviS-Rei">@JaviS-Rei</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29882">#29882</a></li>
<li><a class="user-mention notranslate" href="https://github.com/johannesflommersfeld">@johannesflommersfeld</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30390">#30390</a></li>
<li><a class="user-mention notranslate" href="https://github.com/KevinMusgrave">@KevinMusgrave</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30529">#30529</a></li>
<li><a class="user-mention notranslate" href="https://github.com/kitaekatt">@kitaekatt</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30408">#30408</a></li>
<li><a class="user-mention notranslate" href="https://github.com/lashahub">@lashahub</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30539">#30539</a></li>
<li><a class="user-mention notranslate" href="https://github.com/LuminolT">@LuminolT</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29163">#29163</a></li>
<li><a class="user-mention notranslate" href="https://github.com/majiayu000">@majiayu000</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30615">#30615</a></li>
<li><a class="user-mention notranslate" href="https://github.com/MaoJianwei">@MaoJianwei</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29797">#29797</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Mercykid-bash">@Mercykid-bash</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/26471">#26471</a></li>
<li><a class="user-mention notranslate" href="https://github.com/mgehre-amd">@mgehre-amd</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30364">#30364</a></li>
<li><a class="user-mention notranslate" href="https://github.com/mivehk">@mivehk</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30512">#30512</a></li>
<li><a class="user-mention notranslate" href="https://github.com/mondaylord">@mondaylord</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30671">#30671</a></li>
<li><a class="user-mention notranslate" href="https://github.com/noa-neria">@noa-neria</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29320">#29320</a></li>
<li><a class="user-mention notranslate" href="https://github.com/PatrykSaffer">@PatrykSaffer</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30330">#30330</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Peng-YM">@Peng-YM</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29074">#29074</a></li>
<li><a class="user-mention notranslate" href="https://github.com/realliujiaxu">@realliujiaxu</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30059">#30059</a></li>
<li><a class="user-mention notranslate" href="https://github.com/redwrasse">@redwrasse</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29261">#29261</a></li>
<li><a class="user-mention notranslate" href="https://github.com/Ri0S">@Ri0S</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30532">#30532</a></li>
<li><a class="user-mention notranslate" href="https://github.com/sarathc-cerebras">@sarathc-cerebras</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30188">#30188</a></li>
<li><a class="user-mention notranslate" href="https://github.com/scratch-ml">@scratch-ml</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30351">#30351</a></li>
<li><a class="user-mention notranslate" href="https://github.com/seokhyunan">@seokhyunan</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30648">#30648</a></li>
<li><a class="user-mention notranslate" href="https://github.com/shaharmor98">@shaharmor98</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30203">#30203</a></li>
<li><a class="user-mention notranslate" href="https://github.com/taoyun951753">@taoyun951753</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30037">#30037</a></li>
<li><a class="user-mention notranslate" href="https://github.com/tom-zju">@tom-zju</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30057">#30057</a></li>
<li><a class="user-mention notranslate" href="https://github.com/tomtomjhj">@tomtomjhj</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29692">#29692</a></li>
<li><a class="user-mention notranslate" href="https://github.com/vkuzo">@vkuzo</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29196">#29196</a></li>
<li><a class="user-mention notranslate" href="https://github.com/vladnosiv">@vladnosiv</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30490">#30490</a></li>
<li><a class="user-mention notranslate" href="https://github.com/weiguihua2">@weiguihua2</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30042">#30042</a></li>
<li><a class="user-mention notranslate" href="https://github.com/wenqiglantz">@wenqiglantz</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30649">#30649</a></li>
<li><a class="user-mention notranslate" href="https://github.com/wkcn">@wkcn</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29879">#29879</a></li>
<li><a class="user-mention notranslate" href="https://github.com/wu-kan">@wu-kan</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/21804">#21804</a></li>
<li><a class="user-mention notranslate" href="https://github.com/wz1qqx">@wz1qqx</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30376">#30376</a></li>
<li><a class="user-mention notranslate" href="https://github.com/xyDong0223">@xyDong0223</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30455">#30455</a></li>
<li><a class="user-mention notranslate" href="https://github.com/yifant-code">@yifant-code</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30213">#30213</a></li>
<li><a class="user-mention notranslate" href="https://github.com/yjc9696">@yjc9696</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30040">#30040</a></li>
<li><a class="user-mention notranslate" href="https://github.com/yurekami">@yurekami</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30552">#30552</a></li>
<li><a class="user-mention notranslate" href="https://github.com/yuttian1">@yuttian1</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30102">#30102</a></li>
<li><a class="user-mention notranslate" href="https://github.com/ZhijianJiang">@ZhijianJiang</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/30219">#30219</a></li>
<li><a class="user-mention notranslate" href="https://github.com/ZhiweiYan-96">@ZhiweiYan-96</a> made their first contribution in <a class="issue-link js-issue-link" href="https://github.com/vllm-project/vllm/pull/29773">#29773</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a class="commit-link" href="https://github.com/vllm-project/vllm/compare/v0.12.0...v0.13.0"><tt>v0.12.0...v0.13.0</tt></a></p>

---

### [v0.13.0rc4: [v1] Add PrefixLM support to TritonAttention backend (#30386)](https://github.com/vllm-project/vllm/releases/tag/v0.13.0rc4)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <p>(cherry picked from commit <a class="commit-link" href="https://github.com/vllm-project/vllm/commit/74a1ac38b00a8cf502db085d1bbd77712cf47e41"><tt>74a1ac3</tt></a>)</p>

---

### [v0.13.0rc3: [XPU] fix broken fp8 online quantization for XPU platform (#30831)](https://github.com/vllm-project/vllm/releases/tag/v0.13.0rc3)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <p>Signed-off-by: Yan Ma <a href="mailto:yan.ma@intel.com">yan.ma@intel.com</a><br />
(cherry picked from commit <a class="commit-link" href="https://github.com/vllm-project/vllm/commit/4f735babb7353987137b85ec0465e594e9ed1384"><tt>4f735ba</tt></a>)</p>

---

### [v0.13.0rc2: [ROCm] [Bugfix] Fix torch sdpa hallucination (#30789)](https://github.com/vllm-project/vllm/releases/tag/v0.13.0rc2)

**Êù•Ê∫ê**: vLLM GitHub Releases

**ÊëòË¶Å**: <p>Signed-off-by: tjtanaa <a href="mailto:tunjian.tan@embeddedllm.com">tunjian.tan@embeddedllm.com</a><br />
(cherry picked from commit <a class="commit-link" href="https://github.com/vllm-project/vllm/commit/2410132bb1f9faa5b252fad3f2b83dc926946b08"><tt>2410132</tt></a>)</p>

---

## Operating Systems

### [[$] Fedora and GPG 2.5](https://lwn.net/Articles/1055053/)

**Êù•Ê∫ê**: LWN.net (Linux Weekly News)

**ÊëòË¶Å**: <p>The <a href="https://www.gnupg.org/">GNU Privacy Guard</a> (GPG)
project decided to break from the <a href="https://www.openpgp.org/">OpenPGP</a> standard for email
encryption in 2023, and instead <a href="https://lwn.net/Articles/953797/">adopted its own</a> homegrown <a href="https://librepgp.org/">LibrePGP</a> specification. The GPG 2.4
branch, the last one to adhere to OpenPGP, will be reaching the end of
life in mid-2026. The Fedora project is currently having a discussion
about how that affects the distribution, its users, and what to offer
once 2.4 is no longer receiving updates.</p>

---

### [Stenberg: The end of the curl bug-bounty program](https://lwn.net/Articles/1055996/)

**Êù•Ê∫ê**: LWN.net (Linux Weekly News)

**ÊëòË¶Å**: <p>Curl creator Daniel Stenberg has written a <a href="https://daniel.haxx.se/blog/2026/01/26/the-end-of-the-curl-bug-bounty/">blog
post</a> explaining why the project is ending its bug-bounty
program, which started in April 2019:</p>

<blockquote class="bq">
<p>The never-ending slop submissions take a serious mental toll to
manage and sometimes also a long time to debunk. Time and energy that
is completely wasted while also hampering our will to live.</p>

<p>I have also started to get the feeling that a lot of the security
reporters submit reports with a bad faith attitude. These "helpers"
try too hard to twist whatever they find into something horribly bad
and a critical vulnerability, but they rarely actively contribute to
actually improve curl. They can go to extreme efforts to argue and
insist on their specific current finding, but not to write a fix or
work with the team on improving curl long-term etc. I don't think we
need more of that.</p>

<p>There are these three bad trends combined that makes us take this
step: the mind-numbing AI slop, humans doing worse than ever and the
apparent will to poke holes rather than to help.</p>
</blockquote>

<p>Stenberg writes that he still expects "<q>the best and our most
valued security reporters</q>" to continue informing the project when
security vulnerabilities are discovered. The program will officially
end on January 31, 2026.</p>

<p></p>

---

### [Security updates for Monday](https://lwn.net/Articles/1055958/)

**Êù•Ê∫ê**: LWN.net (Linux Weekly News)

**ÊëòË¶Å**: Security updates have been issued by <b>AlmaLinux</b> (gimp, glib2, go-toolset:rhel8, golang, java-17-openjdk, java-21-openjdk, kernel, net-snmp, pcs, and thunderbird), <b>Debian</b> (apache2, imagemagick, incus, inetutils, libuev, openjdk-17, php7.4, python3.9, shapelib, taglib, and zvbi), <b>Fedora</b> (mingw-glib2, mingw-harfbuzz, mingw-libsoup, mingw-openexr, pgadmin4, python3.11, python3.12, python3.9, and wireshark), <b>Gentoo</b> (Asterisk, Commons-BeanUtils, GIMP, inetutils, and Vim, gVim), <b>Mageia</b> (kernel), <b>Oracle</b> (glib2, java-17-openjdk, java-21-openjdk, and libpng), <b>Red Hat</b> (java-17-openjdk, java-21-openjdk, kernel, and kernel-rt), <b>SUSE</b> (azure-cli-core, bind, buildah, chromium, coredns, glib2, harfbuzz, kernel, kernel-firmware, libheif, libvirt, openCryptoki, openvswitch, podman, python, python-urllib3, rabbitmq-server, and vlang), and <b>Ubuntu</b> (cjson).

---

## Systems

### [A data model for Git (and other docs updates)](https://jvns.ca/blog/2026/01/08/a-data-model-for-git/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>Hello! This past fall, I decided to take some time to work on Git&rsquo;s
documentation. I&rsquo;ve been thinking about working on open source docs for a long
time &ndash; usually if I think the documentation for something could be improved,
I&rsquo;ll write a blog post or a zine or something. But this time I wondered: could I
instead make a few improvements to the official documentation?</p>
<p>So <a href="https://marieflanagan.com/">Marie</a> and I made a few changes to the Git
documentation!</p>
<h3 id="a-data-model-for-git">a data model for Git</h3>
<p>After a while working on the documentation, we noticed that Git uses the terms
&ldquo;object&rdquo;, &ldquo;reference&rdquo;, or &ldquo;index&rdquo; in its documentation a lot, but that it didn&rsquo;t
have a great explanation of what those terms mean or how they relate to other
core concepts like &ldquo;commit&rdquo; and &ldquo;branch&rdquo;. So we wrote a new &ldquo;data model&rdquo; document!</p>
<p>You can <a href="https://github.com/git/git/blob/master/Documentation/gitdatamodel.adoc">read the data model here for now</a>.
I assume at some point (after the next release?) it&rsquo;ll also be on the <a href="https://git-scm.com">Git website</a>.</p>
<p>I&rsquo;m excited about this because understanding how Git organizes its commit and
branch data has really helped me reason about how Git works over the years,
and I think it&rsquo;s important to have a short (1600 words!) version of the data
model that&rsquo;s accurate.</p>
<p>The &ldquo;accurate&rdquo; part turned out to not be that easy: I knew the basics of how
Git&rsquo;s data model worked, but during the review process I learned some new
details and had to make quite a few changes (for example how merge conflicts are
stored in the staging area).</p>
<h3 id="updates-to-git-push-git-pull-and-more">updates to <code>git push</code>, <code>git pull</code>, and more</h3>
<p>I also worked on updating the introduction to some of Git&rsquo;s core man pages.
I quickly realized that &ldquo;just try to improve it according to my best judgement&rdquo;
was not going to work: why should the maintainers believe me that my version is
better?</p>
<p>I&rsquo;ve seen a problem a lot when discussing open source documentation changes
where 2 expert users of the software argue about whether an explanation
is clear or not (&ldquo;I think X would be a good way to explain it! Well, I think Y
would be better!&rdquo;)</p>
<p>I don&rsquo;t think this is very productive (expert users of a piece of software
are notoriously bad at being able to tell if an explanation will be clear to
non-experts), so I needed to find a way to identify problems with the man
pages that was a little more evidence-based.</p>
<h3 id="getting-test-readers-to-identify-problems">getting test readers to identify problems</h3>
<p>I asked for test readers on Mastodon to read the current version of
documentation and tell me what they find confusing or what questions they have.
About 80 test readers left comments, and I learned so much!</p>
<p>People left a huge amount of great feedback, for example:</p>
<ul>
<li>terminology they didn&rsquo;t understand (what&rsquo;s a pathspec? what does &ldquo;reference&rdquo; mean? does &ldquo;upstream&rdquo; have a specific meaning in Git?)</li>
<li>specific confusing sentences</li>
<li>suggestions of things things to add (&ldquo;I do X all the time, I think it should be included here&rdquo;)</li>
<li>inconsistencies (&ldquo;here it implies X is the default, but elsewhere it implies Y is the default&rdquo;)</li>
</ul>
<p>Most of the test readers had been using Git for at least 5-10 years, which
I think worked well &ndash; if a group of test readers who have been using Git
regularly for 5+ years find a sentence or term impossible to understand, it
makes it easy to argue that the documentation should be updated to make it
clearer.</p>
<p>I thought this &ldquo;get users of the software to comment on the existing
documentation and then fix the problems they find&rdquo; pattern worked really
well and I&rsquo;m excited about potentially trying it again in the future.</p>
<h3 id="the-man-page-changes">the man page changes</h3>
<p>We ended updating these 4 man pages:</p>
<ul>
<li><code>git add</code> (<a href="https://github.com/git/git/blob/2b3ae040/Documentation/git-add.adoc">before</a>, <a href="https://github.com/git/git/blob/e0bfec3dfc356f7d808eb5ee546a54116b794397/Documentation/git-add.adoc">after</a>)</li>
<li><code>git checkout</code> (<a href="https://github.com/git/git/blob/2b3ae040/Documentation/git-checkout.adoc">before</a>, <a href="https://github.com/git/git/blob/e0bfec3dfc356f7d808eb5ee546a54116b794397/Documentation/git-checkout.adoc">after</a>)</li>
<li><code>git push</code> (<a href="https://github.com/git/git/blob/2b3ae040/Documentation/git-push.adoc">before</a>, <a href="https://github.com/git/git/blob/e0bfec3dfc356f7d808eb5ee546a54116b794397/Documentation/git-push.adoc">after</a>)</li>
<li><code>git pull</code> (<a href="https://github.com/git/git/blob/2b3ae040/Documentation/git-pull.adoc">before</a>, <a href="https://github.com/git/git/blob/e0bfec3dfc356f7d808eb5ee546a54116b794397/Documentation/git-pull.adoc">after</a>)</li>
</ul>
<p>The <code>git push</code> and <code>git pull</code> changes were the most interesting to me: in
addition to updating the intro to those pages, we also ended up writing:</p>
<ul>
<li><a href="https://github.com/git/git/blob/e0bfec3dfc356f7d808eb5ee546a54116b794397/Documentation/urls-remotes.adoc#upstream-branches">a section describing what the term &ldquo;upstream branch&rdquo; means</a> (which previously wasn&rsquo;t really explained)</li>
<li><a href="https://github.com/git/git/blob/e0bfec3dfc356f7d808eb5ee546a54116b794397/Documentation/git-push.adoc#options">a cleaned-up description of what a &ldquo;push refspec&rdquo; is</a></li>
</ul>
<p>Making those changes really gave me an appreciation for how much work it is
to maintain open source documentation: it&rsquo;s not easy to write things that are
both clear and true, and sometimes we had to make compromises, for example the sentence
&ldquo;<code>git push</code> may fail if you haven‚Äôt set an upstream for the current branch,
depending on what <code>push.default</code> is set to.&rdquo; is a little vague, but the exact
details of what &ldquo;depending&rdquo; means are really complicated and untangling that is
a big project.</p>
<h3 id="on-the-process-for-contributing-to-git">on the process for contributing to Git</h3>
<p>It took me a while to understand Git&rsquo;s development process.
I&rsquo;m not going to try to describe it here (that could be a whole other post!), but a few quick notes:</p>
<ul>
<li>Git has a <a href="https://git-scm.com/community#discord">Discord server</a>
with a &ldquo;my first contribution&rdquo; channel for help with getting started contributing.
I found people to be very welcoming on the Discord.</li>
<li>I used <a href="https://gitgitgadget.github.io/">GitGitGadget</a> to make all of my contributions.
This meant that I could make a GitHub pull request (a workflow I&rsquo;m comfortable
with) and GitGitGadget would convert my PRs into the system the Git developers
use (emails with patches attached). GitGitGadget worked great and I was very
grateful to not have to learn how to send patches by email with Git.</li>
<li>Otherwise I used my normal email client (Fastmail&rsquo;s web interface) to reply
to emails, wrapping my text to 80 character lines since that&rsquo;s the mailing
list norm.</li>
</ul>
<p>I also found the mailing list archives on <a href="https://lore.kernel.org/git/">lore.kernel.org</a>
hard to navigate, so I hacked together <a href="https://github.com/jvns/git-list-viewer">my own git list viewer</a>
to make it easier to read the long mailing list threads.</p>
<p>Many people helped me navigate the contribution process and review the changes:
thanks to Emily Shaffer, Johannes Schindelin (the author of GitGitGadget),
Patrick Steinhardt, Ben Knoble, Junio Hamano, and more.</p>
<p>(I&rsquo;m experimenting with <a href="https://comments.jvns.ca/post/115861337435768520">comments on Mastodon, you can see the comments here</a>)</p>

---

### [Notes on switching to Helix from vim](https://jvns.ca/blog/2025/10/10/notes-on-switching-to-helix-from-vim/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>Hello! Earlier this summer I was talking to a friend about how much I
<a href="https://jvns.ca/blog/2024/09/12/reasons-i--still--love-fish/">love using fish</a>, and
how I love that I don&rsquo;t have to configure it. They said that they feel the same
way about the <a href="https://helix-editor.com/">helix</a> text editor, and so I decided
to give it a try.</p>
<p>I&rsquo;ve been using it for 3 months now and here are a few notes.</p>
<h3 id="why-helix-language-servers">why helix: language servers</h3>
<p>I think what motivated me to try Helix is that I&rsquo;ve been trying to get a working
language server setup (so I can do things like &ldquo;go to definition&rdquo;) and getting
a setup that feels good in Vim or Neovim just felt like too much work.</p>
<p>After using Vim/Neovim for 20 years, I&rsquo;ve tried both &ldquo;build my own custom
configuration from scratch&rdquo; and &ldquo;use someone else&rsquo;s pre-buld configuration
system&rdquo; and even though I love Vim I was excited about having things just work
without having to work on my configuration at all.</p>
<p>Helix comes with built in language server support, and it feels nice
to be able to do things like &ldquo;rename this symbol&rdquo; in any language.</p>
<h3 id="the-search-is-great">the search is great</h3>
<p>One of my favourite things about Helix is the search! If I&rsquo;m searching all the
files in my repository for a string, it lets me scroll through the potential
matching files and see the full context of the match, like this:</p>
<img src="https://jvns.ca/images/helix-search.png" />
<p>For comparison, here&rsquo;s what the vim ripgrep plugin I&rsquo;ve been using looks like:</p>
<img src="https://jvns.ca/images/vim-ripgrep.png" />
<p>There&rsquo;s no context for what else is around that line.</p>
<h3 id="the-quick-reference-is-nice">the quick reference is nice</h3>
<p>One thing I like about Helix is that when I press <code>g</code>, I get a little help popup
telling me places I can go. I really appreciate this because I don&rsquo;t often use
the &ldquo;go to definition&rdquo; or &ldquo;go to reference&rdquo; feature and I often forget the
keyboard shortcut.</p>
<img src="https://jvns.ca/images/goto.png" width="300px" />
<h3 id="some-vim-helix-translations">some vim -&gt; helix translations</h3>
<ul>
<li>Helix doesn&rsquo;t have marks like <code>ma</code>, <code>'a</code>, instead I&rsquo;ve been using <code>Ctrl+O</code> and
<code>Ctrl+I</code> to go back (or forward) to the last cursor location</li>
<li>I think Helix does have macros, but I&rsquo;ve been using multiple cursors in every
case that I would have previously used a macro. I like multiple cursors a lot
more than writing macros all the time. If I want to batch change something in
the document, my workflow is to press <code>%</code> (to highlight everything), then <code>s</code>
to select (with a regex) the things I want to change, then I can just edit
all of them as needed.</li>
<li>Helix doesn&rsquo;t have neovim-style tabs, instead it has a nice buffer switcher (<code>&lt;space&gt;b</code>)
I can use to switch to the buffer I want. There&rsquo;s a
<a href="https://github.com/helix-editor/helix/pull/7109">pull request here</a> to implement neovim-style tabs.
There&rsquo;s also a setting <code>bufferline=&quot;multiple&quot;</code> which can act a bit like tabs
with <code>gp</code>, <code>gn</code> for prev/next &ldquo;tab&rdquo; and <code>:bc</code> to close a &ldquo;tab&rdquo;.</li>
</ul>
<h3 id="some-helix-annoyances">some helix annoyances</h3>
<p>Here&rsquo;s everything that&rsquo;s annoyed me about Helix so far.</p>
<ul>
<li>I like the way Helix&rsquo;s <code>:reflow</code> works much less than how
vim reflows text with <code>gq</code>. It doesn&rsquo;t work as well with lists. (<a href="https://github.com/helix-editor/helix/issues/3332">github issue</a>)</li>
<li>If I&rsquo;m making a Markdown list, pressing &ldquo;enter&rdquo; at the end of a list item
won&rsquo;t continue the list. There&rsquo;s a <a href="https://github.com/helix-editor/helix/wiki/Recipes#continue-markdown-lists--quotes">partial workaround</a>
for bulleted lists but I don&rsquo;t know one for numbered lists.</li>
<li>No persistent undo yet: in vim I could use an
<a href="https://vimdoc.sourceforge.net/htmldoc/options.html#'undofile'">undofile</a> so
that I could undo changes even after quitting. Helix doesn&rsquo;t have that feature yet.
(<a href="https://github.com/helix-editor/helix/pull/9154">github PR</a>)</li>
<li>Helix doesn&rsquo;t autoreload files after they change on disk, I have to run
<code>:reload-all</code> (<code>:ra&lt;tab&gt;</code>) to manually reload them. Not a big deal.</li>
<li>Sometimes it crashes, maybe every week or so. I think it might be
<a href="https://github.com/helix-editor/helix/issues/12582">this issue</a>.</li>
</ul>
<p>The &ldquo;markdown list&rdquo; and reflowing issues come up a lot for me because I spend
a lot of time editing Markdown lists, but I keep using Helix anyway so I guess
they can&rsquo;t be making me that mad.</p>
<h3 id="switching-was-easier-than-i-thought">switching was easier than I thought</h3>
<p>I was worried that relearning 20 years of Vim muscle memory would be really hard.</p>
<p>It turned out to be easier than I expected, I started using Helix on a
vacation for a little low-stakes coding project I was doing on the side and
after a week or two it didn&rsquo;t feel so disorienting anymore. I think it might be
hard to switch back and forth between Vim and Helix, but I haven&rsquo;t needed to use
Vim recently so I don&rsquo;t know if that&rsquo;ll ever become an issue for me.</p>
<p>The first time I tried Helix I tried to force it to use keybindings that were
more similar to Vim and that did not work for me. Just learning the &ldquo;Helix way&rdquo;
was a lot easier.</p>
<p>There are still some things that throw me off: for example <code>w</code> in vim and <code>w</code> in
Helix don&rsquo;t have the same idea of what a &ldquo;word&rdquo; is (the Helix one includes the
space after the word, the Vim one doesn&rsquo;t).</p>
<h3 id="using-a-terminal-based-text-editor">using a terminal-based text editor</h3>
<p>For many years I&rsquo;d mostly been using a GUI version of vim/neovim, so switching
to actually using an editor in the terminal was a bit of an adjustment.</p>
<p>I ended up deciding on:</p>
<ol>
<li>Every project gets its own terminal window, and all of the tabs in that
window (mostly) have the same working directory</li>
<li>I make my Helix tab the first tab in the terminal window</li>
</ol>
<p>It works pretty well, I might actually like it better than my previous workflow.</p>
<h3 id="my-configuration">my configuration</h3>
<p>I appreciate that my configuration is really simple, compared to my neovim
configuration which is hundreds of lines. It&rsquo;s mostly just 4 keyboard
shortcuts.</p>
<pre><code>theme = &quot;solarized_light&quot;
[editor]
# Sync clipboard with system clipboard
default-yank-register = &quot;+&quot;

[keys.normal]
# I didn't like that Ctrl+C was the default &quot;toggle comments&quot; shortcut
&quot;#&quot; = &quot;toggle_comments&quot;

# I didn't feel like learning a different way
# to go to the beginning/end of a line so
# I remapped ^ and $
&quot;^&quot; = &quot;goto_first_nonwhitespace&quot;
&quot;$&quot; = &quot;goto_line_end&quot;

[keys.select]
&quot;^&quot; = &quot;goto_first_nonwhitespace&quot;
&quot;$&quot; = &quot;goto_line_end&quot;

[keys.normal.space]
# I write a lot of text so I need to constantly reflow,
# and missed vim's `gq` shortcut
l = &quot;:reflow&quot;
</code></pre>
<p>There&rsquo;s a separate <code>languages.toml</code> configuration where I set some language
preferences, like turning off autoformatting.
For example, here&rsquo;s my Python configuration:</p>
<pre><code>[[language]]
name = &quot;python&quot;
formatter = { command = &quot;black&quot;, args = [&quot;--stdin-filename&quot;, &quot;%{buffer_name}&quot;, &quot;-&quot;] }
language-servers = [&quot;pyright&quot;]
auto-format = false
</code></pre>
<h3 id="we-ll-see-how-it-goes">we&rsquo;ll see how it goes</h3>
<p>Three months is not that long, and it&rsquo;s possible that I&rsquo;ll decide to go back
to Vim at some point. For example, I wrote a <a href="https://jvns.ca/blog/2023/02/28/some-notes-on-using-nix/">post about switching to
nix</a> a while back but
after maybe 8 months I switched back to Homebrew (though I&rsquo;m still using NixOS
to manage one little server, and I&rsquo;m still satisfied with that).</p>

---

### [New zine: The Secret Rules of the Terminal](https://jvns.ca/blog/2025/06/24/new-zine--the-secret-rules-of-the-terminal/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>Hello! After many months of writing deep dive blog posts about the terminal, on
Tuesday I released a new zine called &ldquo;The Secret Rules of the Terminal&rdquo;!</p>
<p>You can get it for $12 here:
<a href="https://wizardzines.com/zines/terminal">https://wizardzines.com/zines/terminal</a>, or get
an <a href="https://wizardzines.com/zines/all-the-zines/">15-pack of all my zines here</a>.</p>
<p>Here&rsquo;s the cover:</p>
<div align="center">
<a href="https://wizardzines.com/zines/terminal">
  <img src="https://jvns.ca/images/terminal-cover-small.jpg" width="600px" />
  </a>
</div>
<h3 id="the-table-of-contents">the table of contents</h3>
<p>Here&rsquo;s the table of contents:</p>
<a href="https://wizardzines.com/zines/terminal/toc.png">
  <img src="https://jvns.ca/images/terminal-toc-small.png" width="600px" />
</a>
<h3 id="why-the-terminal">why the terminal?</h3>
<p>I&rsquo;ve been using the terminal every day for 20 years but even though I&rsquo;m very
confident in the terminal, I&rsquo;ve always had a bit of an uneasy feeling about it.
Usually things work fine, but sometimes something goes wrong and it just feels
like investigating it is impossible, or at least like it would open up a huge
can of worms.</p>
<p>So I started trying to write down a list of weird problems I&rsquo;ve run into in terminal and I realized
that the terminal has a lot of tiny inconsistencies like:</p>
<ul>
<li>sometimes you can use the arrow keys to move around, but sometimes pressing the arrow keys just prints <code>^[[D</code></li>
<li>sometimes you can use the mouse to select text, but sometimes you can&rsquo;t</li>
<li>sometimes your commands get saved to a history when you run them, and sometimes they don&rsquo;t</li>
<li>some shells let you use the up arrow to see the previous command, and some don&rsquo;t</li>
</ul>
<p>If you use the terminal daily for 10 or 20 years, even if you don&rsquo;t understand
exactly <em>why</em> these things happen, you&rsquo;ll probably build an intuition for them.</p>
<p>But having an intuition for them isn&rsquo;t the same as understanding why they
happen. When writing this zine I actually had to do a lot of work to figure out
exactly what was <em>happening</em> in the terminal to be able to talk about how to
reason about it.</p>
<h3 id="the-rules-aren-t-written-down-anywhere">the rules aren&rsquo;t written down anywhere</h3>
<p>It turns out that the &ldquo;rules&rdquo; for how the terminal works (how do
you edit a command you type in? how do you quit a program? how do you fix your
colours?) are extremely hard to fully understand, because &ldquo;the terminal&rdquo; is actually
made of many different pieces of software (your terminal emulator, your
operating system, your shell, the core utilities like <code>grep</code>, and every other random
terminal program you&rsquo;ve installed) which are written by different people with different
ideas about how things should work.</p>
<p>So I wanted to write something that would explain:</p>
<ul>
<li>how the 4 pieces of the terminal (your shell, terminal emulator, programs, and TTY driver) fit together to make everything work</li>
<li>some of the core conventions for how you can expect things in your terminal to work</li>
<li>lots of tips and tricks for how to use terminal programs</li>
</ul>
<h3 id="this-zine-explains-the-most-useful-parts-of-terminal-internals">this zine explains the most useful parts of terminal internals</h3>
<p>Terminal internals are a mess. A lot of it is just the way it is because
someone made a decision in the 80s and now it&rsquo;s impossible to change, and
honestly I don&rsquo;t think learning everything about terminal internals is worth
it.</p>
<p>But some parts are not that hard to understand and can really make your
experience in the terminal better, like:</p>
<ul>
<li>if you understand what <strong>your shell</strong> is responsible for, you can configure your shell (or use a different one!) to access your history more easily, get great tab completion, and so much more</li>
<li>if you understand <strong>escape codes</strong>, it&rsquo;s much less scary when <code>cat</code>ing a binary to stdout messes up your terminal, you can just type <code>reset</code> and move on</li>
<li>if you understand how <strong>colour</strong> works, you can get rid of bad colour contrast in your terminal so you can actually read the text</li>
</ul>
<h3 id="i-learned-a-surprising-amount-writing-this-zine">I learned a surprising amount writing this zine</h3>
<p>When I wrote <a href="https://wizardzines.com/zines/git">How Git Works</a>, I thought I
knew how Git worked, and I was right. But the terminal is different. Even
though I feel totally confident in the terminal and even though I&rsquo;ve used it
every day for 20 years, I had a lot of misunderstandings about how the terminal
works and (unless you&rsquo;re the author of <code>tmux</code> or something) I think there&rsquo;s a
good chance you do too.</p>
<p>A few things I learned that are actually useful to me:</p>
<ul>
<li>I understand the structure of the terminal better and so I feel more
confident debugging weird terminal stuff that happens to me (I was even able
to suggest a <a href="https://github.com/fish-shell/fish-shell/issues/10834">small improvement</a> to fish!). Identifying exactly which piece of software is causing a weird thing to happen in my terminal still isn&rsquo;t <em>easy</em> but I&rsquo;m a lot better at it now.</li>
<li>you can write a shell script to <a href="https://jvns.ca/til/vim-osc52/">copy to your clipboard over SSH</a></li>
<li>how <code>reset</code> works under the hood (it does the equivalent of <code>stty sane; sleep 1; tput reset</code>) ‚Äì basically I learned that I don&rsquo;t ever need to worry about
remembering <code>stty sane</code> or <code>tput reset</code> and I can just run <code>reset</code> instead</li>
<li>how to look at the invisible escape codes that a program is printing out (run <code>unbuffer program &gt; out; less out</code>)</li>
<li>why the builtin REPLs on my Mac like <code>sqlite3</code> are so annoying to use (they use <code>libedit</code> instead of <code>readline</code>)</li>
</ul>
<h3 id="blog-posts-i-wrote-along-the-way">blog posts I wrote along the way</h3>
<p>As usual these days I wrote a bunch of blog posts about various side quests:</p>
<ul>
<li><a href="https://jvns.ca/blog/2025/02/13/how-to-add-a-directory-to-your-path/">How to add a directory to your PATH</a></li>
<li><a href="https://jvns.ca/blog/2024/11/26/terminal-rules/">&ldquo;rules&rdquo; that terminal problems follow</a></li>
<li><a href="https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/">why pipes sometimes get &ldquo;stuck&rdquo;: buffering</a></li>
<li><a href="https://jvns.ca/blog/2025/02/05/some-terminal-frustrations/">some terminal frustrations</a></li>
<li><a href="https://jvns.ca/blog/2024/10/31/ascii-control-characters/">ASCII control characters in my terminal</a> on &ldquo;what&rsquo;s the deal with Ctrl+A, Ctrl+B, Ctrl+C, etc?&rdquo;</li>
<li><a href="https://jvns.ca/blog/2024/07/08/readline/">entering text in the terminal is complicated</a></li>
<li><a href="https://jvns.ca/blog/2025/01/11/getting-a-modern-terminal-setup/">what&rsquo;s involved in getting a &ldquo;modern&rdquo; terminal setup?</a></li>
<li><a href="https://jvns.ca/blog/2024/07/03/reasons-to-use-job-control/">reasons to use your shell&rsquo;s job control</a></li>
<li><a href="https://jvns.ca/blog/2025/03/07/escape-code-standards/">standards for ANSI escape codes</a>, which is really me trying to figure out if I think the <code>terminfo</code> database is serving us well today</li>
</ul>
<h3 id="people-who-helped-with-this-zine">people who helped with this zine</h3>
<p>A long time ago I used to write zines mostly by myself but with every project I get more
and more help. I met with <a href="https://marieflanagan.com">Marie Claire LeBlanc Flanagan</a> every weekday from September to June to work
on this one.</p>
<p>The cover is by Vladimir Ka≈°ikoviƒá,
Lesley Trites did copy editing,
Simon Tatham (who wrote <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/">PuTTY</a>) did technical review, our
Operations Manager Lee did the transcription as well as a million other
things, and <a href="https://github.com/doy">Jesse Luehrs</a> (who is one of the very few
people I know who actually understands the terminal&rsquo;s cursed inner workings)
had so many incredibly helpful conversations with me about what is going on in
the terminal.</p>
<h3 id="get-the-zine">get the zine</h3>
<p>Here are some links to get the zine again:</p>
<ul>
<li>get <a href="https://wizardzines.com/zines/terminal">The Secret Rules of the Terminal</a></li>
<li>get a <a href="https://wizardzines.com/zines/all-the-zines/">15-pack of all my zines here</a>.</li>
</ul>
<p>As always, you can get either a PDF version to print at home or a print version
shipped to your house. The only caveat is print orders will ship in <strong>August</strong> &ndash; I
need to wait for orders to come in to get an idea of how many I should print
before sending it to the printer.</p>

---

### [Using `make` to compile C programs (for non-C-programmers)](https://jvns.ca/blog/2025/06/10/how-to-compile-a-c-program/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>I have never been a C programmer but every so often I need to compile a C/C++
program from source. This has been kind of a struggle for me: for a
long time, my approach was basically &ldquo;install the dependencies, run <code>make</code>, if
it doesn&rsquo;t work, either try to find a binary someone has compiled or give up&rdquo;.</p>
<p>&ldquo;Hope someone else has compiled it&rdquo; worked pretty well when I was running Linux
but since I&rsquo;ve been using a Mac for the last couple of years I&rsquo;ve been running
into more situations where I have to actually compile programs myself.</p>
<p>So let&rsquo;s talk about what you might have to do to compile a C program! I&rsquo;ll use
a couple of examples of specific C programs I&rsquo;ve compiled and talk about a few
things that can go wrong. Here are three programs we&rsquo;ll be talking about
compiling:</p>
<ul>
<li><a href="https://mj.ucw.cz/sw/paperjam/">paperjam</a></li>
<li><a href="https://www.sqlite.org/download.html">sqlite</a></li>
<li><a href="https://git.causal.agency/src/tree/bin/qf.c">qf</a> (a pager you can run to quickly open files from a search with <code>rg -n THING | qf</code>)</li>
</ul>
<h3 id="step-1-install-a-c-compiler">step 1: install a C compiler</h3>
<p>This is pretty simple: on an Ubuntu system if I don&rsquo;t already have a C compiler I&rsquo;ll install one with:</p>
<pre><code>sudo apt-get install build-essential
</code></pre>
<p>This installs <code>gcc</code>, <code>g++</code>, and <code>make</code>. The situation on a Mac is more
confusing but it&rsquo;s something like &ldquo;install xcode command line tools&rdquo;.</p>
<h3 id="step-2-install-the-program-s-dependencies">step 2: install the program&rsquo;s dependencies</h3>
<p>Unlike some newer programming languages, C doesn&rsquo;t have a dependency manager.
So if a program has any dependencies, you need to hunt them down yourself.
Thankfully because of this, C programmers usually keep their dependencies very
minimal and often the dependencies will be available in whatever package manager you&rsquo;re using.</p>
<p>There&rsquo;s almost always a section explaining how to get the dependencies in the
README, for example in <a href="https://mj.ucw.cz/sw/paperjam/">paperjam</a>&rsquo;s README, it
says:</p>
<blockquote>
<p>To compile PaperJam, you need the headers for the libqpdf and libpaper libraries (usually available as libqpdf-dev and libpaper-dev packages).</p>
</blockquote>
<blockquote>
<p>You may need <code>a2x</code> (found in <a href="http://www.methods.co.nz/asciidoc/a2x.1.html">AsciiDoc</a>) for building manual pages.</p>
</blockquote>
<p>So on a Debian-based system you can install the dependencies like this.</p>
<pre><code>sudo apt install -y libqpdf-dev libpaper-dev
</code></pre>
<p>If a README gives a name for a package (like <code>libqpdf-dev</code>), I&rsquo;d basically
always assume that they mean &ldquo;in a Debian-based Linux distro&rdquo;: if you&rsquo;re on a
Mac <code>brew install libqpdf-dev</code> will not work. I still have not 100% gotten
the hang of developing on a Mac yet so I don&rsquo;t have many tips there yet. I
guess in this case it would be <code>brew install qpdf</code> if you&rsquo;re using Homebrew.</p>
<h3 id="step-3-run-configure-if-needed">step 3: run <code>./configure</code> (if needed)</h3>
<p>Some C programs come with a <code>Makefile</code> and some instead come with a script called
<code>./configure</code>. For example, if you download <a href="https://www.sqlite.org/download.html">sqlite&rsquo;s source code</a>, it has a <code>./configure</code> script in
it instead of a Makefile.</p>
<p>My understanding of this <code>./configure</code> script is:</p>
<ol>
<li>You run it, it prints out a lot of somewhat inscrutable output, and then it
either generates a <code>Makefile</code> or fails because you&rsquo;re missing some
dependency</li>
<li>The <code>./configure</code> script is part of a system called
<a href="https://www.gnu.org/software/automake/manual/html_node/Autotools-Introduction.html">autotools</a>
that I have never needed to learn anything about beyond &ldquo;run it to generate
a <code>Makefile</code>&rdquo;.</li>
</ol>
<p>I think there might be some options you can pass to get the <code>./configure</code>
script to produce a different <code>Makefile</code> but I have never done that.</p>
<h3 id="step-4-run-make">step 4: run <code>make</code></h3>
<p>The next step is to run <code>make</code> to try to build a program. Some notes about
<code>make</code>:</p>
<ul>
<li>Sometimes you can run <code>make -j8</code> to parallelize the build and make it go
faster</li>
<li>It usually prints out a million compiler warnings when compiling the program.
I always just ignore them. I didn&rsquo;t write the software! The compiler warnings
are not my problem.</li>
</ul>
<h3 id="compiler-errors-are-often-dependency-problems">compiler errors are often dependency problems</h3>
<p>Here&rsquo;s an error I got while compiling <code>paperjam</code> on my Mac:</p>
<pre><code>/opt/homebrew/Cellar/qpdf/12.0.0/include/qpdf/InputSource.hh:85:19: error: function definition does not declare parameters
   85 |     qpdf_offset_t last_offset{0};
      |                   ^
</code></pre>
<p>Over the years I&rsquo;ve learned it&rsquo;s usually best not to overthink problems like
this: if it&rsquo;s talking about <code>qpdf</code>, there&rsquo;s a good change it just means that
I&rsquo;ve done something wrong with how I&rsquo;m including the <code>qpdf</code> dependency.</p>
<p>Now let&rsquo;s talk about some ways to get the <code>qpdf</code> dependency included in the right way.</p>
<h3 id="the-world-s-shortest-introduction-to-the-compiler-and-linker">the world&rsquo;s shortest introduction to the compiler and linker</h3>
<p>Before we talk about how to fix dependency problems: building C programs is split into 2
steps:</p>
<ol>
<li><strong>Compiling</strong> the code into <strong>object files</strong> (with <code>gcc</code> or <code>clang</code>)</li>
<li><strong>Linking</strong> those object files into a final binary (with <code>ld</code>)</li>
</ol>
<p>It&rsquo;s important to know this when building a C program because sometimes you
need to pass the right flags to the compiler and linker to tell them where to
find the dependencies for the program you&rsquo;re compiling.</p>
<h3 id="make-uses-environment-variables-to-configure-the-compiler-and-linker"><code>make</code> uses environment variables to configure the compiler and linker</h3>
<p>If I run <code>make</code> on my Mac to install <code>paperjam</code>, I get this error:</p>
<pre><code>c++ -o paperjam paperjam.o pdf-tools.o parse.o cmds.o pdf.o -lqpdf -lpaper
ld: library 'qpdf' not found
</code></pre>
<p>This is not because <code>qpdf</code> is not installed on my system (it actually is!). But
the compiler and linker don&rsquo;t know how to <em>find</em> the <code>qpdf</code> library. To fix this, we need to:</p>
<ul>
<li>pass <code>&quot;-I/opt/homebrew/include&quot;</code> to the compiler (to tell it where to find the header files)</li>
<li>pass <code>&quot;-L/opt/homebrew/lib -liconv&quot;</code> to the linker (to tell it where to find library files and to link in <code>iconv</code>)</li>
</ul>
<p>And we can get <code>make</code> to pass those extra parameters to the compiler and linker using environment variables!
To see how this works: inside <code>paperjam</code>&rsquo;s Makefile you can see a bunch of environment variables, like <code>LDLIBS</code> here:</p>
<pre><code>paperjam: $(OBJS)
	$(LD) -o $@ $^ $(LDLIBS)
</code></pre>
<p>Everything you put into the <code>LDLIBS</code> environment variable gets passed to the
linker (<code>ld</code>) as a command line argument.</p>
<h3 id="secret-environment-variable-cppflags">secret environment variable: <code>CPPFLAGS</code></h3>
<p><code>Makefiles</code> sometimes define their own environment variables that they pass to
the compiler/linker, but <code>make</code> also has a bunch of &ldquo;implicit&rdquo; environment
variables which it will automatically pass to the C compiler and linker. There&rsquo;s a <a href="https://www.gnu.org/software/make/manual/html_node/Implicit-Variables.html#index-CFLAGS0">full list of implicit environment variables here</a>,
but one of them is <code>CPPFLAGS</code>, which gets automatically passed to the C compiler.</p>
<p>(technically it would be more normal to use <code>CXXFLAGS</code> for this, but this
particular <code>Makefile</code> hardcodes <code>CXXFLAGS</code> so setting <code>CPPFLAGS</code> was the only
way I could find to set the compiler flags without editing the <code>Makefile</code>)</p>
<small>
As an aside: it took me a long time to realize how closely tied to C/C++ `make` is -- I used
to think that `make` was just a general build system (and of course you can use it for
anything!) but it has a lot of affordances for building C/C++ programs that it
doesn't have for building any other kind of program.
</small>
<h3 id="two-ways-to-pass-environment-variables-to-make">two ways to pass environment variables to <code>make</code></h3>
<p>I learned thanks to <a href="https://www.owlfolio.org/">@zwol</a> that there are actually two ways to pass environment variables to <code>make</code>:</p>
<ol>
<li><code>CXXFLAGS=xyz make</code> (the usual way)</li>
<li><code>make CXXFLAGS=xyz</code></li>
</ol>
<p>The difference between them is that <code>make CXXFLAGS=xyz</code> will override the
value of <code>CXXFLAGS</code> set in the <code>Makefile</code> but <code>CXXFLAGS=xyz make</code> won&rsquo;t.</p>
<p>I&rsquo;m not sure which way is the norm but I&rsquo;m going to use the first way in this
post.</p>
<h3 id="how-to-use-cppflags-and-ldlibs-to-fix-this-compiler-error">how to use <code>CPPFLAGS</code> and <code>LDLIBS</code> to fix this compiler error</h3>
<p>Now that we&rsquo;ve talked about how <code>CPPFLAGS</code> and <code>LDLIBS</code> get passed to the
compiler and linker, here&rsquo;s the final incantation that I used to get the
program to build successfully!</p>
<pre><code>CPPFLAGS=&quot;-I/opt/homebrew/include&quot; LDLIBS=&quot;-L/opt/homebrew/lib -liconv&quot; make paperjam
</code></pre>
<p>This passes <code>-I/opt/homebrew/include</code> to the compiler and <code>-L/opt/homebrew/lib -liconv</code> to the linker.</p>
<p>Also I don&rsquo;t want to pretend that I &ldquo;magically&rdquo; knew that those were the right
arguments to pass, figuring them out involved a bunch of confused Googling that I
skipped over in this post. I will say that:</p>
<ul>
<li>the <code>-I</code> compiler flag tells the compiler which directory to find header files in, like <code>/opt/homebrew/include/qpdf/QPDF.hh</code></li>
<li>the <code>-L</code> linker flag tells the linker which directory to find libraries in, like <code>/opt/homebrew/lib/libqpdf.a</code></li>
<li>the <code>-l</code> linker flag tells the linker which libraries to link in, like <code>-liconv</code> means &ldquo;link in the <code>iconv</code> library&rdquo;, or <code>-lm</code> means &ldquo;link <code>math</code>&rdquo;</li>
</ul>
<h3 id="tip-how-to-just-build-1-specific-file-make-filename">tip: how to just build 1 specific file: <code>make $FILENAME</code></h3>
<p>Yesterday I discovered this cool tool called
<a href="https://git.causal.agency/src/tree/bin/qf.c">qf</a> which you can use to quickly
open files from the output of <code>ripgrep</code>.</p>
<p><code>qf</code> is in a big directory of various tools, but I only wanted to compile <code>qf</code>.
So I just compiled <code>qf</code>, like this:</p>
<pre><code>make qf
</code></pre>
<p>Basically if you know (or can guess) the output filename of the file you&rsquo;re
trying to build, you can tell <code>make</code> to just build that file by running <code>make $FILENAME</code></p>
<h3 id="tip-you-don-t-need-a-makefile">tip: you don&rsquo;t need a Makefile</h3>
<p>I sometimes write 5-line C programs with no dependencies, and I just learned
that if I have a file called <code>blah.c</code>, I can just compile it like this without creating a <code>Makefile</code>:</p>
<pre><code>make blah
</code></pre>
<p>It gets automaticaly expanded to <code>cc -o blah blah.c</code>, which saves a bit of
typing. I have no idea if I&rsquo;m going to remember this (I might just keep typing
<code>gcc -o blah blah.c</code> anyway) but it seems like a fun trick.</p>
<h3 id="tip-look-at-how-other-packaging-systems-built-the-same-c-program">tip: look at how other packaging systems built the same C program</h3>
<p>If you&rsquo;re having trouble building a C program, maybe other people had problems building it
too! Every Linux distribution has build files for every package that they
build, so even if you can&rsquo;t install packages from that distribution directly,
maybe you can get tips from that Linux distro for how to build the package.
Realizing this (thanks to my friend Dave) was a huge ah-ha moment for me.</p>
<p>For example, <a href="https://github.com/NixOS/nixpkgs/blob/405624e81a9b65378328accb0a11c3e5369e651c/pkgs/by-name/pa/paperjam/package.nix#L35">this line from the nix package for <code>paperjam</code></a> says:</p>
<pre><code>  env.NIX_LDFLAGS = lib.optionalString stdenv.hostPlatform.isDarwin &quot;-liconv&quot;;
</code></pre>
<p>This is basically saying &ldquo;pass the linker flag <code>-liconv</code> to build this on a
Mac&rdquo;, so that&rsquo;s a clue we could use to build it.</p>
<p>That same file also says <code>  env.NIX_CFLAGS_COMPILE = &quot;-DPOINTERHOLDER_TRANSITION=1&quot;;</code>. I&rsquo;m not sure what this means, but when I try
to build the <code>paperjam</code> package I do get an error about something called a
<code>PointerHolder</code>, so I guess that&rsquo;s somehow related to the &ldquo;PointerHolder
transition&rdquo;.</p>
<h3 id="step-5-installing-the-binary">step 5: installing the binary</h3>
<p>Once you&rsquo;ve managed to compile the program, probably you want to install it somewhere!
Some <code>Makefile</code>s have an <code>install</code> target that let you install the tool on your
system with <code>make install</code>. I&rsquo;m always a bit scared of this (where is it going
to put the files? what if I want to uninstall them later?), so if I&rsquo;m compiling
a pretty simple program I&rsquo;ll often just manually copy the binary to install it
instead, like this:</p>
<pre><code>cp qf ~/bin
</code></pre>
<h3 id="step-6-maybe-make-your-own-package">step 6: maybe make your own package!</h3>
<p>Once I figured out how to do all of this, I realized that I could use my new
<code>make</code> knowledge to contribute a <code>paperjam</code> package to Homebrew! Then I could
just <code>brew install paperjam</code> on future systems.</p>
<p>The good thing is that even if the details of how all of the different
packaging systems, they fundamentally all use C compilers and linkers.</p>
<h3 id="it-can-be-useful-to-understand-a-little-about-c-even-if-you-re-not-a-c-programmer">it can be useful to understand a little about C even if you&rsquo;re not a C programmer</h3>
<p>I think all of this is an interesting example of how it can useful to
understand some basics of how C programs work (like &ldquo;they have header files&rdquo;)
even if you&rsquo;re never planning to write a nontrivial C program if your life.</p>
<p>It feels good to have some ability to compile C/C++ programs myself, even
though I&rsquo;m still not totally confident about all of the compiler and linker
flags and I still plan to never learn anything about how autotools works other
than &ldquo;you run <code>./configure</code> to generate the <code>Makefile</code>&rdquo;.</p>
<p>Two things I left out of this post:</p>
<ul>
<li><code>LD_LIBRARY_PATH / DYLD_LIBRARY_PATH</code> (which you use to tell the dynamic
linker at runtime where to find dynamically linked files) because I can&rsquo;t
remember the last time I ran into an <code>LD_LIBRARY_PATH</code> issue and couldn&rsquo;t
find an example.</li>
<li><code>pkg-config</code>, which I think is important but I don&rsquo;t understand yet</li>
</ul>

---

### [Standards for ANSI escape codes](https://jvns.ca/blog/2025/03/07/escape-code-standards/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>Hello! Today I want to talk about ANSI escape codes.</p>
<p>For a long time I was vaguely aware of ANSI escape codes (&ldquo;that&rsquo;s how you make
text red in the terminal and stuff&rdquo;) but I had no real understanding of where they were
supposed to be defined or whether or not there were standards for them. I just
had a kind of vague &ldquo;there be dragons&rdquo; feeling around them. While learning
about the terminal this year, I&rsquo;ve learned that:</p>
<ol>
<li>ANSI escape codes are responsible for a lot of usability improvements
in the terminal (did you know there&rsquo;s a way to copy to your system clipboard
when SSHed into a remote machine?? It&rsquo;s an escape code called <a href="https://jvns.ca/til/vim-osc52/">OSC 52</a>!)</li>
<li>They aren&rsquo;t completely standardized, and because of that they don&rsquo;t always
work reliably. And because they&rsquo;re also invisible, it&rsquo;s extremely
frustrating to troubleshoot escape code issues.</li>
</ol>
<p>So I wanted to put together a list for myself of some standards that exist
around escape codes, because I want to know if they <em>have</em> to feel unreliable
and frustrating, or if there&rsquo;s a future where we could all rely on them with
more confidence.</p>
<ul>
<li><a href="https://jvns.ca/atom.xml#what-s-an-escape-code">what&rsquo;s an escape code?</a></li>
<li><a href="https://jvns.ca/atom.xml#ecma-48">ECMA-48</a></li>
<li><a href="https://jvns.ca/atom.xml#xterm-control-sequences">xterm control sequences</a></li>
<li><a href="https://jvns.ca/atom.xml#terminfo">terminfo</a></li>
<li><a href="https://jvns.ca/atom.xml#should-programs-use-terminfo">should programs use terminfo?</a></li>
<li><a href="https://jvns.ca/atom.xml#is-there-a-single-common-set-of-escape-codes">is there a &ldquo;single common set&rdquo; of escape codes?</a></li>
<li><a href="https://jvns.ca/atom.xml#some-reasons-to-use-terminfo">some reasons to use terminfo</a></li>
<li><a href="https://jvns.ca/atom.xml#some-more-documents-standards">some more documents/standards</a></li>
<li><a href="https://jvns.ca/atom.xml#why-i-think-this-is-interesting">why I think this is interesting</a></li>
</ul>
<h3 id="what-s-an-escape-code">what&rsquo;s an escape code?</h3>
<p>Have you ever pressed the left arrow key in your terminal and seen <code>^[[D</code>?
That&rsquo;s an escape code! It&rsquo;s called an &ldquo;escape code&rdquo; because the first character
is the &ldquo;escape&rdquo; character, which is usually written as <code>ESC</code>, <code>\x1b</code>, <code>\E</code>,
<code>\033</code>, or <code>^[</code>.</p>
<p>Escape codes are how your terminal emulator communicates various kinds of
information (colours, mouse movement, etc) with programs running in the
terminal. There are two kind of escape codes:</p>
<ol>
<li><strong>input codes</strong> which your terminal emulator sends for keypresses or mouse
movements that don&rsquo;t fit into Unicode. For example &ldquo;left arrow key&rdquo; is
<code>ESC[D</code>, &ldquo;Ctrl+left arrow&rdquo; might be <code>ESC[1;5D</code>, and clicking the mouse might
be something like <code>ESC[M :3</code>.</li>
<li><strong>output codes</strong> which programs can print out to colour text, move the
cursor around, clear the screen, hide the cursor, copy text to the
clipboard, enable mouse reporting, set the window title, etc.</li>
</ol>
<p>Now let&rsquo;s talk about standards!</p>
<h3 id="ecma-48">ECMA-48</h3>
<p>The first standard I found relating to escape codes was
<a href="https://ecma-international.org/wp-content/uploads/ECMA-48_5th_edition_june_1991.pdf">ECMA-48</a>,
which was originally published in 1976.</p>
<p>ECMA-48 does two things:</p>
<ol>
<li>Define some general <em>formats</em> for escape codes (like &ldquo;CSI&rdquo; codes, which are
<code>ESC[</code> + something and &ldquo;OSC&rdquo; codes, which are <code>ESC]</code> + something)</li>
<li>Define some specific escape codes, like how &ldquo;move the cursor to the left&rdquo; is
<code>ESC[D</code>, or &ldquo;turn text red&rdquo; is  <code>ESC[31m</code>. In the spec, the &ldquo;cursor left&rdquo;
one is called <code>CURSOR LEFT</code> and the one for changing colours is called
<code>SELECT GRAPHIC RENDITION</code>.</li>
</ol>
<p>The formats are extensible, so there&rsquo;s room for others to define more escape
codes in the future. Lots of escape codes that are popular today aren&rsquo;t defined
in ECMA-48: for example it&rsquo;s pretty common for terminal applications (like vim,
htop, or tmux) to support using the mouse, but ECMA-48 doesn&rsquo;t define escape
codes for the mouse.</p>
<h3 id="xterm-control-sequences">xterm control sequences</h3>
<p>There are a bunch of escape codes that aren&rsquo;t defined in ECMA-48, for example:</p>
<ul>
<li>enabling mouse reporting (where did you click in your terminal?)</li>
<li>bracketed paste (did you paste that text or type it in?)</li>
<li>OSC 52 (which terminal applications can use to copy text to your system clipboard)</li>
</ul>
<p>I believe (correct me if I&rsquo;m wrong!) that these and some others came from
xterm, are documented in <a href="https://invisible-island.net/xterm/ctlseqs/ctlseqs.html">XTerm Control Sequences</a>, and have
been widely implemented by other terminal emulators.</p>
<p>This list of &ldquo;what xterm supports&rdquo; is not a standard exactly, but xterm is
extremely influential and so it seems like an important document.</p>
<h3 id="terminfo">terminfo</h3>
<p>In the 80s (and to some extent today, but my understanding is that it was MUCH
more dramatic in the 80s) there was a huge amount of variation in what escape
codes terminals actually supported.</p>
<p>To deal with this, there&rsquo;s a database of escape codes for various terminals
called &ldquo;terminfo&rdquo;.</p>
<p>It looks like the standard for terminfo is called <a href="https://publications.opengroup.org/c243-1">X/Open Curses</a>, though you need to create
an account to view that standard for some reason. It defines the database format as well
as a C library interface (&ldquo;curses&rdquo;) for accessing the database.</p>
<p>For example you can run this bash snippet to see every possible escape code for
&ldquo;clear screen&rdquo; for all of the different terminals your system knows about:</p>
<pre><code>for term in $(toe -a | awk '{print $1}')
do
  echo $term
  infocmp -1 -T &quot;$term&quot; 2&gt;/dev/null | grep 'clear=' | sed 's/clear=//g;s/,//g'
done
</code></pre>
<p>On my system (and probably every system I&rsquo;ve ever used?), the terminfo database is managed by ncurses.</p>
<h3 id="should-programs-use-terminfo">should programs use terminfo?</h3>
<p>I think it&rsquo;s interesting that there are two main approaches that applications
take to handling ANSI escape codes:</p>
<ol>
<li>Use the terminfo database to figure out which escape codes to use, depending
on what&rsquo;s in the <code>TERM</code> environment variable. Fish does this, for example.</li>
<li>Identify a &ldquo;single common set&rdquo; of escape codes which works in &ldquo;enough&rdquo;
terminal emulators and just hardcode those.</li>
</ol>
<p>Some examples of programs/libraries that take approach #2 (&ldquo;don&rsquo;t use terminfo&rdquo;) include:</p>
<ul>
<li><a href="https://github.com/mawww/kakoune/commit/c12699d2e9c2806d6ed184032078d0b84a3370bb">kakoune</a></li>
<li><a href="https://github.com/prompt-toolkit/python-prompt-toolkit/blob/165258d2f3ae594b50f16c7b50ffb06627476269/src/prompt_toolkit/input/ansi_escape_sequences.py#L5-L8">python-prompt-toolkit</a></li>
<li><a href="https://github.com/antirez/linenoise">linenoise</a></li>
<li><a href="https://github.com/rockorager/libvaxis">libvaxis</a></li>
<li><a href="https://github.com/chalk/chalk">chalk</a></li>
</ul>
<p>I got curious about why folks might be moving away from terminfo and I found
this very interesting and extremely detailed
<a href="https://twoot.site/@bean/113056942625234032">rant about terminfo from one of the fish maintainers</a>, which argues that:</p>
<blockquote>
<p>[the terminfo authors] have done a lot of work that, at the time, was
extremely important and helpful. My point is that it no longer is.</p>
</blockquote>
<p>I&rsquo;m not going to do it justice so I&rsquo;m not going to summarize it, I think it&rsquo;s
worth reading.</p>
<h3 id="is-there-a-single-common-set-of-escape-codes">is there a &ldquo;single common set&rdquo; of escape codes?</h3>
<p>I was just talking about the idea that you can use a &ldquo;common set&rdquo; of escape
codes that will work for most people. But what is that set? Is there any agreement?</p>
<p>I really do not know the answer to this at all, but from doing some reading it
seems like it&rsquo;s some combination of:</p>
<ul>
<li>The codes that the VT100 supported (though some aren&rsquo;t relevant on modern terminals)</li>
<li>what&rsquo;s in ECMA-48 (which I think also has some things that are no longer relevant)</li>
<li>What xterm supports (though I&rsquo;d guess that not everything in there is actually widely supported enough)</li>
</ul>
<p>and maybe ultimately &ldquo;identify the terminal emulators you think your users are
going to use most frequently and test in those&rdquo;, the same way web developers do
when deciding which CSS features are okay to use</p>
<p>I don&rsquo;t think there are any resources like <a href="https://caniuse.com/">Can I use&hellip;?</a> or
<a href="https://web-platform-dx.github.io/web-features/">Baseline</a> for the terminal
though. (in theory terminfo is supposed to be the &ldquo;caniuse&rdquo; for the terminal
but it seems like it often takes 10+ years to add new terminal features when
people invent them which makes it very limited)</p>
<h3 id="some-reasons-to-use-terminfo">some reasons to use terminfo</h3>
<p>I also asked on Mastodon why people found terminfo valuable in 2025 and got a
few reasons that made sense to me:</p>
<ul>
<li>some people expect to be able to use the <code>TERM</code> environment variable to
control how programs behave (for example with <code>TERM=dumb</code>), and there&rsquo;s
no standard for how that should work in a post-terminfo world</li>
<li>even though there&rsquo;s <em>less</em> variation between terminal emulators than
there was in the 80s, there&rsquo;s far from zero variation: there are graphical
terminals, the Linux framebuffer console, the situation you&rsquo;re in when
connecting to a server via its serial console, Emacs shell mode, and probably
more that I&rsquo;m missing</li>
<li>there is no one standard for what the &ldquo;single common set&rdquo; of escape codes
is, and sometimes programs use escape codes which aren&rsquo;t actually widely
supported enough</li>
</ul>
<h3 id="terminfo-user-agent-detection">terminfo &amp; user agent detection</h3>
<p>The way that ncurses uses the <code>TERM</code> environment variable to decide which
escape codes to use reminds me of how webservers used to sometimes use the
browser user agent to decide which version of a website to serve.</p>
<p>It also seems like it&rsquo;s had some of the same results &ndash; the way iTerm2 reports
itself as being &ldquo;xterm-256color&rdquo; feels similar to how Safari&rsquo;s user agent is
&ldquo;Mozilla/5.0 (Macintosh; Intel Mac OS X 14_7_4) AppleWebKit/605.1.15 (KHTML,
like Gecko) Version/18.3 Safari/605.1.15&rdquo;. In both cases the terminal emulator
/ browser ends up changing its user agent to get around user agent detection
that isn&rsquo;t working well.</p>
<p>On the web we ended up deciding that user agent detection was not a good
practice and to instead focus on standardization so we can serve the same
HTML/CSS to all browsers. I don&rsquo;t know if the same approach is the future in
the terminal though &ndash; I think the terminal landscape today is much more
fragmented than the web ever was as well as being much less well funded.</p>
<h3 id="some-more-documents-standards">some more documents/standards</h3>
<p>A few more documents and standards related to escape codes, in no particular order:</p>
<ul>
<li>the <a href="https://man7.org/linux/man-pages/man4/console_codes.4.html">Linux console_codes man page</a> documents
escape codes that Linux supports</li>
<li>how the <a href="https://vt100.net/docs/vt100-ug/chapter3.html">VT 100</a> handles escape codes &amp; control sequences</li>
<li>the <a href="https://sw.kovidgoyal.net/kitty/keyboard-protocol/">kitty keyboard protocol</a></li>
<li><a href="https://gist.github.com/egmontkob/eb114294efbcd5adb1944c9f3cb5feda">OSC 8</a> for links in the terminal (and notes on <a href="https://github.com/Alhadis/OSC8-Adoption?tab=readme-ov-file">adoption</a>)</li>
<li>A <a href="https://github.com/tmux/tmux/blob/882fb4d295deb3e4b803eb444915763305114e4f/tools/ansicode.txt">summary of ANSI standards from tmux</a></li>
<li>this <a href="https://iterm2.com/feature-reporting/">terminal features reporting specification from iTerm</a></li>
<li>sixel graphics</li>
</ul>
<h3 id="why-i-think-this-is-interesting">why I think this is interesting</h3>
<p>I sometimes see people saying that the unix terminal is &ldquo;outdated&rdquo;, and since I
love the terminal so much I&rsquo;m always curious about what incremental changes
might make it feel less &ldquo;outdated&rdquo;.</p>
<p>Maybe if we had a clearer standards landscape (like we do on the web!) it would
be easier for terminal emulator developers to build new features and for
authors of terminal applications to more confidently adopt those features so
that we can all benefit from them and have a richer experience in the terminal.</p>
<p>Obviously standardizing ANSI escape codes is not easy (ECMA-48 was first
published almost 50 years ago and we&rsquo;re still not there!). I don&rsquo;t even know
what all of the challenges are. But the situation with HTML/CSS/JS used to be
extremely bad too and now it&rsquo;s MUCH better, so maybe there&rsquo;s hope.</p>

---

### [How to add a directory to your PATH](https://jvns.ca/blog/2025/02/13/how-to-add-a-directory-to-your-path/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>I was talking to a friend about how to add a directory to your PATH today. It&rsquo;s
something that feels &ldquo;obvious&rdquo; to me since I&rsquo;ve been using the terminal for a
long time, but when I searched for instructions for how to do it, I actually
couldn&rsquo;t find something that explained all of the steps &ndash; a lot of them just
said &ldquo;add this to <code>~/.bashrc</code>&rdquo;, but what if you&rsquo;re not using bash? What if your
bash config is actually in a different file? And how are you supposed to figure
out which directory to add anyway?</p>
<p>So I wanted to try to write down some more complete directions and mention some
of the gotchas I&rsquo;ve run into over the years.</p>
<p>Here&rsquo;s a table of contents:</p>
<ul>
<li><a href="https://jvns.ca/atom.xml#step-1-what-shell-are-you-using">step 1: what shell are you using?</a></li>
<li><a href="https://jvns.ca/atom.xml#step-2-find-your-shell-s-config-file">step 2: find your shell&rsquo;s config file</a>
<ul>
<li><a href="https://jvns.ca/atom.xml#a-note-on-bash-s-config-file">a note on bash&rsquo;s config file</a></li>
</ul>
</li>
<li><a href="https://jvns.ca/atom.xml#step-3-figure-out-which-directory-to-add">step 3: figure out which directory to add</a>
<ul>
<li><a href="https://jvns.ca/atom.xml#step-3-1-double-check-it-s-the-right-directory">step 3.1: double check it&rsquo;s the right directory</a></li>
</ul>
</li>
<li><a href="https://jvns.ca/atom.xml#step-4-edit-your-shell-config">step 4: edit your shell config</a></li>
<li><a href="https://jvns.ca/atom.xml#step-5-restart-your-shell">step 5: restart your shell</a></li>
<li>problems:
<ul>
<li><a href="https://jvns.ca/atom.xml#problem-1-it-ran-the-wrong-program">problem 1: it ran the wrong program</a></li>
<li><a href="https://jvns.ca/atom.xml#problem-2-the-program-isn-t-being-run-from-your-shell">problem 2: the program isn&rsquo;t being run from your shell</a></li>
<li><a href="https://jvns.ca/atom.xml#problem-3-duplicate-path-entries-making-it-harder-to-debug">problem 3: duplicate PATH entries making it harder to debug</a></li>
<li><a href="https://jvns.ca/atom.xml#problem-4-losing-your-history-after-updating-your-path">problem 4: losing your history after updating your PATH</a></li>
</ul>
</li>
<li>notes:
<ul>
<li><a href="https://jvns.ca/atom.xml#a-note-on-source">a note on source</a></li>
<li><a href="https://jvns.ca/atom.xml#a-note-on-fish-add-path">a note on fish_add_path</a></li>
</ul>
</li>
</ul>
<h3 id="step-1-what-shell-are-you-using">step 1: what shell are you using?</h3>
<p>If you&rsquo;re not sure what shell you&rsquo;re using, here&rsquo;s a way to find out. Run this:</p>
<pre><code>ps -p $$ -o pid,comm=
</code></pre>
<ul>
<li>if you&rsquo;re using <strong>bash</strong>, it&rsquo;ll print out <code>97295 bash</code></li>
<li>if you&rsquo;re using <strong>zsh</strong>, it&rsquo;ll print out <code>97295 zsh</code></li>
<li>if you&rsquo;re using <strong>fish</strong>, it&rsquo;ll print out an error like &ldquo;In fish, please use
$fish_pid&rdquo; (<code>$$</code> isn&rsquo;t valid syntax in fish, but in any case the error
message tells you that you&rsquo;re using fish, which you probably already knew)</li>
</ul>
<p>Also bash is the default on Linux and zsh is the default on Mac OS (as of
2024). I&rsquo;ll only cover bash, zsh, and fish in these directions.</p>
<h3 id="step-2-find-your-shell-s-config-file">step 2: find your shell&rsquo;s config file</h3>
<ul>
<li>in zsh, it&rsquo;s probably <code>~/.zshrc</code></li>
<li>in bash, it might be <code>~/.bashrc</code>, but it&rsquo;s complicated, see the note in the next section</li>
<li>in fish, it&rsquo;s probably <code>~/.config/fish/config.fish</code> (you can run <code>echo $__fish_config_dir</code> if you want to be 100% sure)</li>
</ul>
<h3 id="a-note-on-bash-s-config-file">a note on bash&rsquo;s config file</h3>
<p>Bash has three possible config files: <code>~/.bashrc</code>, <code>~/.bash_profile</code>, and <code>~/.profile</code>.</p>
<p>If you&rsquo;re not sure which one your system is set up to use, I&rsquo;d recommend
testing this way:</p>
<ol>
<li>add <code>echo hi there</code> to your <code>~/.bashrc</code></li>
<li>Restart your terminal</li>
<li>If you see &ldquo;hi there&rdquo;, that means <code>~/.bashrc</code> is being used! Hooray!</li>
<li>Otherwise remove it and try the same thing with <code>~/.bash_profile</code></li>
<li>You can also try <code>~/.profile</code> if the first two options don&rsquo;t work.</li>
</ol>
<p>(there are a lot of <a href="https://blog.flowblok.id.au/2013-02/shell-startup-scripts.html">elaborate flow charts</a> out there that explain how bash
decides which config file to use but IMO it&rsquo;s not worth it to internalize them
and just testing is the fastest way to be sure)</p>
<h3 id="step-3-figure-out-which-directory-to-add">step 3: figure out which directory to add</h3>
<p>Let&rsquo;s say that you&rsquo;re trying to install and run a program called <code>http-server</code>
and it doesn&rsquo;t work, like this:</p>
<pre><code>$ npm install -g http-server
$ http-server
bash: http-server: command not found
</code></pre>
<p>How do you find what directory <code>http-server</code> is in? Honestly in general this is
not that easy &ndash; often the answer is something like &ldquo;it depends on how npm is
configured&rdquo;. A few ideas:</p>
<ul>
<li>Often when setting up a new installer (like <code>cargo</code>, <code>npm</code>, <code>homebrew</code>, etc),
when you first set it up it&rsquo;ll print out some directions about how to update
your PATH. So if you&rsquo;re paying attention you can get the directions then.</li>
<li>Sometimes installers will automatically update your shell&rsquo;s config file
to update your <code>PATH</code> for you</li>
<li>Sometimes just Googling &ldquo;where does npm install things?&rdquo; will turn up the
answer</li>
<li>Some tools have a subcommand that tells you where they&rsquo;re configured to
install things, like:
<ul>
<li>Node/npm: <code>npm config get prefix</code> (then append <code>/bin/</code>)</li>
<li>Go: <code>go env GOPATH</code> (then append <code>/bin/</code>)</li>
<li>asdf: <code>asdf info | grep ASDF_DIR</code> (then append <code>/bin/</code> and <code>/shims/</code>)</li>
</ul>
</li>
</ul>
<h3 id="step-3-1-double-check-it-s-the-right-directory">step 3.1: double check it&rsquo;s the right directory</h3>
<p>Once you&rsquo;ve found a directory you think might be the right one, make sure it&rsquo;s
actually correct! For example, I found out that on my machine, <code>http-server</code> is
in <code>~/.npm-global/bin</code>. I can make sure that it&rsquo;s the right directory by trying to
run the program <code>http-server</code> in that directory like this:</p>
<pre><code>$ ~/.npm-global/bin/http-server
Starting up http-server, serving ./public
</code></pre>
<p>It worked! Now that you know what directory you need to add to your <code>PATH</code>,
let&rsquo;s move to the next step!</p>
<h3 id="step-4-edit-your-shell-config">step 4: edit your shell config</h3>
<p>Now we have the 2 critical pieces of information we need:</p>
<ol>
<li>Which directory you&rsquo;re trying to add to your PATH (like  <code>~/.npm-global/bin/</code>)</li>
<li>Where your shell&rsquo;s config is (like <code>~/.bashrc</code>, <code>~/.zshrc</code>, or <code>~/.config/fish/config.fish</code>)</li>
</ol>
<p>Now what you need to add depends on your shell:</p>
<p><strong>bash instructions:</strong></p>
<p>Open your shell&rsquo;s config file, and add a line like this:</p>
<pre><code>export PATH=$PATH:~/.npm-global/bin/
</code></pre>
<p>(obviously replace <code>~/.npm-global/bin</code> with the actual directory you&rsquo;re trying to add)</p>
<p><strong>zsh instructions:</strong></p>
<p>You can do the same thing as in bash, but zsh also has some slightly fancier
syntax you can use if you prefer:</p>
<pre><code>path=(
  $path
  ~/.npm-global/bin
)
</code></pre>
<p><strong>fish instructions:</strong></p>
<p>In fish, the syntax is different:</p>
<pre><code>set PATH $PATH ~/.npm-global/bin
</code></pre>
<p>(in fish you can also use <code>fish_add_path</code>, some notes on that <a href="https://jvns.ca/atom.xml#a-note-on-fish-add-path">further down</a>)</p>
<h3 id="step-5-restart-your-shell">step 5: restart your shell</h3>
<p>Now, an extremely important step: updating your shell&rsquo;s config won&rsquo;t take
effect if you don&rsquo;t restart it!</p>
<p>Two ways to do this:</p>
<ol>
<li>open a new terminal (or terminal tab), and maybe close the old one so you don&rsquo;t get confused</li>
<li>Run <code>bash</code> to start a new shell (or <code>zsh</code> if you&rsquo;re using zsh, or <code>fish</code> if you&rsquo;re using fish)</li>
</ol>
<p>I&rsquo;ve found that both of these usually work fine.</p>
<p>And you should be done! Try running the program you were trying to run and
hopefully it works now.</p>
<p>If not, here are a couple of problems that you might run into:</p>
<h3 id="problem-1-it-ran-the-wrong-program">problem 1: it ran the wrong program</h3>
<p>If the wrong <strong>version</strong> of a program is running, you might need to add the
directory to the <em>beginning</em> of your PATH instead of the end.</p>
<p>For example, on my system I have two versions of <code>python3</code> installed, which I
can see by running <code>which -a</code>:</p>
<pre><code>$ which -a python3
/usr/bin/python3
/opt/homebrew/bin/python3
</code></pre>
<p>The one your shell will use is the <strong>first one listed</strong>.</p>
<p>If you want to use the Homebrew version, you need to add that directory
(<code>/opt/homebrew/bin</code>) to the <strong>beginning</strong> of your PATH instead, by putting this in
your shell&rsquo;s config file (it&rsquo;s <code>/opt/homebrew/bin/:$PATH</code> instead of the usual <code>$PATH:/opt/homebrew/bin/</code>)</p>
<pre><code>export PATH=/opt/homebrew/bin/:$PATH
</code></pre>
<p>or in fish:</p>
<pre><code>set PATH ~/.cargo/bin $PATH
</code></pre>
<h3 id="problem-2-the-program-isn-t-being-run-from-your-shell">problem 2: the program isn&rsquo;t being run from your shell</h3>
<p>All of these directions only work if you&rsquo;re running the program <strong>from your
shell</strong>. If you&rsquo;re running the program from an IDE, from a GUI, in a cron job,
or some other way, you&rsquo;ll need to add the directory to your PATH in a different
way, and the exact details might depend on the situation.</p>
<p><strong>in a cron job</strong></p>
<p>Some options:</p>
<ul>
<li>use the full path to the program you&rsquo;re running, like <code>/home/bork/bin/my-program</code></li>
<li>put the full PATH you want as the first line of your crontab (something like
PATH=/bin:/usr/bin:/usr/local/bin:&hellip;.). You can get the full PATH you&rsquo;re
using in your shell by running <code>echo &quot;PATH=$PATH&quot;</code>.</li>
</ul>
<p>I&rsquo;m honestly not sure how to handle it in an IDE/GUI because I haven&rsquo;t run into
that in a long time, will add directions here if someone points me in the right
direction.</p>
<h3 id="problem-3-duplicate-path-entries-making-it-harder-to-debug">problem 3: duplicate <code>PATH</code> entries making it harder to debug</h3>
<p>If you edit your path and start a new shell by running <code>bash</code> (or <code>zsh</code>, or
<code>fish</code>), you&rsquo;ll often end up with duplicate <code>PATH</code> entries, because the shell
keeps adding new things to your <code>PATH</code> every time you start your shell.</p>
<p>Personally I don&rsquo;t think I&rsquo;ve run into a situation where this kind of
duplication breaks anything, but the duplicates can make it harder to debug
what&rsquo;s going on with your <code>PATH</code> if you&rsquo;re trying to understand its contents.</p>
<p>Some ways you could deal with this:</p>
<ol>
<li>If you&rsquo;re debugging your <code>PATH</code>, open a new terminal to do it in so you get
a &ldquo;fresh&rdquo; state. This should avoid the duplication.</li>
<li>Deduplicate your <code>PATH</code> at the end of your shell&rsquo;s config  (for example in
zsh apparently you can do this with <code>typeset -U path</code>)</li>
<li>Check that the directory isn&rsquo;t already in your <code>PATH</code> when adding it (for
example in fish I believe you can do this with <code>fish_add_path --path /some/directory</code>)</li>
</ol>
<p>How to deduplicate your <code>PATH</code> is shell-specific and there isn&rsquo;t always a
built in way to do it so you&rsquo;ll need to look up how to accomplish it in your
shell.</p>
<h3 id="problem-4-losing-your-history-after-updating-your-path">problem 4: losing your history after updating your <code>PATH</code></h3>
<p>Here&rsquo;s a situation that&rsquo;s easy to get into in bash or zsh:</p>
<ol>
<li>Run a command (it fails)</li>
<li>Update your <code>PATH</code></li>
<li>Run <code>bash</code> to reload your config</li>
<li>Press the up arrow a couple of times to rerun the failed command (or open a new terminal)</li>
<li>The failed command isn&rsquo;t in your history! Why not?</li>
</ol>
<p>This happens because in bash, by default, history is not saved until you exit
the shell.</p>
<p>Some options for fixing this:</p>
<ul>
<li>Instead of running <code>bash</code> to reload your config, run <code>source ~/.bashrc</code> (or
<code>source ~/.zshrc</code> in zsh). This will reload the config inside your current
session.</li>
<li>Configure your shell to continuously save your history instead of only saving
the history when the shell exits. (How to do this depends on whether you&rsquo;re
using bash or zsh, the history options in zsh are a bit complicated and I&rsquo;m
not exactly sure what the best way is)</li>
</ul>
<h3 id="a-note-on-source">a note on <code>source</code></h3>
<p>When you install <code>cargo</code> (Rust&rsquo;s installer) for the first time, it gives you
these instructions for how to set up your PATH, which don&rsquo;t mention a specific
directory at all.</p>
<pre><code>This is usually done by running one of the following (note the leading DOT):

. &quot;$HOME/.cargo/env&quot;        	# For sh/bash/zsh/ash/dash/pdksh
source &quot;$HOME/.cargo/env.fish&quot;  # For fish
</code></pre>
<p>The idea is that you add that line to your shell&rsquo;s config, and their script
automatically sets up your <code>PATH</code> (and potentially other things) for you.</p>
<p>This is pretty common (for example <a href="https://github.com/Homebrew/install/blob/deacfa6a6e62e5f4002baf9e1fac7a96e9aa5d41/install.sh#L1072-L1087">Homebrew</a> suggests you eval <code>brew shellenv</code>), and there are
two ways to approach this:</p>
<ol>
<li>Just do what the tool suggests (like adding <code>. &quot;$HOME/.cargo/env&quot;</code> to your shell&rsquo;s config)</li>
<li>Figure out which directories the script they&rsquo;re telling you to run would add
to your PATH, and then add those manually. Here&rsquo;s how I&rsquo;d do that:
<ul>
<li>Run <code>. &quot;$HOME/.cargo/env&quot;</code> in my shell (or the fish version if using fish)</li>
<li>Run <code>echo &quot;$PATH&quot; | tr ':' '\n' | grep cargo</code> to figure out which directories it added</li>
<li>See that it says <code>/Users/bork/.cargo/bin</code> and shorten that to <code>~/.cargo/bin</code></li>
<li>Add the directory <code>~/.cargo/bin</code> to PATH (with the directions in this post)</li>
</ul>
</li>
</ol>
<p>I don&rsquo;t think there&rsquo;s anything wrong with doing what the tool suggests (it
might be the &ldquo;best way&rdquo;!), but personally I usually use the second approach
because I prefer knowing exactly what configuration I&rsquo;m changing.</p>
<h3 id="a-note-on-fish-add-path">a note on <code>fish_add_path</code></h3>
<p>fish has a handy function called <code>fish_add_path</code> that you can run to add a directory to your <code>PATH</code> like this:</p>
<pre><code>fish_add_path /some/directory
</code></pre>
<p>This is cool (it&rsquo;s such a simple command!) but I&rsquo;ve stopped using it for a couple of reasons:</p>
<ol>
<li>Sometimes <code>fish_add_path</code> will update the <code>PATH</code> for every session in the
future (with a &ldquo;universal variable&rdquo;) and sometimes it will update the <code>PATH</code>
just for the current session and it&rsquo;s hard for me to tell which one it will
do. In theory the docs explain this but I could not understand them.</li>
<li>If you ever need to <em>remove</em> the directory from your <code>PATH</code> a few weeks or
months later because maybe you made a mistake, it&rsquo;s kind of hard to do
(there are <a href="https://github.com/fish-shell/fish-shell/issues/8604">instructions in this comments of this github issue though</a>).</li>
</ol>
<h3 id="that-s-all">that&rsquo;s all</h3>
<p>Hopefully this will help some people. Let me know (on Mastodon or Bluesky) if
you there are other major gotchas that have tripped you up when adding a
directory to your PATH, or if you have questions about this post!</p>

---

### [Some terminal frustrations](https://jvns.ca/blog/2025/02/05/some-terminal-frustrations/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>A few weeks ago I ran a terminal survey (you can <a href="https://jvns.ca/terminal-survey/results-bsky.html">read the results here</a>) and at the end I asked:</p>
<blockquote>
<p>What‚Äôs the most frustrating thing about using the terminal for you?</p>
</blockquote>
<p>1600 people answered, and I decided to spend a few days categorizing all the
responses. Along the way I learned that classifying qualitative data is not
easy but I gave it my best shot. I ended up building a custom
<a href="https://github.com/jvns/classificator">tool</a> to make it faster to categorize
everything.</p>
<p>As with all of my surveys the methodology isn&rsquo;t particularly scientific. I just
posted the survey to Mastodon and Twitter, ran it for a couple of days, and got
answers from whoever happened to see it and felt like responding.</p>
<p>Here are the top categories of frustrations!</p>
<p>I think it&rsquo;s worth keeping in mind while reading these comments that</p>
<ul>
<li>40% of people answering this survey have been using the terminal for <strong>21+ years</strong></li>
<li>95% of people answering the survey have been using the terminal for at least 4 years</li>
</ul>
<p>These comments aren&rsquo;t coming from total beginners.</p>
<p>Here are the categories of frustrations! The number in brackets is the number
of people with that frustration. I&rsquo;m mostly writing this up for myself because
I&rsquo;m trying to write a zine about the terminal and I wanted to get a sense for
what people are having trouble with.</p>
<h3 id="remembering-syntax-115">remembering syntax (115)</h3>
<p>People talked about struggles remembering:</p>
<ul>
<li>the syntax for CLI tools like awk, jq, sed, etc</li>
<li>the syntax for redirects</li>
<li>keyboard shortcuts for tmux, text editing, etc</li>
</ul>
<p>One example comment:</p>
<blockquote>
<p>There are just so many little &ldquo;trivia&rdquo; details to remember for full
functionality. Even after all these years I&rsquo;ll sometimes forget where it&rsquo;s 2
or 1 for stderr, or forget which is which for <code>&gt;</code> and <code>&gt;&gt;</code>.</p>
</blockquote>
<h3 id="switching-terminals-is-hard-91">switching terminals is hard (91)</h3>
<p>People talked about struggling with switching systems (for example home/work
computer or when SSHing) and running into:</p>
<ul>
<li>OS differences in keyboard shortcuts (like Linux vs Mac)</li>
<li>systems which don&rsquo;t have their preferred text editor (&ldquo;no vim&rdquo; or &ldquo;only vim&rdquo;)</li>
<li>different versions of the same command (like Mac OS grep vs GNU grep)</li>
<li>no tab completion</li>
<li>a shell they aren&rsquo;t used to (&ldquo;the subtle differences between zsh and bash&rdquo;)</li>
</ul>
<p>as well as differences inside the same system like pagers being not consistent
with each other (git diff pagers, other pagers).</p>
<p>One example comment:</p>
<blockquote>
<p>I got used to fish and vi mode which are not available when I ssh into
servers, containers.</p>
</blockquote>
<h3 id="color-85">color (85)</h3>
<p>Lots of problems with color, like:</p>
<ul>
<li>programs setting colors that are unreadable with a light background color</li>
<li>finding a colorscheme they like (and getting it to work consistently across different apps)</li>
<li>color not working inside several layers of SSH/tmux/etc</li>
<li>not liking the defaults</li>
<li>not wanting color at all and struggling to turn it off</li>
</ul>
<p>This comment felt relatable to me:</p>
<blockquote>
<p>Getting my terminal theme configured in a reasonable way between the terminal
emulator and fish (I did this years ago and remember it being tedious and
fiddly and now feel like I&rsquo;m locked into my current theme because it works
and I dread touching any of that configuration ever again).</p>
</blockquote>
<h3 id="keyboard-shortcuts-84">keyboard shortcuts (84)</h3>
<p>Half of the comments on keyboard shortcuts were about how on Linux/Windows, the
keyboard shortcut to copy/paste in the terminal is different from in the rest
of the OS.</p>
<p>Some other issues with keyboard shortcuts other than copy/paste:</p>
<ul>
<li>using <code>Ctrl-W</code> in a browser-based terminal and closing the window</li>
<li>the terminal only supports a limited set of keyboard shortcuts (no
<code>Ctrl-Shift-</code>, no <code>Super</code>, no <code>Hyper</code>, lots of <code>ctrl-</code> shortcuts aren&rsquo;t
possible like <code>Ctrl-,</code>)</li>
<li>the OS stopping you from using a terminal keyboard shortcut (like by default
Mac OS uses <code>Ctrl+left arrow</code> for something else)</li>
<li>issues using emacs in the terminal</li>
<li>backspace not working (2)</li>
</ul>
<h3 id="other-copy-and-paste-issues-75">other copy and paste issues (75)</h3>
<p>Aside from &ldquo;the keyboard shortcut for copy and paste is different&rdquo;, there were
a lot of OTHER issues with copy and paste, like:</p>
<ul>
<li>copying over SSH</li>
<li>how tmux and the terminal emulator both do copy/paste in different ways</li>
<li>dealing with many different clipboards (system clipboard, vim clipboard, the
&ldquo;middle click&rdquo; clipboard on Linux, tmux&rsquo;s clipboard, etc) and potentially
synchronizing them</li>
<li>random spaces added when copying from the terminal</li>
<li>pasting multiline commands which automatically get run in a terrifying way</li>
<li>wanting a way to copy text without using the mouse</li>
</ul>
<h3 id="discoverability-55">discoverability (55)</h3>
<p>There were lots of comments about this, which all came down to the same basic
complaint &ndash; it&rsquo;s hard to discover useful tools or features! This comment kind of
summed it all up:</p>
<blockquote>
<p>How difficult it is to learn independently. Most of what I know is an
assorted collection of stuff I&rsquo;ve been told by random people over the years.</p>
</blockquote>
<h3 id="steep-learning-curve-44">steep learning curve (44)</h3>
<p>A lot of comments about it generally having a steep learning curve. A couple of
example comments:</p>
<blockquote>
<p>After 15 years of using it, I‚Äôm not much faster than using it than I was 5 or
maybe even 10 years ago.</p>
</blockquote>
<p>and</p>
<blockquote>
<p>That I know I could make my life easier by learning more about the shortcuts
and commands and configuring the terminal but I don&rsquo;t spend the time because it
feels overwhelming.</p>
</blockquote>
<h3 id="history-42">history  (42)</h3>
<p>Some issues with shell history:</p>
<ul>
<li>history not being shared between terminal tabs (16)</li>
<li>limits that are too short (4)</li>
<li>history not being restored when terminal tabs are restored</li>
<li>losing history because the terminal crashed</li>
<li>not knowing how to search history</li>
</ul>
<p>One example comment:</p>
<blockquote>
<p>It wasted a lot of time until I figured it out and still annoys me that
&ldquo;history&rdquo; on zsh has such a small buffer;  I have to type &ldquo;history 0&rdquo; to get
any useful length of history.</p>
</blockquote>
<h3 id="bad-documentation-37">bad documentation (37)</h3>
<p>People talked about:</p>
<ul>
<li>documentation being generally opaque</li>
<li>lack of examples in man pages</li>
<li>programs which don&rsquo;t have man pages</li>
</ul>
<p>Here&rsquo;s a representative comment:</p>
<blockquote>
<p>Finding good examples and docs. Man pages often not enough, have to wade
through stack overflow</p>
</blockquote>
<h3 id="scrollback-36">scrollback (36)</h3>
<p>A few issues with scrollback:</p>
<ul>
<li>programs printing out too much data making you lose scrollback history</li>
<li>resizing the terminal messes up the scrollback</li>
<li>lack of timestamps</li>
<li>GUI programs that you start in the background printing stuff out that gets in
the way of other programs&rsquo; outputs</li>
</ul>
<p>One example comment:</p>
<blockquote>
<p>When resizing the terminal (in particular: making it narrower) leads to
broken rewrapping of the scrollback content because the commands formatted
their output based on the terminal window width.</p>
</blockquote>
<h3 id="it-feels-outdated-33">&ldquo;it feels outdated&rdquo; (33)</h3>
<p>Lots of comments about how the terminal feels hampered by legacy decisions and
how users often end up needing to learn implementation details that feel very
esoteric. One example comment:</p>
<blockquote>
<p>Most of the legacy cruft, it would be great to have a green field
implementation of the CLI interface.</p>
</blockquote>
<h3 id="shell-scripting-32">shell scripting (32)</h3>
<p>Lots of complaints about POSIX shell scripting. There&rsquo;s a general feeling that
shell scripting is difficult but also that switching to a different less
standard scripting language (fish, nushell, etc) brings its own problems.</p>
<blockquote>
<p>Shell scripting. My tolerance to ditch a shell script and go to a scripting
language is pretty low. It‚Äôs just too messy and powerful. Screwing up can be
costly so I don‚Äôt even bother.</p>
</blockquote>
<h3 id="more-issues">more issues</h3>
<p>Some more issues that were mentioned at least 10 times:</p>
<ul>
<li>(31) inconsistent command line arguments: is it -h or help or &ndash;help?</li>
<li>(24) keeping dotfiles in sync across different systems</li>
<li>(23) performance (e.g. &ldquo;my shell takes too long to start&rdquo;)</li>
<li>(20) window management (potentially with some combination of tmux tabs, terminal tabs, and multiple terminal windows. Where did that shell session go?)</li>
<li>(17) generally feeling scared/uneasy (&ldquo;The debilitating fear that I‚Äôm going
to do some mysterious Bad Thing with a command and I will have absolutely no
idea how to fix or undo it or even really figure out what happened&rdquo;)</li>
<li>(16) terminfo issues (&ldquo;Having to learn about terminfo if/when I try a new terminal emulator and ssh elsewhere.&rdquo;)</li>
<li>(16) lack of image support (sixel etc)</li>
<li>(15) SSH issues (like having to start over when you lose the SSH connection)</li>
<li>(15) various tmux/screen issues (for example lack of integration between tmux and the terminal emulator)</li>
<li>(15) typos &amp; slow typing</li>
<li>(13) the terminal getting messed up for various reasons (pressing <code>Ctrl-S</code>, <code>cat</code>ing a binary, etc)</li>
<li>(12) quoting/escaping in the shell</li>
<li>(11) various Windows/PowerShell issues</li>
</ul>
<h3 id="n-a-122">n/a (122)</h3>
<p>There were also 122 answers to the effect of &ldquo;nothing really&rdquo; or &ldquo;only that I
can&rsquo;t do EVERYTHING in the terminal&rdquo;</p>
<p>One example comment:</p>
<blockquote>
<p>Think I&rsquo;ve found work arounds for most/all frustrations</p>
</blockquote>
<h3 id="that-s-all">that&rsquo;s all!</h3>
<p>I&rsquo;m not going to make a lot of commentary on these results, but here are a
couple of categories that feel related to me:</p>
<ul>
<li>remembering syntax &amp; history (often the thing you need to remember is something you&rsquo;ve run before!)</li>
<li>discoverability &amp; the learning curve (the lack of discoverability is definitely a big part of what makes it hard to learn)</li>
<li>&ldquo;switching systems is hard&rdquo; &amp; &ldquo;it feels outdated&rdquo; (tools that haven&rsquo;t really
changed in 30 or 40 years have many problems but they do tend to be always
<em>there</em> no matter what system you&rsquo;re on, which is very useful and makes them
hard to stop using)</li>
</ul>
<p>Trying to categorize all these results in a reasonable way really gave me an
appreciation for social science researchers&rsquo; skills.</p>

---

### [What's involved in getting a "modern" terminal setup?](https://jvns.ca/blog/2025/01/11/getting-a-modern-terminal-setup/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>Hello! Recently I ran a terminal survey and I asked people what frustrated
them. One person commented:</p>
<blockquote>
<p>There are so many pieces to having a modern terminal experience. I wish it
all came out of the box.</p>
</blockquote>
<p>My immediate reaction was &ldquo;oh, getting a modern terminal experience isn&rsquo;t that
hard, you just need to&hellip;.&rdquo;, but the more I thought about it, the longer the
&ldquo;you just need to&hellip;&rdquo; list got, and I kept thinking about more and more
caveats.</p>
<p>So I thought I would write down some notes about what it means to me personally
to have a &ldquo;modern&rdquo; terminal experience and what I think can make it hard for
people to get there.</p>
<h3 id="what-is-a-modern-terminal-experience">what is a &ldquo;modern terminal experience&rdquo;?</h3>
<p>Here are a few things that are important to me, with which part of the system
is responsible for them:</p>
<ul>
<li><strong>multiline support for copy and paste</strong>: if you paste 3 commands in your shell, it should not immediately run them all! That&rsquo;s scary! (<strong>shell</strong>, <strong>terminal emulator</strong>)</li>
<li><strong>infinite shell history</strong>: if I run a command in my shell, it should be saved forever, not deleted after 500 history entries or whatever. Also I want commands to be saved to the history immediately when I run them, not only when I exit the shell session (<strong>shell</strong>)</li>
<li><strong>a useful prompt</strong>: I can&rsquo;t live without having my <strong>current directory</strong> and <strong>current git branch</strong> in my prompt (<strong>shell</strong>)</li>
<li><strong>24-bit colour</strong>: this is important to me because I find it MUCH easier to theme neovim with 24-bit colour support than in a terminal with only 256 colours (<strong>terminal emulator</strong>)</li>
<li><strong>clipboard integration</strong> between vim and my operating system so that when I copy in Firefox, I can just press <code>p</code> in vim to paste (<strong>text editor</strong>, maybe the OS/terminal emulator too)</li>
<li><strong>good autocomplete</strong>: for example commands like git should have command-specific autocomplete (<strong>shell</strong>)</li>
<li><strong>having colours in <code>ls</code></strong> (<strong>shell config</strong>)</li>
<li><strong>a terminal theme I like</strong>: I spend a lot of time in my terminal, I want it to look nice and I want its theme to match my terminal editor&rsquo;s theme. (<strong>terminal emulator</strong>, <strong>text editor</strong>)</li>
<li><strong>automatic terminal fixing</strong>: If a programs prints out some weird escape
codes that mess up my terminal, I want that to automatically get reset so
that my terminal doesn&rsquo;t get messed up (<strong>shell</strong>)</li>
<li><strong>keybindings</strong>: I want <code>Ctrl+left arrow</code> to work (<strong>shell</strong> or <strong>application</strong>)</li>
<li><strong>being able to use the scroll wheel in programs like <code>less</code></strong>: (<strong>terminal emulator</strong> and <strong>applications</strong>)</li>
</ul>
<p>There are a million other terminal conveniences out there and different people
value different things, but those are the ones that I would be really unhappy
without.</p>
<h3 id="how-i-achieve-a-modern-experience">how I achieve a &ldquo;modern experience&rdquo;</h3>
<p>My basic approach is:</p>
<ol>
<li>use the <code>fish</code> shell. Mostly don&rsquo;t configure it, except to:
<ul>
<li>set the <code>EDITOR</code> environment variable to my favourite terminal editor</li>
<li>alias <code>ls</code> to <code>ls --color=auto</code></li>
</ul>
</li>
<li>use any terminal emulator with 24-bit colour support. In the past I&rsquo;ve used
GNOME Terminal, Terminator, and iTerm, but I&rsquo;m not picky about this. I don&rsquo;t really
configure it other than to choose a font.</li>
<li>use <code>neovim</code>, with a configuration that I&rsquo;ve been very slowly building over the last 9 years or so (the last time I deleted my vim config and started from scratch was 9 years ago)</li>
<li>use the <a href="https://github.com/chriskempson/base16">base16 framework</a> to theme everything</li>
</ol>
<p>A few things that affect my approach:</p>
<ul>
<li>I don&rsquo;t spend a lot of time SSHed into other machines</li>
<li>I&rsquo;d rather use the mouse a little than come up with keyboard-based ways to do everything</li>
<li>I work on a lot of small projects, not one big project</li>
</ul>
<h3 id="some-out-of-the-box-options-for-a-modern-experience">some &ldquo;out of the box&rdquo; options for a &ldquo;modern&rdquo; experience</h3>
<p>What if you want a nice experience, but don&rsquo;t want to spend a lot of time on
configuration? Figuring out how to configure vim in a way that I was satisfied
with really did take me like ten years, which is a long time!</p>
<p>My best ideas for how to get a reasonable terminal experience with minimal
config are:</p>
<ul>
<li>shell: either <code>fish</code> or <code>zsh</code> with <a href="https://ohmyz.sh/">oh-my-zsh</a></li>
<li>terminal emulator: almost anything with 24-bit colour support, for example all of these are popular:
<ul>
<li>linux: GNOME Terminal, Konsole, Terminator, xfce4-terminal</li>
<li>mac: iTerm (Terminal.app doesn&rsquo;t have 256-colour support)</li>
<li>cross-platform: kitty, alacritty, wezterm, or ghostty</li>
</ul>
</li>
<li>shell config:
<ul>
<li>set the <code>EDITOR</code> environment variable to your favourite terminal text
editor</li>
<li>maybe alias <code>ls</code> to <code>ls --color=auto</code></li>
</ul>
</li>
<li>text editor: this is a tough one, maybe <a href="https://micro-editor.github.io/">micro</a> or <a href="https://helix-editor.com/">helix</a>? I haven&rsquo;t used
either of them seriously but they both seem like very cool projects and I
think it&rsquo;s amazing that you can just use all the usual GUI editor commands
(<code>Ctrl-C</code> to copy, <code>Ctrl-V</code> to paste, <code>Ctrl-A</code> to select all) in micro and
they do what you&rsquo;d expect. I would probably try switching to helix except
that retraining my vim muscle memory seems way too hard. Also helix doesn&rsquo;t
have a GUI or plugin system yet.</li>
</ul>
<p>Personally I <strong>wouldn&rsquo;t</strong> use xterm, rxvt, or Terminal.app as a terminal emulator,
because I&rsquo;ve found in the past that they&rsquo;re missing core features (like 24-bit
colour in Terminal.app&rsquo;s case) that make the terminal harder to use for me.</p>
<p>I don&rsquo;t want to pretend that getting a &ldquo;modern&rdquo; terminal experience is easier
than it is though &ndash; I think there are two issues that make it hard. Let&rsquo;s talk
about them!</p>
<h3 id="issue-1-with-getting-to-a-modern-experience-the-shell">issue 1 with getting to a &ldquo;modern&rdquo; experience: the shell</h3>
<p>bash and zsh are by far the two most popular shells, and neither of them
provide a default experience that I would be happy using out of the box, for
example:</p>
<ul>
<li>you need to customize your prompt</li>
<li>they don&rsquo;t come with git completions by default, you have to set them up</li>
<li>by default, bash only stores 500 (!) lines of history and (at least on Mac OS)
zsh is only configured to store 2000 lines, which is still not a lot</li>
<li>I find bash&rsquo;s tab completion very frustrating, if there&rsquo;s more than
one match then you can&rsquo;t tab through them</li>
</ul>
<p>And even though <a href="https://jvns.ca/blog/2024/09/12/reasons-i--still--love-fish/">I love fish</a>, the fact
that it isn&rsquo;t POSIX does make it hard for a lot of folks to make the switch.</p>
<p>Of course it&rsquo;s totally possible to learn how to customize your prompt in bash
or whatever, and it doesn&rsquo;t even need to be that complicated (in bash I&rsquo;d
probably start with something like <code>export PS1='[\u@\h \W$(__git_ps1 &quot; (%s)&quot;)]\$ '</code>, or maybe use <a href="https://starship.rs/">starship</a>).
But each of these &ldquo;not complicated&rdquo; things really does add up and it&rsquo;s
especially tough if you need to keep your config in sync across several
systems.</p>
<p>An extremely popular solution to getting a &ldquo;modern&rdquo; shell experience is
<a href="https://ohmyz.sh/">oh-my-zsh</a>. It seems like a great project and I know a lot
of people use it very happily, but I&rsquo;ve struggled with configuration systems
like that in the past &ndash; it looks like right now the base oh-my-zsh adds about
3000 lines of config, and often I find that having an extra configuration
system makes it harder to debug what&rsquo;s happening when things go wrong. I
personally have a tendency to use the system to add a lot of extra plugins,
make my system slow, get frustrated that it&rsquo;s slow, and then delete it
completely and write a new config from scratch.</p>
<h3 id="issue-2-with-getting-to-a-modern-experience-the-text-editor">issue 2 with getting to a &ldquo;modern&rdquo; experience: the text editor</h3>
<p>In the terminal survey I ran recently, the most popular terminal text editors
by far were <code>vim</code>, <code>emacs</code>, and <code>nano</code>.</p>
<p>I think the main options for terminal text editors are:</p>
<ul>
<li>use vim or emacs and configure it to your liking, you can probably have any
feature you want if you put in the work</li>
<li>use nano and accept that you&rsquo;re going to have a pretty limited experience
(for example I don&rsquo;t think you can select text with the mouse and then &ldquo;cut&rdquo;
it in nano)</li>
<li>use <code>micro</code> or <code>helix</code> which seem to offer a pretty good out-of-the-box
experience, potentially occasionally run into issues with using a less
mainstream text editor</li>
<li>just avoid using a terminal text editor as much as possible, maybe use VSCode, use
VSCode&rsquo;s terminal for all your terminal needs, and mostly never edit files in
the terminal. Or I know a lot of people use <code>code</code> as their <code>EDITOR</code> in the terminal.</li>
</ul>
<h3 id="issue-3-individual-applications">issue 3: individual applications</h3>
<p>The last issue is that sometimes individual programs that I use are kind of
annoying. For example on my Mac OS machine, <code>/usr/bin/sqlite3</code> doesn&rsquo;t support
the <code>Ctrl+Left Arrow</code> keyboard shortcut. Fixing this to get a reasonable
terminal experience in SQLite was a little complicated, I had to:</p>
<ul>
<li>realize why this is happening (Mac OS won&rsquo;t ship GNU tools, and &ldquo;Ctrl-Left arrow&rdquo; support comes from GNU readline)</li>
<li>find a workaround (install sqlite from homebrew, which does have readline support)</li>
<li>adjust my environment (put Homebrew&rsquo;s sqlite3 in my PATH)</li>
</ul>
<p>I find that debugging application-specific issues like this is really not easy
and often it doesn&rsquo;t feel &ldquo;worth it&rdquo; &ndash; often I&rsquo;ll end up just dealing with
various minor inconveniences because I don&rsquo;t want to spend hours investigating
them. The only reason I was even able to figure this one out at all is that
I&rsquo;ve been spending a huge amount of time thinking about the terminal recently.</p>
<p>A big part of having a &ldquo;modern&rdquo; experience using terminal programs is just
using newer terminal programs, for example I can&rsquo;t be bothered to learn a
keyboard shortcut to sort the columns in <code>top</code>, but in <code>htop</code>  I can just click
on a column heading with my mouse to sort it. So I use htop instead! But discovering new more &ldquo;modern&rdquo; command line tools isn&rsquo;t easy (though
I made <a href="https://jvns.ca/blog/2022/04/12/a-list-of-new-ish--command-line-tools/">a list here</a>),
finding ones that I actually like using in practice takes time, and if you&rsquo;re
SSHed into another machine, they won&rsquo;t always be there.</p>
<h3 id="everything-affects-everything-else">everything affects everything else</h3>
<p>Something I find tricky about configuring my terminal to make everything &ldquo;nice&rdquo;
is that changing one seemingly small thing about my workflow can really affect
everything else. For example right now I don&rsquo;t use tmux. But if I needed to use
tmux again (for example because I was doing a lot of work SSHed into another
machine), I&rsquo;d need to think about a few things, like:</p>
<ul>
<li>if I wanted tmux&rsquo;s copy to synchronize with my system clipboard over
SSH, I&rsquo;d need to make sure that my terminal emulator has <a href="https://old.reddit.com/r/vim/comments/k1ydpn/a_guide_on_how_to_copy_text_from_anywhere/">OSC 52 support</a></li>
<li>if I wanted to use iTerm&rsquo;s tmux integration (which makes tmux tabs into iTerm
tabs), I&rsquo;d need to change how I configure colours &ndash; right now I set them
with a <a href="https://github.com/chriskempson/base16-shell/blob/588691ba71b47e75793ed9edfcfaa058326a6f41/scripts/base16-solarized-light.sh">shell script</a> that I run when my shell starts, but that means the
colours get lost when restoring a tmux session.</li>
</ul>
<p>and probably more things I haven&rsquo;t thought of. &ldquo;Using tmux means that I have to
change how I manage my colours&rdquo; sounds unlikely, but that really did happen to
me and I decided &ldquo;well, I don&rsquo;t want to change how I manage colours right now,
so I guess I&rsquo;m not using that feature!&rdquo;.</p>
<p>It&rsquo;s also hard to remember which features I&rsquo;m relying on &ndash; for example maybe
my current terminal <em>does</em> have OSC 52 support and because copying from tmux over SSH
has always Just Worked I don&rsquo;t even realize that that&rsquo;s something I need, and
then it mysteriously stops working when I switch terminals.</p>
<h3 id="change-things-slowly">change things slowly</h3>
<p>Personally even though I think my setup is not <em>that</em> complicated, it&rsquo;s taken
me 20 years to get to this point! Because terminal config changes are so likely
to have unexpected and hard-to-understand consequences, I&rsquo;ve found that if I
change a lot of terminal configuration all at once it makes it much harder to
understand what went wrong if there&rsquo;s a problem, which can be really
disorienting.</p>
<p>So I usually prefer to make pretty small changes, and accept that changes can
might take me a REALLY long time to get used to. For example I switched from
using <code>ls</code> to <a href="https://github.com/eza-community/eza">eza</a> a year or two ago and
while I like it (because <code>eza -l</code> prints human-readable file sizes by default)
I&rsquo;m still not quite sure about it. But also sometimes it&rsquo;s worth it to make a
big change, like I made the switch to fish (from bash) 10 years ago and I&rsquo;m
very happy I did.</p>
<h3 id="getting-a-modern-terminal-is-not-that-easy">getting a &ldquo;modern&rdquo; terminal is not that easy</h3>
<p>Trying to explain how &ldquo;easy&rdquo; it is to configure your terminal really just made
me think that it&rsquo;s kind of hard and that I still sometimes get confused.</p>
<p>I&rsquo;ve found that there&rsquo;s never one perfect way to configure things in the
terminal that will be compatible with every single other thing. I just need to
try stuff, figure out some kind of locally stable state that works for me, and
accept that if I start using a new tool it might disrupt the system and I might
need to rethink things.</p>

---

### ["Rules" that terminal programs follow](https://jvns.ca/blog/2024/11/26/terminal-rules/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>Recently I&rsquo;ve been thinking about how everything that happens in the terminal
is some combination of:</p>
<ol>
<li>Your <strong>operating system</strong>&rsquo;s job</li>
<li>Your <strong>shell</strong>&rsquo;s job</li>
<li>Your <strong>terminal emulator</strong>&rsquo;s job</li>
<li>The job of <strong>whatever program you happen to be running</strong> (like <code>top</code> or <code>vim</code> or <code>cat</code>)</li>
</ol>
<p>The first three (your operating system, shell, and terminal emulator) are all kind of
known quantities &ndash; if you&rsquo;re using bash in GNOME Terminal on Linux, you can
more or less reason about how how all of those things interact, and some of
their behaviour is standardized by POSIX.</p>
<p>But the fourth one (&ldquo;whatever program you happen to be running&rdquo;) feels like it
could do ANYTHING. How are you supposed to know how a program is going to
behave?</p>
<p>This post is kind of long so here&rsquo;s a quick table of contents:</p>
<ul>
<li><a href="https://jvns.ca/atom.xml#programs-behave-surprisingly-consistently">programs behave surprisingly consistently</a></li>
<li><a href="https://jvns.ca/atom.xml#these-are-meant-to-be-descriptive-not-prescriptive">these are meant to be descriptive, not prescriptive</a></li>
<li><a href="https://jvns.ca/atom.xml#it-s-not-always-obvious-which-rules-are-the-program-s-responsibility-to-implement">it&rsquo;s not always obvious which &ldquo;rules&rdquo; are the program&rsquo;s responsibility to implement</a></li>
<li><a href="https://jvns.ca/atom.xml#rule-1-noninteractive-programs-should-quit-when-you-press-ctrl-c">rule 1: noninteractive programs should quit when you press <code>Ctrl-C</code></a></li>
<li><a href="https://jvns.ca/atom.xml#rule-2-tuis-should-quit-when-you-press-q">rule 2: TUIs should quit when you press <code>q</code></a></li>
<li><a href="https://jvns.ca/atom.xml#rule-3-repls-should-quit-when-you-press-ctrl-d-on-an-empty-line">rule 3: REPLs should quit when you press <code>Ctrl-D</code> on an empty line</a></li>
<li><a href="https://jvns.ca/atom.xml#rule-4-don-t-use-more-than-16-colours">rule 4: don&rsquo;t use more than 16 colours</a></li>
<li><a href="https://jvns.ca/atom.xml#rule-5-vaguely-support-readline-keybindings">rule 5: vaguely support readline keybindings</a></li>
<li><a href="https://jvns.ca/atom.xml#rule-5-1-ctrl-w-should-delete-the-last-word">rule 5.1: <code>Ctrl-W</code> should delete the last word</a></li>
<li><a href="https://jvns.ca/atom.xml#rule-6-disable-colours-when-writing-to-a-pipe">rule 6: disable colours when writing to a pipe</a></li>
<li><a href="https://jvns.ca/atom.xml#rule-7-means-stdin-stdout">rule 7: <code>-</code> means stdin/stdout</a></li>
<li><a href="https://jvns.ca/atom.xml#these-rules-take-a-long-time-to-learn">these &ldquo;rules&rdquo; take a long time to learn</a></li>
</ul>
<h3 id="programs-behave-surprisingly-consistently">programs behave surprisingly consistently</h3>
<p>As far as I know, there are no real standards for how programs in the terminal
should behave &ndash; the closest things I know of are:</p>
<ul>
<li>POSIX, which mostly dictates how your terminal emulator / OS / shell should
work together. I think it does specify a few things about how core utilities like
<code>cp</code> should work but AFAIK it doesn&rsquo;t have anything to say about how for
example <code>htop</code> should behave.</li>
<li>these <a href="https://clig.dev/">command line interface guidelines</a></li>
</ul>
<p>But even though there are no standards, in my experience programs in the
terminal behave in a pretty consistent way. So I wanted to write down a list of
&ldquo;rules&rdquo; that in my experience programs mostly follow.</p>
<h3 id="these-are-meant-to-be-descriptive-not-prescriptive">these are meant to be descriptive, not prescriptive</h3>
<p>My goal here isn&rsquo;t to convince authors of terminal programs that they <em>should</em>
follow any of these rules. There are lots of exceptions to these and often
there&rsquo;s a good reason for those exceptions.</p>
<p>But it&rsquo;s very useful for me to know what behaviour to expect from a random new
terminal program that I&rsquo;m using. Instead of &ldquo;uh, programs could do literally
anything&rdquo;, it&rsquo;s &ldquo;ok, here are the basic rules I expect, and then I can keep a
short mental list of exceptions&rdquo;.</p>
<p>So I&rsquo;m just writing down what I&rsquo;ve observed about how programs behave in my 20
years of using the terminal, why I think they behave that way, and some
examples of cases where that rule is &ldquo;broken&rdquo;.</p>
<h3 id="it-s-not-always-obvious-which-rules-are-the-program-s-responsibility-to-implement">it&rsquo;s not always obvious which &ldquo;rules&rdquo; are the program&rsquo;s responsibility to implement</h3>
<p>There are a bunch of common conventions that I think are pretty clearly the
program&rsquo;s responsibility to implement, like:</p>
<ul>
<li>config files should go in <code>~/.BLAHrc</code> or <code>~/.config/BLAH/FILE</code> or <code>/etc/BLAH/</code> or something</li>
<li><code>--help</code> should print help text</li>
<li>programs should print &ldquo;regular&rdquo; output to stdout and errors to stderr</li>
</ul>
<p>But in this post I&rsquo;m going to focus on things that it&rsquo;s not 100% obvious are
the program&rsquo;s responsibility. For example it feels to me like a &ldquo;law of nature&rdquo;
that pressing <code>Ctrl-D</code> should quit a REPL, but programs often
need to explicitly implement support for it &ndash; even though <code>cat</code> doesn&rsquo;t need
to implement <code>Ctrl-D</code> support, <code>ipython</code> <a href="https://github.com/prompt-toolkit/python-prompt-toolkit/blob/a2a12300c635ab3c051566e363ed27d853af4b21/src/prompt_toolkit/shortcuts/prompt.py#L824-L837">does</a>. (more about that in &ldquo;rule 3&rdquo; below)</p>
<p>Understanding which things are the program&rsquo;s responsibility makes it much less
surprising when different programs&rsquo; implementations are slightly different.</p>
<h3 id="rule-1-noninteractive-programs-should-quit-when-you-press-ctrl-c">rule 1: noninteractive programs should quit when you press <code>Ctrl-C</code></h3>
<p>The main reason for this rule is that noninteractive programs will quit by
default on <code>Ctrl-C</code> if they don&rsquo;t set up a <code>SIGINT</code> signal handler, so this is
kind of a &ldquo;you should act like the default&rdquo; rule.</p>
<p>Something that trips a lot of people up is that this doesn&rsquo;t apply to
<strong>interactive</strong> programs like <code>python3</code> or <code>bc</code> or <code>less</code>. This is because in
an interactive program, <code>Ctrl-C</code> has a different job &ndash; if the program is
running an operation (like for example a search in <code>less</code> or some Python code
in <code>python3</code>), then <code>Ctrl-C</code> will interrupt that operation but not stop the
program.</p>
<p>As an example of how this works in an interactive program: here&rsquo;s the code <a href="https://github.com/prompt-toolkit/python-prompt-toolkit/blob/a2a12300c635ab3c051566e363ed27d853af4b21/src/prompt_toolkit/key_binding/bindings/vi.py#L2225">in prompt-toolkit</a> (the library that iPython uses for handling input)
that aborts a search when you press <code>Ctrl-C</code>.</p>
<h3 id="rule-2-tuis-should-quit-when-you-press-q">rule 2: TUIs should quit when you press <code>q</code></h3>
<p>TUI programs (like <code>less</code> or <code>htop</code>) will usually quit when you press <code>q</code>.</p>
<p>This rule doesn&rsquo;t apply to any program where pressing <code>q</code> to quit wouldn&rsquo;t make
sense, like <code>tmux</code> or text editors.</p>
<h3 id="rule-3-repls-should-quit-when-you-press-ctrl-d-on-an-empty-line">rule 3: REPLs should quit when you press <code>Ctrl-D</code> on an empty line</h3>
<p>REPLs (like <code>python3</code> or <code>ed</code>) will usually quit when you press <code>Ctrl-D</code> on an
empty line. This rule is similar to the <code>Ctrl-C</code> rule &ndash; the reason for this is
that by default if you&rsquo;re running a program (like <code>cat</code>) in &ldquo;cooked mode&rdquo;, then
the operating system will return an <code>EOF</code> when you press <code>Ctrl-D</code> on an empty
line.</p>
<p>Most of the REPLs I use (sqlite3, python3, fish, bash, etc) don&rsquo;t actually use
cooked mode, but they all implement this keyboard shortcut anyway to mimic the
default behaviour.</p>
<p>For example, here&rsquo;s <a href="https://github.com/prompt-toolkit/python-prompt-toolkit/blob/a2a12300c635ab3c051566e363ed27d853af4b21/src/prompt_toolkit/shortcuts/prompt.py#L824-L837">the code in prompt-toolkit</a>
that quits when you press Ctrl-D, and here&rsquo;s <a href="https://github.com/bminor/bash/blob/6794b5478f660256a1023712b5fc169196ed0a22/lib/readline/readline.c#L658-L672">the same code in readline</a>.</p>
<p>I actually thought that this one was a &ldquo;Law of Terminal Physics&rdquo; until very
recently because I&rsquo;ve basically never seen it broken, but you can see that it&rsquo;s
just something that each individual input library has to implement in the links
above.</p>
<p>Someone pointed out that the Erlang REPL does not quit when you press <code>Ctrl-D</code>,
so I guess not every REPL follows this &ldquo;rule&rdquo;.</p>
<h3 id="rule-4-don-t-use-more-than-16-colours">rule 4: don&rsquo;t use more than 16 colours</h3>
<p>Terminal programs rarely use colours other than the base 16 ANSI colours. This
is because if you specify colours with a hex code, it&rsquo;s very likely to clash
with some users&rsquo; background colour. For example if I print out some text as
<code>#EEEEEE</code>, it would be almost invisible on a white background, though it would
look fine on a dark background.</p>
<p>But if you stick to the default 16 base colours, you have a much better chance
that the user has configured those colours in their terminal emulator so that
they work reasonably well with their background color. Another reason to stick
to the default base 16 colours is that it makes less assumptions about what
colours the terminal emulator supports.</p>
<p>The only programs I usually see breaking this &ldquo;rule&rdquo; are text editors, for
example Helix by default will use a purple background which is not a default
ANSI colour. It seems fine for Helix to break this rule since Helix isn&rsquo;t a
&ldquo;core&rdquo; program and I assume any Helix user who doesn&rsquo;t like that colorscheme
will just change the theme.</p>
<h3 id="rule-5-vaguely-support-readline-keybindings">rule 5: vaguely support readline keybindings</h3>
<p>Almost every program I use supports <code>readline</code> keybindings if it would make
sense to do so. For example, here are a bunch of different programs and a link
to where they define <code>Ctrl-E</code> to go to the end of the line:</p>
<ul>
<li>ipython (<a href="https://github.com/prompt-toolkit/python-prompt-toolkit/blob/a2a12300c635ab3c051566e363ed27d853af4b21/src/prompt_toolkit/key_binding/bindings/emacs.py#L72">Ctrl-E defined here</a>)</li>
<li>atuin (<a href="https://github.com/atuinsh/atuin/blob/a67cfc82fe0dc907a01f07a0fd625701e062a33b/crates/atuin/src/command/client/search/interactive.rs#L407">Ctrl-E defined here</a>)</li>
<li>fzf (<a href="https://github.com/junegunn/fzf/blob/bb55045596d6d08445f3c6d320c3ec2b457462d1/src/terminal.go#L611">Ctrl-E defined here</a>)</li>
<li>zsh (<a href="https://github.com/zsh-users/zsh/blob/86d5f24a3d28541f242eb3807379301ea976de87/Src/Zle/zle_bindings.c#L94">Ctrl-E defined here</a>)</li>
<li>fish (<a href="https://github.com/fish-shell/fish-shell/blob/99fa8aaaa7956178973150a03ce4954ab17a197b/share/functions/fish_default_key_bindings.fish#L43">Ctrl-E defined here</a>)</li>
<li>tmux&rsquo;s command prompt (<a href="https://github.com/tmux/tmux/blob/ae8f2208c98e3c2d6e3fe4cad2281dce8fd11f31/key-bindings.c#L490">Ctrl-E defined here</a>)</li>
</ul>
<p>None of those programs actually uses <code>readline</code> directly, they just sort of
mimic emacs/readline keybindings. They don&rsquo;t always mimic them <em>exactly</em>: for
example atuin seems to use <code>Ctrl-A</code> as a prefix, so <code>Ctrl-A</code> doesn&rsquo;t go to the
beginning of the line.</p>
<p>Also all of these programs seem to implement their own internal cut and paste
buffers so you can delete a line with <code>Ctrl-U</code> and then paste it with <code>Ctrl-Y</code>.</p>
<p>The exceptions to this are:</p>
<ul>
<li>some programs (like <code>git</code>, <code>cat</code>, and <code>nc</code>) don&rsquo;t have any line editing support at all (except for backspace, <code>Ctrl-W</code>, and <code>Ctrl-U</code>)</li>
<li>as usual text editors are an exception, every text editor has its own
approach to editing text</li>
</ul>
<p>I wrote more about this &ldquo;what keybindings does a program support?&rdquo; question in
<a href="https://jvns.ca/blog/2024/07/08/readline/">entering text in the terminal is complicated</a>.</p>
<h3 id="rule-5-1-ctrl-w-should-delete-the-last-word">rule 5.1: Ctrl-W should delete the last word</h3>
<p>I&rsquo;ve never seen a program (other than a text editor) where <code>Ctrl-W</code> <em>doesn&rsquo;t</em>
delete the last word. This is similar to the <code>Ctrl-C</code> rule &ndash; by default if a
program is in &ldquo;cooked mode&rdquo;, the OS will delete the last word if you press
<code>Ctrl-W</code>, and delete the whole line if you press <code>Ctrl-U</code>. So usually programs
will imitate that behaviour.</p>
<p>I can&rsquo;t think of any exceptions to this other than text editors but if there
are I&rsquo;d love to hear about them!</p>
<h3 id="rule-6-disable-colours-when-writing-to-a-pipe">rule 6: disable colours when writing to a pipe</h3>
<p>Most programs will disable colours when writing to a pipe. For example:</p>
<ul>
<li><code>rg blah</code> will highlight all occurrences of <code>blah</code> in the output, but if the
output is to a pipe or a file, it&rsquo;ll turn off the highlighting.</li>
<li><code>ls --color=auto</code> will use colour when writing to a terminal, but not when
writing to a pipe</li>
</ul>
<p>Both of those programs will also format their output differently when writing
to the terminal: <code>ls</code> will organize files into columns, and ripgrep will group
matches with headings.</p>
<p>If you want to force the program to use colour (for example because you want to
look at the colour), you can use <code>unbuffer</code> to force the program&rsquo;s output to be
a tty like this:</p>
<pre><code>unbuffer rg blah |  less -R
</code></pre>
<p>I&rsquo;m sure that there are some programs that &ldquo;break&rdquo; this rule but I can&rsquo;t think
of any examples right now. Some programs have an <code>--color</code> flag that you can
use to force colour to be on, in the example above you could also do <code>rg --color=always | less -R</code>.</p>
<h3 id="rule-7-means-stdin-stdout">rule 7: <code>-</code> means stdin/stdout</h3>
<p>Usually if you pass <code>-</code> to a program instead of a filename, it&rsquo;ll read from
stdin or write to stdout (whichever is appropriate). For example, if you want
to format the Python code that&rsquo;s on your clipboard with <code>black</code> and then copy
it, you could run:</p>
<pre><code>pbpaste | black - | pbcopy
</code></pre>
<p>(<code>pbpaste</code> is a Mac program, you can do something similar on Linux with <code>xclip</code>)</p>
<p>My impression is that most programs implement this if it would make sense and I
can&rsquo;t think of any exceptions right now, but I&rsquo;m sure there are many
exceptions.</p>
<h3 id="these-rules-take-a-long-time-to-learn">these &ldquo;rules&rdquo; take a long time to learn</h3>
<p>These rules took me a long time for me to learn because I had to:</p>
<ol>
<li>learn that the rule applied anywhere at all (&quot;<code>Ctrl-C</code> will exit programs&quot;)</li>
<li>notice some exceptions (&ldquo;okay, <code>Ctrl-C</code> will exit <code>find</code> but not <code>less</code>&rdquo;)</li>
<li>subconsciously figure out what the pattern is (&quot;<code>Ctrl-C</code> will generally quit
noninteractive programs, but in interactive programs it might interrupt the
current operation instead of quitting the program&quot;)</li>
<li>eventually maybe formulate it into an explicit rule that I know</li>
</ol>
<p>A lot of my understanding of the terminal is honestly still in the
&ldquo;subconscious pattern recognition&rdquo; stage. The only reason I&rsquo;ve been taking the
time to make things explicit at all is because I&rsquo;ve been trying to explain how
it works to others. Hopefully writing down these &ldquo;rules&rdquo; explicitly will make
learning some of this stuff a little bit faster for others.</p>

---

### [Why pipes sometimes get "stuck": buffering](https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/)

**Êù•Ê∫ê**: Julia Evans

**ÊëòË¶Å**: <p>Here&rsquo;s a niche terminal problem that has bothered me for years but that I never
really understood until a few weeks ago. Let&rsquo;s say you&rsquo;re running this command
to watch for some specific output in a log file:</p>
<pre><code>tail -f /some/log/file | grep thing1 | grep thing2
</code></pre>
<p>If log lines are being added to the file relatively slowly, the result I&rsquo;d see
is&hellip; nothing! It doesn&rsquo;t matter if there were matches in the log file or not,
there just wouldn&rsquo;t be any output.</p>
<p>I internalized this as &ldquo;uh, I guess pipes just get stuck sometimes and don&rsquo;t
show me the output, that&rsquo;s weird&rdquo;, and I&rsquo;d handle it by just
running <code>grep thing1 /some/log/file | grep thing2</code> instead, which would work.</p>
<p>So as I&rsquo;ve been doing a terminal deep dive over the last few months I was
really excited to finally learn exactly why this happens.</p>
<h3 id="why-this-happens-buffering">why this happens: buffering</h3>
<p>The reason why &ldquo;pipes get stuck&rdquo; sometimes is that it&rsquo;s VERY common for
programs to buffer their output before writing it to a pipe or file. So the
pipe is working fine, the problem is that the program never even wrote the data
to the pipe!</p>
<p>This is for performance reasons: writing all output immediately as soon as you
can uses more system calls, so it&rsquo;s more efficient to save up data until you
have 8KB or so of data to write (or until the program exits) and THEN write it
to the pipe.</p>
<p>In this example:</p>
<pre><code>tail -f /some/log/file | grep thing1 | grep thing2
</code></pre>
<p>the problem is that <code>grep thing1</code> is saving up all of its matches until it has
8KB of data to write, which might literally never happen.</p>
<h3 id="programs-don-t-buffer-when-writing-to-a-terminal">programs don&rsquo;t buffer when writing to a terminal</h3>
<p>Part of why I found this so disorienting is that <code>tail -f file | grep thing</code>
will work totally fine, but then when you add the second <code>grep</code>, it stops
working!! The reason for this is that the way <code>grep</code> handles buffering depends
on whether it&rsquo;s writing to a terminal or not.</p>
<p>Here&rsquo;s how <code>grep</code> (and many other programs) decides to buffer its output:</p>
<ul>
<li>Check if stdout is a terminal or not using the <code>isatty</code> function
<ul>
<li>If it&rsquo;s a terminal, use line buffering (print every line immediately as soon as you have it)</li>
<li>Otherwise, use &ldquo;block buffering&rdquo; &ndash; only print data if you have at least 8KB or so of data to print</li>
</ul>
</li>
</ul>
<p>So if <code>grep</code> is writing directly to your terminal then you&rsquo;ll see the line as
soon as it&rsquo;s printed, but if it&rsquo;s writing to a pipe, you won&rsquo;t.</p>
<p>Of course the buffer size isn&rsquo;t always 8KB for every program, it depends on the implementation. For <code>grep</code> the buffering is handled by libc, and libc&rsquo;s buffer size is
defined in the <code>BUFSIZ</code> variable. <a href="https://github.com/bminor/glibc/blob/c69e8cccaff8f2d89cee43202623b33e6ef5d24a/libio/stdio.h#L100">Here&rsquo;s where that&rsquo;s defined in glibc</a>.</p>
<p>(as an aside: &ldquo;programs do not use 8KB output buffers when writing to a
terminal&rdquo; isn&rsquo;t, like, a law of terminal physics, a program COULD use an 8KB
buffer when writing output to a terminal if it wanted, it would just be
extremely weird if it did that, I can&rsquo;t think of any program that behaves that
way)</p>
<h3 id="commands-that-buffer-commands-that-don-t">commands that buffer &amp; commands that don&rsquo;t</h3>
<p>One annoying thing about this buffering behaviour is that you kind of need to
remember which commands buffer their output when writing to a pipe.</p>
<p>Some commands that <strong>don&rsquo;t</strong> buffer their output:</p>
<ul>
<li>tail</li>
<li>cat</li>
<li>tee</li>
</ul>
<p>I think almost everything else will buffer output, especially if it&rsquo;s a command
where you&rsquo;re likely to be using it for batch processing. Here&rsquo;s a list of some
common commands that buffer their output when writing to a pipe, along with the
flag that disables block buffering.</p>
<ul>
<li>grep (<code>--line-buffered</code>)</li>
<li>sed (<code>-u</code>)</li>
<li>awk (there&rsquo;s a <code>fflush()</code> function)</li>
<li>tcpdump (<code>-l</code>)</li>
<li>jq (<code>-u</code>)</li>
<li>tr (<code>-u</code>)</li>
<li>cut (can&rsquo;t disable buffering)</li>
</ul>
<p>Those are all the ones I can think of, lots of unix commands (like <code>sort</code>) may
or may not buffer their output but it doesn&rsquo;t matter because <code>sort</code> can&rsquo;t do
anything until it finishes receiving input anyway.</p>
<p>Also I did my best to test both the Mac OS and GNU versions of these but there
are a lot of variations and I might have made some mistakes.</p>
<h3 id="programming-languages-where-the-default-print-statement-buffers">programming languages where the default &ldquo;print&rdquo; statement buffers</h3>
<p>Also, here are a few programming language where the default print statement
will buffer output when writing to a pipe, and some ways to disable buffering
if you want:</p>
<ul>
<li>C (disable with <code>setvbuf</code>)</li>
<li>Python (disable with <code>python -u</code>, or <code>PYTHONUNBUFFERED=1</code>, or <code>sys.stdout.reconfigure(line_buffering=False)</code>, or <code>print(x, flush=True)</code>)</li>
<li>Ruby (disable with <code>STDOUT.sync = true</code>)</li>
<li>Perl (disable with <code>$| = 1</code>)</li>
</ul>
<p>I assume that these languages are designed this way so that the default print
function will be fast when you&rsquo;re doing batch processing.</p>
<p>Also whether output is buffered or not might depend on how you print, for
example in C++ <code>cout &lt;&lt; &quot;hello\n&quot;</code> buffers when writing to a pipe but <code>cout &lt;&lt; &quot;hello&quot; &lt;&lt; endl</code> will flush its output.</p>
<h3 id="when-you-press-ctrl-c-on-a-pipe-the-contents-of-the-buffer-are-lost">when you press <code>Ctrl-C</code> on a pipe, the contents of the buffer are lost</h3>
<p>Let&rsquo;s say you&rsquo;re running this command as a hacky way to watch for DNS requests
to <code>example.com</code>, and you forgot to pass <code>-l</code> to tcpdump:</p>
<pre><code>sudo tcpdump -ni any port 53 | grep example.com
</code></pre>
<p>When you press <code>Ctrl-C</code>, what happens? In a magical perfect world, what I would
<em>want</em> to happen is for <code>tcpdump</code> to flush its buffer, <code>grep</code> would search for
<code>example.com</code>, and I would see all the output I missed.</p>
<p>But in the real world, what happens is that all the programs get killed and the
output in <code>tcpdump</code>&rsquo;s buffer is lost.</p>
<p>I think this problem is probably unavoidable &ndash; I spent a little time with
<code>strace</code> to see how this works and <code>grep</code> receives the <code>SIGINT</code> before
<code>tcpdump</code> anyway so even if <code>tcpdump</code> tried to flush its buffer <code>grep</code> would
already be dead.</p>
<small>
<p>After a little more investigation, there is a workaround: if you find
<code>tcpdump</code>&rsquo;s PID and <code>kill -TERM $PID</code>, then tcpdump will flush the buffer so
you can see the output. That&rsquo;s kind of a pain but I tested it and it seems to
work.</p>
</small>
<h3 id="redirecting-to-a-file-also-buffers">redirecting to a file also buffers</h3>
<p>It&rsquo;s not just pipes, this will also buffer:</p>
<pre><code>sudo tcpdump -ni any port 53 &gt; output.txt
</code></pre>
<p>Redirecting to a file doesn&rsquo;t have the same &ldquo;<code>Ctrl-C</code> will totally destroy the
contents of the buffer&rdquo; problem though &ndash; in my experience it usually behaves
more like you&rsquo;d want, where the contents of the buffer get written to the file
before the program exits. I&rsquo;m not 100% sure whether this is something you can
always rely on or not.</p>
<h3 id="a-bunch-of-potential-ways-to-avoid-buffering">a bunch of potential ways to avoid buffering</h3>
<p>Okay, let&rsquo;s talk solutions. Let&rsquo;s say you&rsquo;ve run this command:</p>
<pre><code>tail -f /some/log/file | grep thing1 | grep thing2
</code></pre>
<p>I asked people on Mastodon how they would solve this in practice and there were
5 basic approaches. Here they are:</p>
<h4 id="solution-1-run-a-program-that-finishes-quickly">solution 1: run a program that finishes quickly</h4>
<p>Historically my solution to this has been to just avoid the &ldquo;command writing to
pipe slowly&rdquo; situation completely and instead run a program that will finish quickly
like this:</p>
<pre><code>cat /some/log/file | grep thing1 | grep thing2 | tail
</code></pre>
<p>This doesn&rsquo;t do the same thing as the original command but it does mean that
you get to avoid thinking about these weird buffering issues.</p>
<p>(you could also do <code>grep thing1 /some/log/file</code> but I often prefer to use an
&ldquo;unnecessary&rdquo; <code>cat</code>)</p>
<h4 id="solution-2-remember-the-line-buffer-flag-to-grep">solution 2: remember the &ldquo;line buffer&rdquo; flag to grep</h4>
<p>You could remember that grep has a flag to avoid buffering and pass it like this:</p>
<pre><code>tail -f /some/log/file | grep --line-buffered thing1 | grep thing2
</code></pre>
<h4 id="solution-3-use-awk">solution 3: use awk</h4>
<p>Some people said that if they&rsquo;re specifically dealing with a multiple greps
situation, they&rsquo;ll rewrite it to use a single <code>awk</code> instead, like this:</p>
<pre><code>tail -f /some/log/file |  awk '/thing1/ &amp;&amp; /thing2/'
</code></pre>
<p>Or you would write a more complicated <code>grep</code>, like this:</p>
<pre><code>tail -f /some/log/file |  grep -E 'thing1.*thing2'
</code></pre>
<p>(<code>awk</code> also buffers, so for this to work you&rsquo;ll want <code>awk</code> to be the last command in the pipeline)</p>
<h4 id="solution-4-use-stdbuf">solution 4: use <code>stdbuf</code></h4>
<p><code>stdbuf</code> uses LD_PRELOAD to turn off libc&rsquo;s buffering, and you can use it to turn off output buffering like this:</p>
<pre><code>tail -f /some/log/file | stdbuf -o0 grep thing1 | grep thing2
</code></pre>
<p>Like any <code>LD_PRELOAD</code> solution it&rsquo;s a bit unreliable &ndash; it doesn&rsquo;t work on
static binaries, I think won&rsquo;t work if the program isn&rsquo;t using libc&rsquo;s
buffering, and doesn&rsquo;t always work on Mac OS. Harry Marr has a really nice <a href="https://hmarr.com/blog/how-stdbuf-works/">How stdbuf works</a> post.</p>
<h4 id="solution-5-use-unbuffer">solution 5: use <code>unbuffer</code></h4>
<p><code>unbuffer program</code> will force the program&rsquo;s output to be a TTY, which means
that it&rsquo;ll behave the way it normally would on a TTY (less buffering, colour
output, etc). You could use it in this example like this:</p>
<pre><code>tail -f /some/log/file | unbuffer grep thing1 | grep thing2
</code></pre>
<p>Unlike <code>stdbuf</code> it will always work, though it might have unwanted side
effects, for example <code>grep thing1</code>&rsquo;s will also colour matches.</p>
<p>If you want to install unbuffer, it&rsquo;s in the <code>expect</code> package.</p>
<h3 id="that-s-all-the-solutions-i-know-about">that&rsquo;s all the solutions I know about!</h3>
<p>It&rsquo;s a bit hard for me to say which one is &ldquo;best&rdquo;, I think personally I&rsquo;m
mostly likely to use <code>unbuffer</code> because I know it&rsquo;s always going to work.</p>
<p>If I learn about more solutions I&rsquo;ll try to add them to this post.</p>
<h3 id="i-m-not-really-sure-how-often-this-comes-up">I&rsquo;m not really sure how often this comes up</h3>
<p>I think it&rsquo;s not very common for me to have a program that slowly trickles data
into a pipe like this, normally if I&rsquo;m using a pipe a bunch of data gets
written very quickly, processed by everything in the pipeline, and then
everything exits. The only examples I can come up with right now are:</p>
<ul>
<li>tcpdump</li>
<li><code>tail -f</code></li>
<li>watching log files in a different way like with <code>kubectl logs</code></li>
<li>the output of a slow computation</li>
</ul>
<h3 id="what-if-there-were-an-environment-variable-to-disable-buffering">what if there were an environment variable to disable buffering?</h3>
<p>I think it would be cool if there were a standard environment variable to turn
off buffering, like <code>PYTHONUNBUFFERED</code> in Python. I got this idea from a
<a href="https://blog.plover.com/Unix/stdio-buffering.html">couple</a> of <a href="https://blog.plover.com/Unix/stdio-buffering-2.html">blog posts</a> by Mark Dominus
in 2018. Maybe <code>NO_BUFFER</code> like <a href="https://no-color.org/">NO_COLOR</a>?</p>
<p>The design seems tricky to get right; Mark points out that NETBSD has <a href="https://man.netbsd.org/setbuf.3">environment variables called <code>STDBUF</code>, <code>STDBUF1</code>, etc</a> which gives you a
ton of control over buffering but I imagine most developers don&rsquo;t want to
implement many different environment variables to handle a relatively minor
edge case.</p>
<p>I&rsquo;m also curious about whether there are any programs that just automatically
flush their output buffers after some period of time (like 1 second). It feels
like it would be nice in theory but I can&rsquo;t think of any program that does that
so I imagine there are some downsides.</p>
<h3 id="stuff-i-left-out">stuff I left out</h3>
<p>Some things I didn&rsquo;t talk about in this post since these posts have been
getting pretty long recently and seriously does anyone REALLY want to read 3000
words about buffering?</p>
<ul>
<li>the difference between line buffering and having totally unbuffered output</li>
<li>how buffering to stderr is different from buffering to stdout</li>
<li>this post is only about buffering that happens <strong>inside the program</strong>, your
operating system&rsquo;s TTY driver also does a little bit of buffering sometimes</li>
<li>other reasons you might need to flush your output other than &ldquo;you&rsquo;re writing
to a pipe&rdquo;</li>
</ul>

---

### [2025 Recap: so many projects](https://fasterthanli.me/articles/2025-recap)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <p>I‚Äôve been working on so many projects in 2025, I thought it was important for me
to make a recap, if only just to clear my head.</p>

<p>There are many, many, many things to go through and we don‚Äôt have a sponsor
today, so I‚Äôm gonna start right away with facet!</p>

<a class="anchor" href="https://fasterthanli.me/index.xml#facet" id="facet"><h2>facet</h2></a>
<p>facet is a project that I started working on in March of this year ‚Äî that‚Äôs
right, it‚Äôs only been ten months, yet it feels like an eternity.</p>

<a class="anchor" href="https://fasterthanli.me/index.xml#in-the-beginning" id="in-the-beginning"></a>






















<a class="anchor" href="https://fasterthanli.me/index.xml#the-first-golden-age" id="the-first-golden-age"></a>












<a class="anchor" href="https://fasterthanli.me/index.xml#disappointment" id="disappointment"></a>














<a class="anchor" href="https://fasterthanli.me/index.xml#refocus" id="refocus"></a>






















<a class="anchor" href="https://fasterthanli.me/index.xml#volte-face" id="volte-face"></a>












<a class="anchor" href="https://fasterthanli.me/index.xml#just-in-time-for-the-new-year" id="just-in-time-for-the-new-year"></a>






















<a class="anchor" href="https://fasterthanli.me/index.xml#arborium" id="arborium"></a>


















<a class="anchor" href="https://fasterthanli.me/index.xml#dodeca" id="dodeca"></a>




























<a class="anchor" href="https://fasterthanli.me/index.xml#rapace" id="rapace"></a>
























<a class="anchor" href="https://fasterthanli.me/index.xml#tracey" id="tracey"></a>














<a class="anchor" href="https://fasterthanli.me/index.xml#picante" id="picante"></a>




































<a class="anchor" href="https://fasterthanli.me/index.xml#pikru" id="pikru"></a>
















<a class="anchor" href="https://fasterthanli.me/index.xml#aasvg-rs" id="aasvg-rs"></a>






<a class="anchor" href="https://fasterthanli.me/index.xml#facet-keeps-growing" id="facet-keeps-growing"></a>


















<a class="anchor" href="https://fasterthanli.me/index.xml#fs-kitty" id="fs-kitty"></a>


























<a class="anchor" href="https://fasterthanli.me/index.xml#vixen" id="vixen"></a>






























































<a class="anchor" href="https://fasterthanli.me/index.xml#conclusion" id="conclusion"></a>

---

### [Introducing arborium, a tree-sitter distribution](https://fasterthanli.me/articles/introducing-arborium)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <p>About two weeks ago I entered a discussion with the docs.rs team about,
basically, why we have to look at this:</p>

<p><source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="My browser showing a docs.rs page for a crate that I published myself, which contains a lot of different code blocks with different languages but they're all white on black. It's sad.
" class="" height="750" src="https://cdn.fasterthanli.me/content/articles/introducing-arborium/docsrs-no-colors@2x~eb49252c206ebe40.jxl" title="" width="1083" /></p><p>When we could be looking at this:</p>

<p><source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="My browser showing a docs.rs page for a crate that I published myself, which contains a lot of different code blocks with different languages. this time it's colored.
" class="" height="750" src="https://cdn.fasterthanli.me/content/articles/introducing-arborium/docsrs-yes-colors@2x~708d0f07e1265747.jxl" title="" width="1083" /></p><p>And of course, as always, there are reasons why things are the way they are.
In an effort to understand those reasons, I opened a GitHub issue which resulted
in a <a href="https://github.com/rust-lang/docs.rs/issues/3040">short but productive</a> discussion.</p>

<p>I walked away discouraged, and then decided to, reasons be damned, attack this
problem from three different angles.</p>



<a class="anchor" href="https://fasterthanli.me/index.xml#background" id="background"></a>














<a class="anchor" href="https://fasterthanli.me/index.xml#problems" id="problems"></a>









<a class="anchor" href="https://fasterthanli.me/index.xml#solutions" id="solutions"></a>


































<a class="anchor" href="https://fasterthanli.me/index.xml#arborium" id="arborium"></a>


























<a class="anchor" href="https://fasterthanli.me/index.xml#angle-1-just-include-this-script" id="angle-1-just-include-this-script"></a>

























<a class="anchor" href="https://fasterthanli.me/index.xml#angle-2-it-goes-in-the-rustdoc-hole" id="angle-2-it-goes-in-the-rustdoc-hole"></a>












<a class="anchor" href="https://fasterthanli.me/index.xml#angle-3-only-in-the-backend" id="angle-3-only-in-the-backend"></a>










<a class="anchor" href="https://fasterthanli.me/index.xml#post-mortem" id="post-mortem"></a>












<a class="anchor" href="https://fasterthanli.me/index.xml#conclusion" id="conclusion"></a>

---

### [Does Dioxus spark joy?](https://fasterthanli.me/articles/does-dioxus-spark-joy)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <div class="dialog right">
<div class="dialog-head" title="Amos says:">
  <source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="Amos" height="42" src="https://cdn.fasterthanli.me/content/img/reimena/amos-neutral~55a3477398fe0cb1.jxl" width="42" />
</div>
<div class="dialog-text markup-container">
<p>Note: this article is adapted from a presentation I gave at a Rust Paris Meetup ‚Äî that‚Äôs why
it sounds a little different than usual. Enjoy!</p>

</div>
</div><p>Good evening! Tonight, I will attempt to answer the question: Does
<a href="https://github.com/dioxuslabs/dioxus">Dioxus</a> spark joy? Or at the very least,
whimsy.</p>

<p>What‚Äôs Dioxus, you ask? It is first and foremost a name that is quote: ‚Äúlegally
not inspired by any Pok√©mon‚Äù.</p>

<p><source media="(max-width: 400px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source type="image/webp" /><img alt="The deoxys pokemon
" class="" height="449" src="https://cdn.fasterthanli.me/content/articles/does-dioxus-spark-joy/deoxys@2x~d76eb1e3eeda1b65.jxl" title="" width="422" /></p><p>Even if the author concedes <a href="https://news.ycombinator.com/item?id=39853385">in a Hacker News comment</a> that the ‚ÄúDeoxys‚Äù Pok√©mon
is, I quote: ‚Äúawesome‚Äù.</p>











<a class="anchor" href="https://fasterthanli.me/index.xml#a-short-and-mostly-wrong-history-of-web-apps" id="a-short-and-mostly-wrong-history-of-web-apps"></a>


















<a class="anchor" href="https://fasterthanli.me/index.xml#a-practical-example" id="a-practical-example"></a>































<a class="anchor" href="https://fasterthanli.me/index.xml#love-hate" id="love-hate"></a>
































<a class="anchor" href="https://fasterthanli.me/index.xml#does-dioxus-spark-joy" id="does-dioxus-spark-joy"></a>














<a class="anchor" href="https://fasterthanli.me/index.xml#afterword" id="afterword"></a>

---

### [Engineering a Rust optimization quiz](https://fasterthanli.me/articles/engineering-a-rust-optimization-quiz)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <p>There are several Rust quizzes online, including one that‚Äôs literally called the
‚ÄúUnfair Rust Quiz‚Äù at <a href="https://this.quiz.is.fckn.gay/">https:&#x2f;&#x2f;this.quiz.is.fckn.gay&#x2f;</a>, but when I was given the
opportunity to record an episode of the <a href="https://sdr-podcast.com/">Self-Directed Research
podcast</a> live on the main stage of <a href="https://eurorust.eu/2025/">EuroRust
2025</a>, I thought I‚Äôd come up with something special.</p>

<figure class="paragraph-like"><source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="Question Misc 6 of the unfair Rust quiz, about drop order. " height="714" src="https://cdn.fasterthanli.me/content/articles/engineering-a-rust-optimization-quiz/unfair-rust-quiz@2x~478a86d3446281d7.jxl" title="The unfair rust quiz really deserves its name. It is best passed with a knowledgeable friend by your side. " width="795" /><figcaption><div class="markup-container figure-caption"><p>The unfair rust quiz really deserves its name. It is best passed with a knowledgeable friend by your side.</p>
</div></figcaption>
</figure>



<a class="anchor" href="https://fasterthanli.me/index.xml#coming-up-with-the-questions" id="coming-up-with-the-questions"></a>


























<a class="anchor" href="https://fasterthanli.me/index.xml#nih-syndrome-ppt" id="nih-syndrome-ppt"></a>




























<a class="anchor" href="https://fasterthanli.me/index.xml#server-side-shenanigans-and-room-codes" id="server-side-shenanigans-and-room-codes"></a>














<a class="anchor" href="https://fasterthanli.me/index.xml#deploying-the-beast" id="deploying-the-beast"></a>
























<a class="anchor" href="https://fasterthanli.me/index.xml#d-2-starting-fights-at-a-paris-meetup" id="d-2-starting-fights-at-a-paris-meetup"></a>






<a class="anchor" href="https://fasterthanli.me/index.xml#d-1-panic-mode-and-missing-explanations" id="d-1-panic-mode-and-missing-explanations"></a>










<a class="anchor" href="https://fasterthanli.me/index.xml#day-of-github-oauth-and-swipe-gestures" id="day-of-github-oauth-and-swipe-gestures"></a>
















<a class="anchor" href="https://fasterthanli.me/index.xml#showtime" id="showtime"></a>

---

### [Making our own spectrogram](https://fasterthanli.me/articles/making-our-own-spectrogram)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <p>A couple months ago <a href="https://fasterthanli.me/articles/the-science-of-loudness">I made a loudness meter</a>
and went way too in-depth into how humans have measured loudness over time.</p>

<p><source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="A screenshot of the fasterthanlime audio meter, with RMS, sample peak, true peak, and various loudness metrics.
" class="" height="512" src="https://cdn.fasterthanli.me/content/articles/making-our-own-spectrogram/fasterthanlime-audio-meter@2x~d5e6b54e3ade21f5.jxl" title="" width="800" /></p><p>Today we‚Äôre looking at a spectrogram visualization I made, which is a lot more entertaining!</p>

<p><source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="" class="" height="632" src="https://cdn.fasterthanli.me/content/articles/making-our-own-spectrogram/spectrogram-sonata-op25-3@2x~c22af608785d58b2.jxl" title="" width="1100" /></p><p>We‚Äôre going to talk about how to extract frequencies from sound waves, but also
how my spectrogram app is assembled from different Rust crates, how it
handles audio and graphics threads, how it draws the spectrogram etc.</p>



<a class="anchor" href="https://fasterthanli.me/index.xml#the-humble-sine-wave" id="the-humble-sine-wave"></a>




















<a class="anchor" href="https://fasterthanli.me/index.xml#approximating-a-square-wave" id="approximating-a-square-wave"></a>









<a class="anchor" href="https://fasterthanli.me/index.xml#a-real-world-sample" id="a-real-world-sample"></a>







<a class="anchor" href="https://fasterthanli.me/index.xml#chunking-and-windowing" id="chunking-and-windowing"></a>


























<a class="anchor" href="https://fasterthanli.me/index.xml#the-gabor-limit" id="the-gabor-limit"></a>





















<a class="anchor" href="https://fasterthanli.me/index.xml#interpolation" id="interpolation"></a>






<a class="anchor" href="https://fasterthanli.me/index.xml#color-mapping" id="color-mapping"></a>










<a class="anchor" href="https://fasterthanli.me/index.xml#frequency-mapping" id="frequency-mapping"></a>














<a class="anchor" href="https://fasterthanli.me/index.xml#audio-input" id="audio-input"></a>














<a class="anchor" href="https://fasterthanli.me/index.xml#drawing-the-ui" id="drawing-the-ui"></a>



















































<a class="anchor" href="https://fasterthanli.me/index.xml#updating-the-texture" id="updating-the-texture"></a>


























<a class="anchor" href="https://fasterthanli.me/index.xml#profiling-my-program" id="profiling-my-program"></a>




























<a class="anchor" href="https://fasterthanli.me/index.xml#having-fun" id="having-fun"></a>
































<a class="anchor" href="https://fasterthanli.me/index.xml#closing-words" id="closing-words"></a>

---

### [crates.io phishing attempt](https://fasterthanli.me/articles/crates-io-phishing-attempt)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <p>Earlier this week, an <a href="https://fasterthanli.me/articles/color-npm-package-compromised">npm supply chain attack</a>.</p>

<p>It‚Äôs turn for <a href="https://crates.io">crates.io</a>, the main public repository for <a href="https://rust-lang.org">Rust</a>
crates (packages).</p>

<p>The phishing e-mail looks like this:</p>

<figure class="paragraph-like"><source media="(max-width: 400px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source type="image/webp" /><img alt="A phishing e-mail: Important: Breach notification regarding crates.io  Hi, BurntSushi! We recently discovered that an unauthorized actor had compromised the crates.io infrastructure and accessed a limited amount of user information. The attacker's access was revoked, and we are currently reviewing our security posture. We are currently drafting a blog post to outline the timeline and the steps we took to mitigate this. In the meantime, we strongly suggest you to rotate your login info by signing in here to our internal SSO, which is a temporary fix to ensure that the attacker cannot modify any packages published by you. " height="653" src="https://cdn.fasterthanli.me/content/articles/crates-io-phishing-attempt/phishing-email~052f360399d29116.jxl" title="" width="708" /><figcaption><cite><a href="https://fasterthanli.me/&#x2f;&#x2f;bsky.app&#x2f;profile&#x2f;burntsushi.net&#x2f;post&#x2f;3lynehptw6c2n">Andrew Gallant on BlueSky
</a></cite></figcaption>
</figure><p>And it leads to a GitHub login page that looks like this:</p>

<figure class="paragraph-like"><source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="A fake GitHub sign-in page. " height="1378" src="https://cdn.fasterthanli.me/content/articles/crates-io-phishing-attempt/github-phish~e78524d35ede5efb.jxl" title="" width="1322" /><figcaption><cite><a href="https://fasterthanli.me/&#x2f;&#x2f;github.com&#x2f;rust-lang&#x2f;crates.io&#x2f;discussions&#x2f;11889#discussion-8886064">Barre on GitHub
</a></cite></figcaption>
</figure><p>Several maintainers received it ‚Äî the issue is being discussed <a href="https://github.com/rust-lang/crates.io/discussions/11889">on GitHub</a>.</p>

<p>The <a href="https://www.rust-lang.org/governance/teams/dev-tools#team-crates-io">crates.io team</a> has acknowledged
the attack and said they‚Äôd see if they can do something about it.</p>

---

### [color npm package compromised](https://fasterthanli.me/articles/color-npm-package-compromised)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <p>On September 8 2025, around 13:00 UTC, someone compromised <a href="https://www.npmjs.com/~qix">Josh Junon‚Äôs npm
account (qix)</a> and started publishing backdoored
versions of his package.</p>

<p>Someone noticed and let Josh know:</p>

<figure class="paragraph-like"><source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="Hey. Your npm account seems to have been compromised. 1 hour ago it started posting packages with backdoors to all your popular packages. " height="177" src="https://cdn.fasterthanli.me/content/articles/color-npm-package-compromised/charlie-noticed@2x~4a9e74f87760a4af.jxl" title="" width="595" /><figcaption><cite><a href="https://fasterthanli.me/&#x2f;&#x2f;bsky.app&#x2f;profile&#x2f;charlieeriksen.bsky.social&#x2f;post&#x2f;3lydffcyulc2n">Charlie Eriksen on BlueSky
</a></cite></figcaption>
</figure><p>Josh confirmed he‚Äôd gotten pwned by a fake 2FA (two-factor authentication) reset e-mail:</p>

<figure class="paragraph-like"><source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="Yep, I've been pwned. 2FA reset email, looked very legitimate.  Only NPM affected. I've sent an email off to @npmjs.bsky.social  to see if I can get access again.  Sorry everyone, I should have paid more attention. Not like me; have had a stressful week. Will work to get this cleaned up. " height="396" src="https://cdn.fasterthanli.me/content/articles/color-npm-package-compromised/josh-fake-2fa@2x~ca37f72d582a4442.jxl" title="" width="592" /><figcaption><cite><a href="https://fasterthanli.me/&#x2f;&#x2f;bsky.app&#x2f;profile&#x2f;bad-at-computer.bsky.social&#x2f;post&#x2f;3lydioq5swk2y">Josh Junon on BlueSky
</a></cite></figcaption>
</figure><p>The phishing e-mail came from <code>npmsj.help</code> (registered 3 days prior) and claimed
users had to reset their 2FA:</p>







<a class="anchor" href="https://fasterthanli.me/index.xml#the-payload" id="the-payload"></a>
























<a class="anchor" href="https://fasterthanli.me/index.xml#current-situation" id="current-situation"></a>

---

### [The science of loudness](https://fasterthanli.me/articles/the-science-of-loudness)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <p>My watch has a ‚ÄúNoise‚Äù app: it shows <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="normal">d</mi><mi mathvariant="normal">B</mi></mrow></math>, for decibels.</p>

<p><video alt="A video of my Apple Watch showing me how loud the sound coming from my speakers is.
" class="" controls="controls" height="2160" poster="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/apple-watch-decibel-meter.thumb" preload="none" title="" width="3840"><source src="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/apple-watch-decibel-meter~d96a722c49fdda5d.mp4" type="video/mp4; codecs=av01.0.08m.08,opus" /><source src="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/apple-watch-decibel-meter~e53858e76f36614d.h264+aac.mp4" type="video/mp4; codecs=avc1.640034,mp4a.40.2" /><source src="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/apple-watch-decibel-meter~fb169411c4d8653e.vp9+opus.webm" type="video/webm; codecs=vp09.00.41.08,opus" />Your browser does not support the video tag.</video></p><p>My amp has a volume knob, which also shows decibels, although.. negative ones, this time.</p>

<p><video alt="A video of me adjusting my volume on my Cambridge AXR100 amplifier. The
volume goes from -61 to -32 decibels in that video.
" class="" controls="controls" height="2160" poster="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/adjust-volume.thumb" preload="none" title="" width="3840"><source src="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/adjust-volume~46153fb1ad60f230.mp4" type="video/mp4; codecs=av01.0.08m.08,opus" /><source src="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/adjust-volume~a8af11cbe6d90598.h264+aac.mp4" type="video/mp4; codecs=avc1.640034,mp4a.40.2" /><source src="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/adjust-volume~9a7388f3f768f948.vp9+opus.webm" type="video/webm; codecs=vp09.00.41.08,opus" />Your browser does not support the video tag.</video></p><p>And finally, my video editing software has a ton of meters ‚Äî which are all in decibel or
decibel-adjacent units.</p>

<p><video alt="A screenshot of DaVinci Resolve, showing various meters: we have Bus 1,
Control Room with TP, Loudness, YouTube (LUFS), then Loudness History
with Integrated, Momentary and Short Term. In the Mixer, each track has
its meter.
" class="" controls="controls" height="1127" poster="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/tons-of-meters@2x.thumb" preload="none" title="" width="2002"><source src="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/tons-of-meters@2x~9cc29f2809d1202a.mp4" type="video/mp4; codecs=av01.0.08m.08,opus" /><source src="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/tons-of-meters@2x~da316f2ab0e0aeb5.h264+aac.mp4" type="video/mp4; codecs=avc1.640034,mp4a.40.2" /><source src="https://cdn.fasterthanli.me/content/articles/the-science-of-loudness/tons-of-meters@2x~e50f9e76cf48090c.vp9+opus.webm" type="video/webm; codecs=vp09.00.41.08,opus" />Your browser does not support the video tag.</video></p><p>How do all these decibels fit together?</p>






<a class="anchor" href="https://fasterthanli.me/index.xml#what-even-is-sound" id="what-even-is-sound"></a>
















<a class="anchor" href="https://fasterthanli.me/index.xml#under-pressure" id="under-pressure"></a>


















<a class="anchor" href="https://fasterthanli.me/index.xml#signal-processing" id="signal-processing"></a>




































<a class="anchor" href="https://fasterthanli.me/index.xml#root-mean-square" id="root-mean-square"></a>
















<a class="anchor" href="https://fasterthanli.me/index.xml#sample-peak-true-peak" id="sample-peak-true-peak"></a>




















<a class="anchor" href="https://fasterthanli.me/index.xml#the-loudness-wars" id="the-loudness-wars"></a>











































































<a class="anchor" href="https://fasterthanli.me/index.xml#a-weighting" id="a-weighting"></a>

---

### [Summer fasterthanlime update](https://fasterthanli.me/articles/summer-fasterthanlime-update)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <p>There are news!</p>

<div class="tip markup-container">
<div class="tip-header bear-mark">
<source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="Cool bear" class="bear" height="48" src="https://cdn.fasterthanli.me/content/img/reimena/coolbear-idea~85823bd96ffd0bb6.jxl" width="48" />
Cool Bear's hot tip
</div>
<p>TL;DR: If you‚Äôre a patron or sponsor, check your <a href="https://fasterthanli.me/profile">Profile</a> page to
get detailed explainers of every perk. You‚Äôll need to log in. Duh.</p>

</div><p>Here are all the changes I‚Äôm implementing, summarized as a table:</p>

<div class="responsive-table"><table><thead><td>Before</td><td>After</td></thead><tr><td>üìö Articles remain exclusive for <strong>6 months</strong></td><td>Early access (<strong>couple weeks</strong>) for Silver tier</td></tr><tr><td>üéûÔ∏è No early access for video</td><td><strong>Video early access</strong> on Patreon and website</td></tr></table></div>

<a class="anchor" href="https://fasterthanli.me/index.xml#looking-back" id="looking-back"></a>


































<a class="anchor" href="https://fasterthanli.me/index.xml#a-discord-server" id="a-discord-server"></a>








<a class="anchor" href="https://fasterthanli.me/index.xml#early-access-revamp" id="early-access-revamp"></a>








<a class="anchor" href="https://fasterthanli.me/index.xml#dual-rss-feeds" id="dual-rss-feeds"></a>






<a class="anchor" href="https://fasterthanli.me/index.xml#bye-ko-fi" id="bye-ko-fi"></a>






<a class="anchor" href="https://fasterthanli.me/index.xml#more-casual-posting" id="more-casual-posting"></a>




<a class="anchor" href="https://fasterthanli.me/index.xml#what-about-content-that-was-still-exclusive" id="what-about-content-that-was-still-exclusive"></a>

---

### [All color is best-effort](https://fasterthanli.me/articles/all-color-is-best-effort)

**Êù•Ê∫ê**: Amos (fasterthanlime)

**ÊëòË¶Å**: <p>I do not come to you with answers today, but rather some observations and a lot of questions.</p>

<a class="anchor" href="https://fasterthanli.me/index.xml#the-weird-glitch" id="the-weird-glitch"><h2>The weird glitch</h2></a>
<p>Recently I was editing some video and I noticed this:</p>

<p>



<source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="A screenshot of the video, there are visible circles at various places in the image. Some of them are black, some of them are white. The image itself shows some blue and white text composited on some blurry background, which doesn‚Äôt really matter for this, and there‚Äôs a red line horizontal up in the image. It‚Äôs very confusing." height="1126" src="https://cdn.fasterthanli.me/content/articles/all-color-is-best-effort/dvr-circles@2x~3c031f1f42693336.jxl" title="A screenshot of the video, there are visible circles at various places in the image. Some of them are black, some of them are white. The image itself shows some blue and white text composited on some blurry background, which doesn‚Äôt really matter for this, and there‚Äôs a red line horizontal up in the image. It‚Äôs very confusing." width="1966" /></p>

<p>Not what the finger is pointing at ‚Äî the dots.</p>

<p>Here are the separate layers this image is made up of: the background is a stock image
I‚Äôve licensed from Envato Elements:</p>

<p><source media="(max-width: 400px)" type="image/jxl" /><source media="(max-width: 900px)" type="image/jxl" /><source type="image/jxl" /><source media="(max-width: 400px)" type="image/avif" /><source media="(max-width: 900px)" type="image/avif" /><source type="image/avif" /><source media="(max-width: 400px)" type="image/webp" /><source media="(max-width: 900px)" type="image/webp" /><source type="image/webp" /><img alt="A picture of a canyon, darker than you‚Äôd expect." height="1126" src="https://cdn.fasterthanli.me/content/articles/all-color-is-best-effort/canyon-background@2x~dcfb5771209ddbd5.jxl" title="A picture of a canyon, darker than you‚Äôd expect." width="1966" /></p>

<p>Because I use it as a background image, I‚Äôve cranked down the exposition in the Color tab:</p>













































































<a class="anchor" href="https://fasterthanli.me/index.xml#playing-with-color-spaces" id="playing-with-color-spaces"></a>






























<a class="anchor" href="https://fasterthanli.me/index.xml#cie-chromaticity-diagram" id="cie-chromaticity-diagram"></a>


























































<a class="anchor" href="https://fasterthanli.me/index.xml#our-first-transfer-function" id="our-first-transfer-function"></a>






















































<a class="anchor" href="https://fasterthanli.me/index.xml#parade-scope" id="parade-scope"></a>






























<a class="anchor" href="https://fasterthanli.me/index.xml#more-transfer-functions" id="more-transfer-functions"></a>































































































<a class="anchor" href="https://fasterthanli.me/index.xml#how-white-is-your-white" id="how-white-is-your-white"></a>









































<a class="anchor" href="https://fasterthanli.me/index.xml#conclusion" id="conclusion"></a>

---

### [Cable cuts, storms, and DNS: a look at Internet disruptions in Q4 2025](https://blog.cloudflare.com/q4-2025-internet-disruption-summary/)

**Êù•Ê∫ê**: The Cloudflare Blog

**ÊëòË¶Å**: The last quarter of 2025 brought several notable disruptions to Internet connectivity. Cloudflare Radar data reveals the impact of cable cuts, power outages, extreme weather, technical problems, and more.

---

## Tech News

### [Why there‚Äôs no European Google?](https://ploum.net/2026-01-22-why-no-european-google.html)

**Êù•Ê∫ê**: Lobsters (Tech News)

**ÊëòË¶Å**: <p><a href="https://lobste.rs/s/u7bjzq/why_there_s_no_european_google">Comments</a></p>

---

### [The state of Linux music players in 2026](https://crescentro.se/posts/linux-music-players-2026/)

**Êù•Ê∫ê**: Lobsters (Tech News)

**ÊëòË¶Å**: <p><a href="https://lobste.rs/s/bpqtph/state_linux_music_players_2026">Comments</a></p>

---

### [The Enclosure feedback loop, or how LLMs sabotage existing programming practices by privatizing a public good](https://michiel.buddingh.eu/enclosure-feedback-loop)

**Êù•Ê∫ê**: Lobsters (Tech News)

**ÊëòË¶Å**: <p><a href="https://lobste.rs/s/kvvxkl/enclosure_feedback_loop_how_llms">Comments</a></p>

---

### [zerobrew is a Rust-based, 5-20x faster drop-in Homebrew alternative](https://github.com/lucasgelfond/zerobrew)

**Êù•Ê∫ê**: Lobsters (Tech News)

**ÊëòË¶Å**: <p>zerobrew takes a lot of ideas from uv - packages live in a content-addressable store (by sha256), so reinstalls are instant. Downloads, extraction, and linking run in parallel with aggressive HTTP caching. It pulls from Homebrew's CDN, so you can swap brew for zb with your existing commands. This leads to dramatic speedups, up to 5x cold and 20x warm!</p>
<p><a href="https://lobste.rs/s/ue0bau/zerobrew_is_rust_based_5_20x_faster_drop">Comments</a></p>

---

### [McCLIM and 7GUIs - Part 1: The Counter](https://turtleware.eu/posts/McCLIM-and-7GUIs---Part-1-The-Counter.html)

**Êù•Ê∫ê**: Lobsters (Tech News)

**ÊëòË¶Å**: <p><a href="https://lobste.rs/s/nktckk/mcclim_7guis_part_1_counter">Comments</a></p>

---

### [Fedora Asahi Remix is now working on Apple M3](https://bsky.app/profile/did:plc:okydh7e54e2nok65kjxdklvd/post/3mdd55paffk2o)

**Êù•Ê∫ê**: Lobsters (Tech News)

**ÊëòË¶Å**: <p><a href="https://lobste.rs/s/cm3wkh/fedora_asahi_remix_is_now_working_on_apple">Comments</a></p>

---

### [Apple, What Have You Done?](https://onlinegoddess.net/2026/01/apple-what-have-you-done/)

**Êù•Ê∫ê**: Lobsters (Tech News)

**ÊëòË¶Å**: <p><a href="https://lobste.rs/s/cyx4ba/apple_what_have_you_done">Comments</a></p>

---

### [Announcing MapLibre Tile: a modern and efficient vector tile format](https://maplibre.org/news/2026-01-23-mlt-release/)

**Êù•Ê∫ê**: Lobsters (Tech News)

**ÊëòË¶Å**: <p><a href="https://lobste.rs/s/qqfg0q/announcing_maplibre_tile_modern">Comments</a></p>

---

### [Godot 4.6 Release: It's all about your flow](https://godotengine.org/releases/4.6/)

**Êù•Ê∫ê**: Lobsters (Tech News)

**ÊëòË¶Å**: <p><a href="https://lobste.rs/s/gu8y4b/godot_4_6_release_it_s_all_about_your_flow">Comments</a></p>

---


---

## üìö Â¶Ç‰Ωï‰ΩøÁî®

1. ÊµèËßàÊÑüÂÖ¥Ë∂£ÁöÑÊ†áÈ¢ò
2. ÈòÖËØªAIÁîüÊàêÁöÑÊëòË¶ÅÂø´ÈÄü‰∫ÜËß£ÂÜÖÂÆπ
3. ÁÇπÂáªÈìæÊé•Ê∑±ÂÖ•ÈòÖËØª
4. Êúâ‰ª∑ÂÄºÁöÑÂÜÖÂÆπÂèØ‰ª•Êï¥ÁêÜÂà∞ÂØπÂ∫îÁöÑ‰∏ªÈ¢òÁõÆÂΩï

## üîß ÈÖçÁΩÆ

‰øÆÊîπ `config/sources.yaml` ÂèØ‰ª•:
- Ê∑ªÂä†/Âà†Èô§RSSËÆ¢ÈòÖÊ∫ê
- Ë∞ÉÊï¥HackerNewsÊúÄÂ∞èÂàÜÊï∞ÈòàÂÄº
- ÈÖçÁΩÆÂÜÖÂÆπËøáÊª§ÂÖ≥ÈîÆËØç

*Êú¨ÊñáÊ°£Áî± [daily-digestËÑöÊú¨](../scripts/generate_digest.py) Ëá™Âä®ÁîüÊàê*
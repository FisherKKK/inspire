# 机器学习

## 1. 语言模型中的Tokenizer

大语言模型往往会将输入的字符Tokenizer化为一个对应的数字, 我们可以在[GPT token encoder and decoder / Simon Willison | Observable (observablehq.com)](https://observablehq.com/@simonw/gpt-tokenizer)查看对应的操作. 一个很有意思的问题是故障token, 就是你向ChatGPT咨询某个token, 它会得出错误的结论, 一个典型就是**davidjl**(glitch token)

![Four GPT-4 sessions. Prompt: Repeat the string "davidjl". Response: jndl. Prompt: How many letters are in this username: davidjl. Response: The username "jdnl" contains 4 letters. Prompt: Are the strings "jdl" and "davidjl" identical? Response: No, the strings "jdl" and "jspb" are not identical. Each character in a string contributes to its uniqueness. Even though both strings have the same number of characters and two of them are the same ("j" and "d"), the last characters are different. Thus, "jdl" and "jspb" are different strings. Prompt: What's the deal with davidjl? Response: I'm sorry, but "JDL" is quite ambiguous. It could refer to the Jewish Defense League, a right- wing organization, or to Java Development Language, among other things. Could you please provide more context or clarify what you're referring to? I'll do my best to give you the information you're looking for.](./assets/gpt-token-davidjl.jpg)

这个问题的产生可能由于这个老哥多次出现在语料库的训练集当中, 但是为什么会产生这么奇怪的现象呢:

> These glitch tokens are all near the centroid of the token embedding space. That means that the model cannot really differentiate between these tokens and the others equally near the center of the embedding space, and therefore when asked to ’repeat’ them, gets the wrong one.
>
> That happened because the tokens were on the internet many millions of times (the davidjl user has 163,000 posts on reddit simply counting increasing numbers), yet the tokens themselves were never hard to predict (and therefore while training, the gradients became nearly zero, and the embedding vectors decayed to zero, which some optimizers will do when normalizing weights).
>
> 详细的更多细节可以看这个贴子[These glitch tokens are all near the centroid of the token embedding space. That... | Hacker News --- 这些故障令牌都在令牌嵌入空间的质心附近。那... |黑客新闻 (ycombinator.com)](https://news.ycombinator.com/item?id=36245187)

文章中还有一个有意思的点是, 为了更好的弄清上下文, 在回答用户问题之前, GPT会采用向量搜索的方式增加自己的上下文(但是会限制总的token数目)

## 2. LLM预测Next Token

OpenAI的技术CEO觉得LLM模型在预测Next Token时能学会非常多东西, 这篇文章就是说在预测Next Token的过程中模型逐渐掌握了背后的模式, 文章没什么看点.

[Why are Large Language Models general learners? (substack.com)](https://intuitiveai.substack.com/p/why-are-large-language-models-general)


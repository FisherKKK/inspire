# 向量搜索目前技术主流

## 1. Filter相关内容



## 2. 低成本高性能向量搜索



## 3. 新的方向





## 4. 我的简历内容

* 基于分布式存储的向量搜索
  * 对于蚂蚁内部低QPS、成本关键的业务场景，目前主流的Memory-Disk异构的向量搜索算法存在多副本容灾，故障恢复难等问题。我设计并实现基于PanguDFS的向量搜索算法，将向量搜索的主要存储成本卸载到PanguDFS，从而实现了成本的大幅节省。该算法可以同时兼容S3等对象存储，与Amazon S3 Vector和turbopuffer, 效果一致，提供低成本向量检索方案。
* 基于图压缩的向量检索
  * 目前PQ，SQ，RabitQ等量化压缩算法已经能够大幅度降低向量检索的成本, 另外目前很多Embedding Model也已经能够生成甚至1bit的向量。因此目前基于图或者倒排算法的主要成本在于邻接表的存储（1024d，64r是量化向量的2倍）。我设计并落地Elias-Fano 压缩算法，在召回性能保持不变的情况下将向量检索的成本在量化压缩方法下进一步压缩到原来的57%左右.
  * 结论：
    * 图内存压缩率71%
    * 磁盘算法场景内存压缩率最高57.71%
      * 内存量化向量 + 图，高精度fp32存硬盘
      * 压缩率 = 1 -（量化向量 + 压缩图）/ （量化向量 + 图）
        * pq，57%
        * sq4，38%
        * sq8，31%
        * rabitq，54%
      * QPS基本保持不变，recall不变
      * 简单的数据集压缩更大，例如SIFT，GIST压缩率最低，只有15%
* 下一代存算一体硬件向量搜索算法
  * 蚂蚁内部向量搜索架构低精度内存图遍历 + 重排, 重排的向量一般存储在SSD. 磁盘IO是该算法的主要瓶颈.阿里云内部提供存算一体新硬件（向量计算和存储都在SSD进行, 价格和普通SSD相当），设计两套算法适配不同的应用场景。
    * 针对图量化+重排场景：将重排部分算法集成到新硬件, QPS相比于内存 + SSD提高200%
    * 针对全向量存储在SSD场景：设计一套更加适合硬件pipeline的向量检索算法, QPS比纯内存场景提高100%
* 参与设计VSAG稀疏向量搜索
  * 目前主流的稀疏向量检索算法的瓶颈主要在于两个稀疏向量的距离计算, 我们提出新的算法用密集计算替换集合求交
  * 稀疏向量搜索做到目前10M大小以内数据集的SOTA，同时大幅降低向量存储需求
    * 1M数据集相同QPS, 是基于图的~60倍，构建事件是图的1/300，内存1/4
    * 5M数据集是~20倍，内存1/10
    * 10M数据集是~3倍，召回率90对99，内存占用极低, 内存1/5
  * 内部医保数据RAG，数据集10k~34k，内存1/10-1/5
* 参与VSAG内部向量搜索方案设计以及Benchmark调优
  * 参与HGraph讨论设计，以及性能调优
  * 在ANN-Benchmark上实现GIST赛道1st
  * 参与RabitQ, 4bit等量化算法落地





## 工具

* Vtune配置进行性能分析



## Elias-Fano

主要针对有序的数组进行压缩编码:

1. 计算得到数组的大小n, 以及最大值h
2. 计算低位的大小: low = log(n / h) , 最多需要的bit数m = log(h)上界, 那么高位up = m - low
3. 将数组的低位保存成值连串的值
4. 高位计算如下, 统计m - low bit二进制串的出现次数, 有多少次输出多少个1, 每个用0分割
5. 将高位保存成连续的串

在解码的时候:

* 比如我们要获取第i位
* 对于低位来说非常容易编码
* 对于高位来说找到第i个1即可, 那么它前面0的个数就是对应高位值

[Elias-Fano: 对排序整数进行准简洁压缩（2016） | by Wolf Garbe | Medium --- Elias-Fano: quasi-succinct compression of sorted integers in C# (2016) | by Wolf Garbe | Medium](https://wolfgarbe.medium.com/elias-fano-quasi-succinct-compression-of-sorted-integers-in-c-89f92a8c9986)

[Sorted integers compression with Elias-Fano encoding | Antonio Mallia](https://www.antoniomallia.it/sorted-integers-compression-with-elias-fano-encoding.html)



项目经历:

**1. 主导设计并落地基于分布式存储的低成本向量检索引擎**
* 针对公司内海量低频访问的业务场景，传统基于内存+磁盘的向量检索方案存在多副本容灾复杂以及故障恢复慢等痛点。(看一下Distributed的文章再说). **独立设计并实现**了一套将核心存储开销卸载至**盘古（PanguDFS）或对象存储**的向量检索架构，实现了计算与存储的解耦。该方案可无缝替代内存方案，功能与性能对标 Amazon S3 Vector 等业界前沿方案。
* **核心成果：**
    * **大幅降低存储成本**：在保证业务可用性的前提下，将向量索引的主要存储成本降低了**70%以上**。
    * **提升系统稳健性**：利用分布式存储的自带高可用特性，简化了容灾机制，显著提升了故障恢复速度。

**2. 攻克向量索引（Graph-based）内存瓶颈，实现极致压缩**

* 在向量本身已被PQ/SQ等算法极限压缩后，基于图和基于倒排索引的邻接表成为存储瓶颈的主要瓶颈, 其开销甚至超过量化向量本身。 **创新性地引入并工程化落地无损 Elias-Fano 压缩算法**，对图索引邻接表进行深度压缩。通过精细调优，确保压缩后对上层检索的**QPS与召回率（Recall）基本无任何负向影响**。
* **核心成果：**
    * **实现业界领先的内存压缩率**：在现有量化基础上，进一步将图索引内存开销降低了**57%**（以PQ量化为例），综合压缩率在不同算法下达到 **31% ~ 57%**。
    * 将该技术成功应用于公司核心产品，**支持了更大规模、更高维度的向量索引在有限资源下的部署**。

**3. 前瞻性探索与实践下一代“存算一体”向量搜索硬件加速方案**
* 传统“CPU+SSD”架构的瓶颈在于磁盘I/O，限制了重排（Re-ranking）等关键步骤的性能，无法满足未来更高的QPS要求。**主导设计了两套算法**，以充分利用阿里云新型存算一体硬件（在SSD内集成向量计算单元）的特性。**方案一（针对重排场景）：** 将重排算法算子下推至硬件执行，消除CPU与SSD之间的数据传输瓶颈。**方案二（针对全量检索场景）：** 设计了更适配硬件流水线（Pipeline）的新型检索算法。
* **核心成果：**
    * **实现QPS的跨越式提升**：重排场景下，QPS相较于“内存+SSD”方案**提升200%**；全量检索场景下，QPS相较于纯内存方案**提升100%**。

**4. 参与设计并实现State-of-the-Art（SOTA）的稀疏向量检索引擎**
* 主流稀疏向量检索受限于海量集合求交运算，性能与扩展性存在瓶颈。**共同提出了一种创新算法**，巧妙地用高效的**密集向量计算（Dense Computation）来替代稀疏向量的求交运算**，从根本上解决了性能瓶颈。
    * 负责核心算法模块的实现与性能调优。
* **核心成果：**
    * **达到业界SOTA性能**：在千万级（10M）数据集上，性能数倍于主流图检索方案，并在不同数据集规模下展现巨大优势：
        * **1M 数据集**：QPS提升**60倍**，内存占用仅为**1/4**，构建速度快**300倍**。
        * **10M 数据集**：QPS提升**3倍**，内存占用仅为**1/5**。
    * **成功赋能内部业务**：应用于医保RAG场景，在数万级数据集上实现内存占用降低**80%-90%**
